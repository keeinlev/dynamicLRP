{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2e5bca-5fb2-4c76-afcc-a2ab615c94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3674a9c3-644b-4adc-a9ed-34e2d94e463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinlee-talka/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-2-117M/7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"zhihan1996/DNABERT-2-117M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "955778f8-7778-45cf-aa06-dee75285b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class LRPCheckpoint(torch.autograd.Function):\n",
    "    \"\"\"Identity autograd fcn for marking where to capture relevance.\"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, input: torch.Tensor) -> torch.Tensor:\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.Tensor) -> Tuple[torch.Tensor, None, None]:\n",
    "        return grad_output, None, None\n",
    "\n",
    "create_checkpoint = LRPCheckpoint.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2462a393-1877-4f94-b66c-be0b1f69c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_hook(module, input, output):\n",
    "    return create_checkpoint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f01096bb-97a3-47cf-916c-5f38a899ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_module in model.encoder.layer:\n",
    "    layer_module.attention.self.register_forward_hook(checkpoint_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "7d0cba7c-db59-4cc8-acb9-0cb41f9ccbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = \"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\"\n",
    "inputs = tokenizer(dna, return_tensors = 'pt')[\"input_ids\"]\n",
    "hidden_states : torch.Tensor = model(inputs, requires_grad=True)[0] # [1, sequence_length, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4a4b85e0-9f4d-4bcd-b5b5-81157205841a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 768])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a288ca1c-ad72-4943-85b7-2ddb78b735ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    m = hidden_states.max(-1)\n",
    "    # print(m)\n",
    "    b = torch.zeros_like(a)\n",
    "    for i, inds in enumerate(m.indices):\n",
    "        b[i,list(range(hidden_states.shape[1])),inds] = torch.ones_like(m.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "432acd9e-5070-4f44-8a29-f75ac41ea750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "fcns = [ [hidden_states.grad_fn] ]\n",
    "visited = set()\n",
    "names = set()\n",
    "\n",
    "count = 0\n",
    "while fcns:\n",
    "    count += 1\n",
    "    # print(len(fcns))\n",
    "    new_fcns = []\n",
    "    for fcn_list in fcns:\n",
    "        for fcn in fcn_list:\n",
    "            if fcn is None or fcn in visited:\n",
    "                continue\n",
    "            if type(fcn).__name__ not in names:\n",
    "                names.add(type(fcn).__name__)\n",
    "            visited.add(fcn)\n",
    "            new_fcns.append([ fcn_tup[0] for fcn_tup in fcn.next_functions ])\n",
    "        # new_fcns += [ [ fcn_tup[0] for fcn_tup in curr.next_functions ] for curr in fcn_list if (curr is not None) ]\n",
    "    fcns = new_fcns\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "703f399d-f29f-40d5-9dae-e131fe3e7f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccumulateGrad',\n",
       " 'AddBackward0',\n",
       " 'AddmmBackward0',\n",
       " 'BmmBackward0',\n",
       " 'DivBackward0',\n",
       " 'EmbeddingBackward0',\n",
       " 'ExpandBackward0',\n",
       " 'GeluBackward0',\n",
       " 'IndexFirstAxisBackward',\n",
       " 'IndexPutFirstAxisBackward',\n",
       " 'LRPCheckpointBackward',\n",
       " 'MmBackward0',\n",
       " 'MulBackward0',\n",
       " 'NativeLayerNormBackward0',\n",
       " 'PermuteBackward0',\n",
       " 'ReshapeAliasBackward0',\n",
       " 'SelectBackward0',\n",
       " 'SliceBackward0',\n",
       " 'SoftmaxBackward0',\n",
       " 'TBackward0',\n",
       " 'UnsafeViewBackward0',\n",
       " 'ViewBackward0'}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "cb40f3c5-406a-40e5-8586-8befdadb8e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = list(visited)\n",
    "visited = sorted(visited, key=lambda fcn: fcn._sequence_nr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0d57aada-f2bd-43c3-af00-839a878fb75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, <EmbeddingBackward0 at 0x28e21f6d0>),\n",
       " (1, <EmbeddingBackward0 at 0x28e21f6a0>),\n",
       " (2, <AddBackward0 at 0x28e21f430>),\n",
       " (3, <NativeLayerNormBackward0 at 0x28e21f1c0>),\n",
       " (4, <ViewBackward0 at 0x28e219d60>),\n",
       " (5, <torch.autograd.function.IndexFirstAxisBackward at 0x28d5ce440>),\n",
       " (6, <TBackward0 at 0x28e21dc10>),\n",
       " (7, <AddmmBackward0 at 0x28e21db20>),\n",
       " (8, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e372240>),\n",
       " (9, <ViewBackward0 at 0x28e21da30>),\n",
       " (10, <ViewBackward0 at 0x28e21d8e0>),\n",
       " (11, <SliceBackward0 at 0x28e21dc40>),\n",
       " (12, <SliceBackward0 at 0x28e21dbe0>),\n",
       " (13, <SelectBackward0 at 0x28e21dbb0>),\n",
       " (14, <SliceBackward0 at 0x28e21dac0>),\n",
       " (15, <SliceBackward0 at 0x28e21da60>),\n",
       " (16, <PermuteBackward0 at 0x28e21d9d0>),\n",
       " (17, <SliceBackward0 at 0x28e21dcd0>),\n",
       " (18, <SliceBackward0 at 0x28e21dc70>),\n",
       " (19, <SelectBackward0 at 0x28e21db80>),\n",
       " (20, <SliceBackward0 at 0x28e21db50>),\n",
       " (21, <SliceBackward0 at 0x28e21daf0>),\n",
       " (22, <PermuteBackward0 at 0x28e21d9a0>),\n",
       " (23, <SliceBackward0 at 0x28e21d7c0>),\n",
       " (24, <SliceBackward0 at 0x28e21d6a0>),\n",
       " (25, <SelectBackward0 at 0x28e21d580>),\n",
       " (26, <SliceBackward0 at 0x28e21d490>),\n",
       " (27, <SliceBackward0 at 0x28e21d310>),\n",
       " (28, <PermuteBackward0 at 0x28e21d190>),\n",
       " (29, <ExpandBackward0 at 0x28e21d880>),\n",
       " (30, <ReshapeAliasBackward0 at 0x28e21d760>),\n",
       " (31, <ExpandBackward0 at 0x28e21d910>),\n",
       " (32, <ReshapeAliasBackward0 at 0x28e21d7f0>),\n",
       " (33, <BmmBackward0 at 0x28e21d6d0>),\n",
       " (34, <UnsafeViewBackward0 at 0x28e21d5b0>),\n",
       " (35, <DivBackward0 at 0x28e21d400>),\n",
       " (36, <AddBackward0 at 0x28e21d280>),\n",
       " (37, <SoftmaxBackward0 at 0x28e21d100>),\n",
       " (38, <ExpandBackward0 at 0x28e21feb0>),\n",
       " (39, <ViewBackward0 at 0x28e21fdf0>),\n",
       " (40, <ExpandBackward0 at 0x28e21fe80>),\n",
       " (41, <ReshapeAliasBackward0 at 0x28e21fdc0>),\n",
       " (42, <BmmBackward0 at 0x28e21fbe0>),\n",
       " (43, <UnsafeViewBackward0 at 0x28e21fa90>),\n",
       " (44, <PermuteBackward0 at 0x28e21f880>),\n",
       " (45, <ReshapeAliasBackward0 at 0x28e21f640>),\n",
       " (46, <torch.autograd.function.IndexFirstAxisBackward at 0x28e372440>),\n",
       " (47, <ViewBackward0 at 0x28e21f1f0>),\n",
       " (48, <torch.autograd.function.LRPCheckpointBackward at 0x28e372140>),\n",
       " (49, <TBackward0 at 0x28e219fd0>),\n",
       " (50, <AddmmBackward0 at 0x28e219ca0>),\n",
       " (51, <AddBackward0 at 0x28e219a00>),\n",
       " (52, <NativeLayerNormBackward0 at 0x28e219790>),\n",
       " (53, <TBackward0 at 0x28e21f3a0>),\n",
       " (54, <MmBackward0 at 0x28e21f160>),\n",
       " (55, <SliceBackward0 at 0x28e21f190>),\n",
       " (56, <SliceBackward0 at 0x28e219f70>),\n",
       " (57, <SliceBackward0 at 0x28e219fa0>),\n",
       " (58, <SliceBackward0 at 0x28e219c70>),\n",
       " (59, <GeluBackward0 at 0x28e219c40>),\n",
       " (60, <MulBackward0 at 0x28e2199a0>),\n",
       " (61, <TBackward0 at 0x28e2199d0>),\n",
       " (62, <AddmmBackward0 at 0x28e219760>),\n",
       " (63, <AddBackward0 at 0x28e2194f0>),\n",
       " (64, <NativeLayerNormBackward0 at 0x28e2191f0>),\n",
       " (65, <TBackward0 at 0x28e21d8b0>),\n",
       " (66, <AddmmBackward0 at 0x28e21d790>),\n",
       " (67, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e372340>),\n",
       " (68, <ViewBackward0 at 0x28e21d520>),\n",
       " (69, <ViewBackward0 at 0x28e21d430>),\n",
       " (70, <SliceBackward0 at 0x28e21da00>),\n",
       " (71, <SliceBackward0 at 0x28e21d970>),\n",
       " (72, <SelectBackward0 at 0x28e21d850>),\n",
       " (73, <SliceBackward0 at 0x28e21d730>),\n",
       " (74, <SliceBackward0 at 0x28e21d670>),\n",
       " (75, <PermuteBackward0 at 0x28e21d4c0>),\n",
       " (76, <SliceBackward0 at 0x28e21da90>),\n",
       " (77, <SliceBackward0 at 0x28e21d940>),\n",
       " (78, <SelectBackward0 at 0x28e21d820>),\n",
       " (79, <SliceBackward0 at 0x28e21d700>),\n",
       " (80, <SliceBackward0 at 0x28e21d640>),\n",
       " (81, <PermuteBackward0 at 0x28e21d550>),\n",
       " (82, <SliceBackward0 at 0x28e21d2b0>),\n",
       " (83, <SliceBackward0 at 0x28e21d130>),\n",
       " (84, <SelectBackward0 at 0x28e21fe20>),\n",
       " (85, <SliceBackward0 at 0x28e21fd60>),\n",
       " (86, <SliceBackward0 at 0x28e21fc10>),\n",
       " (87, <PermuteBackward0 at 0x28e21fa00>),\n",
       " (88, <ExpandBackward0 at 0x28e21d3d0>),\n",
       " (89, <ReshapeAliasBackward0 at 0x28e21d250>),\n",
       " (90, <ExpandBackward0 at 0x28e21d3a0>),\n",
       " (91, <ReshapeAliasBackward0 at 0x28e21d220>),\n",
       " (92, <BmmBackward0 at 0x28e21d0a0>),\n",
       " (93, <UnsafeViewBackward0 at 0x28e21ffa0>),\n",
       " (94, <DivBackward0 at 0x28e21fd90>),\n",
       " (95, <AddBackward0 at 0x28e21fb80>),\n",
       " (96, <SoftmaxBackward0 at 0x28e21fa30>),\n",
       " (97, <ExpandBackward0 at 0x28e21f820>),\n",
       " (98, <ViewBackward0 at 0x28e21f5e0>),\n",
       " (99, <ExpandBackward0 at 0x28e21f8b0>),\n",
       " (100, <ReshapeAliasBackward0 at 0x28e21f670>),\n",
       " (101, <BmmBackward0 at 0x28e21f3d0>),\n",
       " (102, <UnsafeViewBackward0 at 0x28e21f100>),\n",
       " (103, <PermuteBackward0 at 0x28e219f40>),\n",
       " (104, <ReshapeAliasBackward0 at 0x28e219c10>),\n",
       " (105, <torch.autograd.function.IndexFirstAxisBackward at 0x28e372540>),\n",
       " (106, <ViewBackward0 at 0x28e219730>),\n",
       " (107, <torch.autograd.function.LRPCheckpointBackward at 0x28e372640>),\n",
       " (108, <TBackward0 at 0x28e2194c0>),\n",
       " (109, <AddmmBackward0 at 0x28e2191c0>),\n",
       " (110, <AddBackward0 at 0x28eaabee0>),\n",
       " (111, <NativeLayerNormBackward0 at 0x28eaabc70>),\n",
       " (112, <TBackward0 at 0x28e219970>),\n",
       " (113, <MmBackward0 at 0x28e219700>),\n",
       " (114, <SliceBackward0 at 0x28e2196d0>),\n",
       " (115, <SliceBackward0 at 0x28e219460>),\n",
       " (116, <SliceBackward0 at 0x28e219490>),\n",
       " (117, <SliceBackward0 at 0x28e219190>),\n",
       " (118, <GeluBackward0 at 0x28e219160>),\n",
       " (119, <MulBackward0 at 0x28eaabe80>),\n",
       " (120, <TBackward0 at 0x28eaabeb0>),\n",
       " (121, <AddmmBackward0 at 0x28eaabc40>),\n",
       " (122, <AddBackward0 at 0x28eaab9d0>),\n",
       " (123, <NativeLayerNormBackward0 at 0x28eaab610>),\n",
       " (124, <TBackward0 at 0x28e21d340>),\n",
       " (125, <AddmmBackward0 at 0x28e21d1c0>),\n",
       " (126, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e372740>),\n",
       " (127, <ViewBackward0 at 0x28e21ffd0>),\n",
       " (128, <ViewBackward0 at 0x28e21fd00>),\n",
       " (129, <SliceBackward0 at 0x28e21d610>),\n",
       " (130, <SliceBackward0 at 0x28e21d460>),\n",
       " (131, <SelectBackward0 at 0x28e21d2e0>),\n",
       " (132, <SliceBackward0 at 0x28e21d160>),\n",
       " (133, <SliceBackward0 at 0x28e21d040>),\n",
       " (134, <PermuteBackward0 at 0x28e21ff70>),\n",
       " (135, <SliceBackward0 at 0x28e21d5e0>),\n",
       " (136, <SliceBackward0 at 0x28e21d4f0>),\n",
       " (137, <SelectBackward0 at 0x28e21d370>),\n",
       " (138, <SliceBackward0 at 0x28e21d1f0>),\n",
       " (139, <SliceBackward0 at 0x28e21d0d0>),\n",
       " (140, <PermuteBackward0 at 0x28e21ff40>),\n",
       " (141, <SliceBackward0 at 0x28e21fbb0>),\n",
       " (142, <SliceBackward0 at 0x28e21f9a0>),\n",
       " (143, <SelectBackward0 at 0x28e21f850>),\n",
       " (144, <SliceBackward0 at 0x28e21f610>),\n",
       " (145, <SliceBackward0 at 0x28e21f340>),\n",
       " (146, <PermuteBackward0 at 0x28e21f130>),\n",
       " (147, <ExpandBackward0 at 0x28e21fca0>),\n",
       " (148, <ReshapeAliasBackward0 at 0x28e21fb50>),\n",
       " (149, <ExpandBackward0 at 0x28e21fd30>),\n",
       " (150, <ReshapeAliasBackward0 at 0x28e21fb20>),\n",
       " (151, <BmmBackward0 at 0x28e21f9d0>),\n",
       " (152, <UnsafeViewBackward0 at 0x28e21f7c0>),\n",
       " (153, <DivBackward0 at 0x28e21f580>),\n",
       " (154, <AddBackward0 at 0x28e21f370>),\n",
       " (155, <SoftmaxBackward0 at 0x28e21f0a0>),\n",
       " (156, <ExpandBackward0 at 0x28e219ee0>),\n",
       " (157, <ViewBackward0 at 0x28e219bb0>),\n",
       " (158, <ExpandBackward0 at 0x28e219f10>),\n",
       " (159, <ReshapeAliasBackward0 at 0x28e219be0>),\n",
       " (160, <BmmBackward0 at 0x28e219940>),\n",
       " (161, <UnsafeViewBackward0 at 0x28e2196a0>),\n",
       " (162, <PermuteBackward0 at 0x28e219430>),\n",
       " (163, <ReshapeAliasBackward0 at 0x28e219130>),\n",
       " (164, <torch.autograd.function.IndexFirstAxisBackward at 0x28e372840>),\n",
       " (165, <ViewBackward0 at 0x28eaabc10>),\n",
       " (166, <torch.autograd.function.LRPCheckpointBackward at 0x28e372940>),\n",
       " (167, <TBackward0 at 0x28eaab9a0>),\n",
       " (168, <AddmmBackward0 at 0x28eaab5e0>),\n",
       " (169, <AddBackward0 at 0x28eaab2e0>),\n",
       " (170, <NativeLayerNormBackward0 at 0x28eaab070>),\n",
       " (171, <TBackward0 at 0x28eaabe50>),\n",
       " (172, <MmBackward0 at 0x28eaabbe0>),\n",
       " (173, <SliceBackward0 at 0x28eaabbb0>),\n",
       " (174, <SliceBackward0 at 0x28eaab8e0>),\n",
       " (175, <SliceBackward0 at 0x28eaab910>),\n",
       " (176, <SliceBackward0 at 0x28eaab5b0>),\n",
       " (177, <GeluBackward0 at 0x28eaab580>),\n",
       " (178, <MulBackward0 at 0x28eaab280>),\n",
       " (179, <TBackward0 at 0x28eaab2b0>),\n",
       " (180, <AddmmBackward0 at 0x28eaab040>),\n",
       " (181, <AddBackward0 at 0x28e20dd60>),\n",
       " (182, <NativeLayerNormBackward0 at 0x28e20dac0>),\n",
       " (183, <TBackward0 at 0x28e21fcd0>),\n",
       " (184, <AddmmBackward0 at 0x28e21fac0>),\n",
       " (185, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e372a40>),\n",
       " (186, <ViewBackward0 at 0x28e21f7f0>),\n",
       " (187, <ViewBackward0 at 0x28e21f5b0>),\n",
       " (188, <SliceBackward0 at 0x28e21ff10>),\n",
       " (189, <SliceBackward0 at 0x28e21fe50>),\n",
       " (190, <SelectBackward0 at 0x28e21fc70>),\n",
       " (191, <SliceBackward0 at 0x28e21fa60>),\n",
       " (192, <SliceBackward0 at 0x28e21f970>),\n",
       " (193, <PermuteBackward0 at 0x28e21f790>),\n",
       " (194, <SliceBackward0 at 0x28da6df10>),\n",
       " (195, <SliceBackward0 at 0x28e21fee0>),\n",
       " (196, <SelectBackward0 at 0x28e21fc40>),\n",
       " (197, <SliceBackward0 at 0x28e21faf0>),\n",
       " (198, <SliceBackward0 at 0x28e21f940>),\n",
       " (199, <PermuteBackward0 at 0x28e21f760>),\n",
       " (200, <SliceBackward0 at 0x28e21f2e0>),\n",
       " (201, <SliceBackward0 at 0x28e21f0d0>),\n",
       " (202, <SelectBackward0 at 0x28e219eb0>),\n",
       " (203, <SliceBackward0 at 0x28e219b80>),\n",
       " (204, <SliceBackward0 at 0x28e219910>),\n",
       " (205, <PermuteBackward0 at 0x28e219670>),\n",
       " (206, <ExpandBackward0 at 0x28e21f550>),\n",
       " (207, <ReshapeAliasBackward0 at 0x28e21f280>),\n",
       " (208, <ExpandBackward0 at 0x28e21f520>),\n",
       " (209, <ReshapeAliasBackward0 at 0x28e21f310>),\n",
       " (210, <BmmBackward0 at 0x28e21f040>),\n",
       " (211, <UnsafeViewBackward0 at 0x28e219e80>),\n",
       " (212, <DivBackward0 at 0x28e219b50>),\n",
       " (213, <AddBackward0 at 0x28e2198e0>),\n",
       " (214, <SoftmaxBackward0 at 0x28e219640>),\n",
       " (215, <ExpandBackward0 at 0x28e219370>),\n",
       " (216, <ViewBackward0 at 0x28e2190d0>),\n",
       " (217, <ExpandBackward0 at 0x28e219400>),\n",
       " (218, <ReshapeAliasBackward0 at 0x28e219100>),\n",
       " (219, <BmmBackward0 at 0x28eaabe20>),\n",
       " (220, <UnsafeViewBackward0 at 0x28eaabb80>),\n",
       " (221, <PermuteBackward0 at 0x28eaab8b0>),\n",
       " (222, <ReshapeAliasBackward0 at 0x28eaab4f0>),\n",
       " (223, <torch.autograd.function.IndexFirstAxisBackward at 0x28e372b40>),\n",
       " (224, <ViewBackward0 at 0x28e20dfa0>),\n",
       " (225, <torch.autograd.function.LRPCheckpointBackward at 0x28e372c40>),\n",
       " (226, <TBackward0 at 0x28e20dd90>),\n",
       " (227, <AddmmBackward0 at 0x28e20daf0>),\n",
       " (228, <AddBackward0 at 0x28e20d730>),\n",
       " (229, <NativeLayerNormBackward0 at 0x28e20d400>),\n",
       " (230, <TBackward0 at 0x28eaab250>),\n",
       " (231, <MmBackward0 at 0x28e20dfd0>),\n",
       " (232, <SliceBackward0 at 0x28e20df40>),\n",
       " (233, <SliceBackward0 at 0x28e20dd30>),\n",
       " (234, <SliceBackward0 at 0x28e20dd00>),\n",
       " (235, <SliceBackward0 at 0x28e20da60>),\n",
       " (236, <GeluBackward0 at 0x28e20da30>),\n",
       " (237, <MulBackward0 at 0x28e20d6d0>),\n",
       " (238, <TBackward0 at 0x28e20d6a0>),\n",
       " (239, <AddmmBackward0 at 0x28e20d430>),\n",
       " (240, <AddBackward0 at 0x28e20d160>),\n",
       " (241, <NativeLayerNormBackward0 at 0x28e235f70>),\n",
       " (242, <TBackward0 at 0x28e21f4c0>),\n",
       " (243, <AddmmBackward0 at 0x28e21f2b0>),\n",
       " (244, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e372d40>),\n",
       " (245, <ViewBackward0 at 0x28e219e50>),\n",
       " (246, <ViewBackward0 at 0x28e219b20>),\n",
       " (247, <SliceBackward0 at 0x28e21f910>),\n",
       " (248, <SliceBackward0 at 0x28e21f730>),\n",
       " (249, <SelectBackward0 at 0x28e21f400>),\n",
       " (250, <SliceBackward0 at 0x28e21f250>),\n",
       " (251, <SliceBackward0 at 0x28e219df0>),\n",
       " (252, <PermuteBackward0 at 0x28e219d30>),\n",
       " (253, <SliceBackward0 at 0x28e21f8e0>),\n",
       " (254, <SliceBackward0 at 0x28e21f700>),\n",
       " (255, <SelectBackward0 at 0x28e21f490>),\n",
       " (256, <SliceBackward0 at 0x28e21f220>),\n",
       " (257, <SliceBackward0 at 0x28e21f070>),\n",
       " (258, <PermuteBackward0 at 0x28e219e20>),\n",
       " (259, <SliceBackward0 at 0x28e2198b0>),\n",
       " (260, <SliceBackward0 at 0x28e219610>),\n",
       " (261, <SelectBackward0 at 0x28e219340>),\n",
       " (262, <SliceBackward0 at 0x28e2190a0>),\n",
       " (263, <SliceBackward0 at 0x28eaabdf0>),\n",
       " (264, <PermuteBackward0 at 0x28eaabb50>),\n",
       " (265, <ExpandBackward0 at 0x28e219ac0>),\n",
       " (266, <ReshapeAliasBackward0 at 0x28e219850>),\n",
       " (267, <ExpandBackward0 at 0x28e219af0>),\n",
       " (268, <ReshapeAliasBackward0 at 0x28e219880>),\n",
       " (269, <BmmBackward0 at 0x28e2195e0>),\n",
       " (270, <UnsafeViewBackward0 at 0x28e219310>),\n",
       " (271, <DivBackward0 at 0x28e219070>),\n",
       " (272, <AddBackward0 at 0x28eaabdc0>),\n",
       " (273, <SoftmaxBackward0 at 0x28eaabb20>),\n",
       " (274, <ExpandBackward0 at 0x28eaab850>),\n",
       " (275, <ViewBackward0 at 0x28eaab490>),\n",
       " (276, <ExpandBackward0 at 0x28eaab880>),\n",
       " (277, <ReshapeAliasBackward0 at 0x28eaab4c0>),\n",
       " (278, <BmmBackward0 at 0x28eaab220>),\n",
       " (279, <UnsafeViewBackward0 at 0x28e20df70>),\n",
       " (280, <PermuteBackward0 at 0x28e20dca0>),\n",
       " (281, <ReshapeAliasBackward0 at 0x28e20d9a0>),\n",
       " (282, <torch.autograd.function.IndexFirstAxisBackward at 0x28e372e40>),\n",
       " (283, <ViewBackward0 at 0x28e20d3a0>),\n",
       " (284, <torch.autograd.function.LRPCheckpointBackward at 0x28e3b7040>),\n",
       " (285, <TBackward0 at 0x28e20d190>),\n",
       " (286, <AddmmBackward0 at 0x28e235ee0>),\n",
       " (287, <AddBackward0 at 0x28e235b80>),\n",
       " (288, <NativeLayerNormBackward0 at 0x28e235970>),\n",
       " (289, <TBackward0 at 0x28e20d640>),\n",
       " (290, <MmBackward0 at 0x28e20d3d0>),\n",
       " (291, <SliceBackward0 at 0x28e20d340>),\n",
       " (292, <SliceBackward0 at 0x28e20d130>),\n",
       " (293, <SliceBackward0 at 0x28e20d100>),\n",
       " (294, <SliceBackward0 at 0x28e235f10>),\n",
       " (295, <GeluBackward0 at 0x28e235e80>),\n",
       " (296, <MulBackward0 at 0x28e235b20>),\n",
       " (297, <TBackward0 at 0x28e235bb0>),\n",
       " (298, <AddmmBackward0 at 0x28e2358e0>),\n",
       " (299, <AddBackward0 at 0x28e2356d0>),\n",
       " (300, <NativeLayerNormBackward0 at 0x28e235430>),\n",
       " (301, <TBackward0 at 0x28e219a90>),\n",
       " (302, <AddmmBackward0 at 0x28e219820>),\n",
       " (303, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e3b7140>),\n",
       " (304, <ViewBackward0 at 0x28e2192e0>),\n",
       " (305, <ViewBackward0 at 0x28e219040>),\n",
       " (306, <SliceBackward0 at 0x28e219d90>),\n",
       " (307, <SliceBackward0 at 0x28e219cd0>),\n",
       " (308, <SelectBackward0 at 0x28e219a30>),\n",
       " (309, <SliceBackward0 at 0x28e2197c0>),\n",
       " (310, <SliceBackward0 at 0x28e219580>),\n",
       " (311, <PermuteBackward0 at 0x28e219280>),\n",
       " (312, <SliceBackward0 at 0x28e219dc0>),\n",
       " (313, <SliceBackward0 at 0x28e219d00>),\n",
       " (314, <SelectBackward0 at 0x28e219a60>),\n",
       " (315, <SliceBackward0 at 0x28e2197f0>),\n",
       " (316, <SliceBackward0 at 0x28e2195b0>),\n",
       " (317, <PermuteBackward0 at 0x28e2192b0>),\n",
       " (318, <SliceBackward0 at 0x28eaabd90>),\n",
       " (319, <SliceBackward0 at 0x28eaabaf0>),\n",
       " (320, <SelectBackward0 at 0x28eaab820>),\n",
       " (321, <SliceBackward0 at 0x28eaab460>),\n",
       " (322, <SliceBackward0 at 0x28eaab1f0>),\n",
       " (323, <PermuteBackward0 at 0x28e20dee0>),\n",
       " (324, <ExpandBackward0 at 0x28eaabfa0>),\n",
       " (325, <ReshapeAliasBackward0 at 0x28eaabd30>),\n",
       " (326, <ExpandBackward0 at 0x28eaabfd0>),\n",
       " (327, <ReshapeAliasBackward0 at 0x28eaabd60>),\n",
       " (328, <BmmBackward0 at 0x28eaabac0>),\n",
       " (329, <UnsafeViewBackward0 at 0x28eaab7f0>),\n",
       " (330, <DivBackward0 at 0x28eaab430>),\n",
       " (331, <AddBackward0 at 0x28eaab1c0>),\n",
       " (332, <SoftmaxBackward0 at 0x28e20df10>),\n",
       " (333, <ExpandBackward0 at 0x28e20dc40>),\n",
       " (334, <ViewBackward0 at 0x28e20d940>),\n",
       " (335, <ExpandBackward0 at 0x28e20dcd0>),\n",
       " (336, <ReshapeAliasBackward0 at 0x28e20d9d0>),\n",
       " (337, <BmmBackward0 at 0x28e20d610>),\n",
       " (338, <UnsafeViewBackward0 at 0x28e20d370>),\n",
       " (339, <PermuteBackward0 at 0x28e20d0a0>),\n",
       " (340, <ReshapeAliasBackward0 at 0x28e235eb0>),\n",
       " (341, <torch.autograd.function.IndexFirstAxisBackward at 0x28e3b7240>),\n",
       " (342, <ViewBackward0 at 0x28e235910>),\n",
       " (343, <torch.autograd.function.LRPCheckpointBackward at 0x28e3b7340>),\n",
       " (344, <TBackward0 at 0x28e235640>),\n",
       " (345, <AddmmBackward0 at 0x28e2353a0>),\n",
       " (346, <AddBackward0 at 0x28e235070>),\n",
       " (347, <NativeLayerNormBackward0 at 0x28e225670>),\n",
       " (348, <TBackward0 at 0x28e235b50>),\n",
       " (349, <MmBackward0 at 0x28e235880>),\n",
       " (350, <SliceBackward0 at 0x28e2358b0>),\n",
       " (351, <SliceBackward0 at 0x28e2355e0>),\n",
       " (352, <SliceBackward0 at 0x28e235670>),\n",
       " (353, <SliceBackward0 at 0x28e2353d0>),\n",
       " (354, <GeluBackward0 at 0x28e235340>),\n",
       " (355, <MulBackward0 at 0x28e2352b0>),\n",
       " (356, <TBackward0 at 0x28e235220>),\n",
       " (357, <AddmmBackward0 at 0x28e225490>),\n",
       " (358, <AddBackward0 at 0x28e225ee0>),\n",
       " (359, <NativeLayerNormBackward0 at 0x28e225dc0>),\n",
       " (360, <TBackward0 at 0x28eaabf70>),\n",
       " (361, <AddmmBackward0 at 0x28eaabd00>),\n",
       " (362, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e3b7440>),\n",
       " (363, <ViewBackward0 at 0x28eaab7c0>),\n",
       " (364, <ViewBackward0 at 0x28eaab400>),\n",
       " (365, <SliceBackward0 at 0x28e219520>),\n",
       " (366, <SliceBackward0 at 0x28e219220>),\n",
       " (367, <SelectBackward0 at 0x28eaabf10>),\n",
       " (368, <SliceBackward0 at 0x28eaabca0>),\n",
       " (369, <SliceBackward0 at 0x28eaaba60>),\n",
       " (370, <PermuteBackward0 at 0x28eaab6a0>),\n",
       " (371, <SliceBackward0 at 0x28e219550>),\n",
       " (372, <SliceBackward0 at 0x28e219250>),\n",
       " (373, <SelectBackward0 at 0x28eaabf40>),\n",
       " (374, <SliceBackward0 at 0x28eaabcd0>),\n",
       " (375, <SliceBackward0 at 0x28eaaba90>),\n",
       " (376, <PermuteBackward0 at 0x28eaab6d0>),\n",
       " (377, <SliceBackward0 at 0x28eaab190>),\n",
       " (378, <SliceBackward0 at 0x28e20de80>),\n",
       " (379, <SelectBackward0 at 0x28e20dc70>),\n",
       " (380, <SliceBackward0 at 0x28e20d970>),\n",
       " (381, <SliceBackward0 at 0x28e20d580>),\n",
       " (382, <PermuteBackward0 at 0x28e20d2e0>),\n",
       " (383, <ExpandBackward0 at 0x28eaab3a0>),\n",
       " (384, <ReshapeAliasBackward0 at 0x28eaab130>),\n",
       " (385, <ExpandBackward0 at 0x28eaab3d0>),\n",
       " (386, <ReshapeAliasBackward0 at 0x28eaab160>),\n",
       " (387, <BmmBackward0 at 0x28e20deb0>),\n",
       " (388, <UnsafeViewBackward0 at 0x28e20dbe0>),\n",
       " (389, <DivBackward0 at 0x28e20d8e0>),\n",
       " (390, <AddBackward0 at 0x28e20d5b0>),\n",
       " (391, <SoftmaxBackward0 at 0x28e20d310>),\n",
       " (392, <ExpandBackward0 at 0x28e20d040>),\n",
       " (393, <ViewBackward0 at 0x28e235df0>),\n",
       " (394, <ExpandBackward0 at 0x28e20d0d0>),\n",
       " (395, <ReshapeAliasBackward0 at 0x28e235e20>),\n",
       " (396, <BmmBackward0 at 0x28e235ac0>),\n",
       " (397, <UnsafeViewBackward0 at 0x28e235820>),\n",
       " (398, <PermuteBackward0 at 0x28e235610>),\n",
       " (399, <ReshapeAliasBackward0 at 0x28e235370>),\n",
       " (400, <torch.autograd.function.IndexFirstAxisBackward at 0x28e3b7540>),\n",
       " (401, <ViewBackward0 at 0x28e225eb0>),\n",
       " (402, <torch.autograd.function.LRPCheckpointBackward at 0x28e3b7640>),\n",
       " (403, <TBackward0 at 0x28e2250d0>),\n",
       " (404, <AddmmBackward0 at 0x28e2255e0>),\n",
       " (405, <AddBackward0 at 0x28da440d0>),\n",
       " (406, <NativeLayerNormBackward0 at 0x28da44580>),\n",
       " (407, <TBackward0 at 0x28e235280>),\n",
       " (408, <MmBackward0 at 0x28e225a30>),\n",
       " (409, <SliceBackward0 at 0x28e225a00>),\n",
       " (410, <SliceBackward0 at 0x28e2254c0>),\n",
       " (411, <SliceBackward0 at 0x28e225e50>),\n",
       " (412, <SliceBackward0 at 0x28e225280>),\n",
       " (413, <GeluBackward0 at 0x28e2251c0>),\n",
       " (414, <MulBackward0 at 0x28da441c0>),\n",
       " (415, <TBackward0 at 0x28da44400>),\n",
       " (416, <AddmmBackward0 at 0x28da44a30>),\n",
       " (417, <AddBackward0 at 0x28e212e20>),\n",
       " (418, <NativeLayerNormBackward0 at 0x28e2124f0>),\n",
       " (419, <TBackward0 at 0x28eaab370>),\n",
       " (420, <AddmmBackward0 at 0x28eaab100>),\n",
       " (421, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e3b7740>),\n",
       " (422, <ViewBackward0 at 0x28e20dc10>),\n",
       " (423, <ViewBackward0 at 0x28e20d910>),\n",
       " (424, <SliceBackward0 at 0x28eaaba00>),\n",
       " (425, <SliceBackward0 at 0x28eaab640>),\n",
       " (426, <SelectBackward0 at 0x28eaab310>),\n",
       " (427, <SliceBackward0 at 0x28eaab0a0>),\n",
       " (428, <SliceBackward0 at 0x28e20de50>),\n",
       " (429, <PermuteBackward0 at 0x28e20dbb0>),\n",
       " (430, <SliceBackward0 at 0x28eaaba30>),\n",
       " (431, <SliceBackward0 at 0x28eaab670>),\n",
       " (432, <SelectBackward0 at 0x28eaab340>),\n",
       " (433, <SliceBackward0 at 0x28eaab0d0>),\n",
       " (434, <SliceBackward0 at 0x28e20de20>),\n",
       " (435, <PermuteBackward0 at 0x28e20db80>),\n",
       " (436, <SliceBackward0 at 0x28e20d520>),\n",
       " (437, <SliceBackward0 at 0x28e20d280>),\n",
       " (438, <SelectBackward0 at 0x28e20d070>),\n",
       " (439, <SliceBackward0 at 0x28e235d60>),\n",
       " (440, <SliceBackward0 at 0x28e235af0>),\n",
       " (441, <PermuteBackward0 at 0x28e235850>),\n",
       " (442, <ExpandBackward0 at 0x28e20d7f0>),\n",
       " (443, <ReshapeAliasBackward0 at 0x28e20d4c0>),\n",
       " (444, <ExpandBackward0 at 0x28e20d880>),\n",
       " (445, <ReshapeAliasBackward0 at 0x28e20d550>),\n",
       " (446, <BmmBackward0 at 0x28e20d2b0>),\n",
       " (447, <UnsafeViewBackward0 at 0x28da2e730>),\n",
       " (448, <DivBackward0 at 0x28e235d90>),\n",
       " (449, <AddBackward0 at 0x28e235a60>),\n",
       " (450, <SoftmaxBackward0 at 0x28e2357c0>),\n",
       " (451, <ExpandBackward0 at 0x28e2355b0>),\n",
       " (452, <ViewBackward0 at 0x28e235310>),\n",
       " (453, <ExpandBackward0 at 0x28e235580>),\n",
       " (454, <ReshapeAliasBackward0 at 0x28e2352e0>),\n",
       " (455, <BmmBackward0 at 0x288d4c3a0>),\n",
       " (456, <UnsafeViewBackward0 at 0x28e225250>),\n",
       " (457, <PermuteBackward0 at 0x28e2256a0>),\n",
       " (458, <ReshapeAliasBackward0 at 0x28e225fd0>),\n",
       " (459, <torch.autograd.function.IndexFirstAxisBackward at 0x28e3b7840>),\n",
       " (460, <ViewBackward0 at 0x28da443d0>),\n",
       " (461, <torch.autograd.function.LRPCheckpointBackward at 0x28e3b7940>),\n",
       " (462, <TBackward0 at 0x28e2129a0>),\n",
       " (463, <AddmmBackward0 at 0x28e2124c0>),\n",
       " (464, <AddBackward0 at 0x28e2122b0>),\n",
       " (465, <NativeLayerNormBackward0 at 0x28e212b80>),\n",
       " (466, <TBackward0 at 0x28da44970>),\n",
       " (467, <MmBackward0 at 0x28da44670>),\n",
       " (468, <SliceBackward0 at 0x28e212910>),\n",
       " (469, <SliceBackward0 at 0x28e212af0>),\n",
       " (470, <SliceBackward0 at 0x28e212b20>),\n",
       " (471, <SliceBackward0 at 0x28e212490>),\n",
       " (472, <GeluBackward0 at 0x28e212460>),\n",
       " (473, <MulBackward0 at 0x28e212250>),\n",
       " (474, <TBackward0 at 0x28e212280>),\n",
       " (475, <AddmmBackward0 at 0x28e212b50>),\n",
       " (476, <AddBackward0 at 0x28e212cd0>),\n",
       " (477, <NativeLayerNormBackward0 at 0x28e212a00>),\n",
       " (478, <TBackward0 at 0x28e20d760>),\n",
       " (479, <AddmmBackward0 at 0x28e20d4f0>),\n",
       " (480, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e3b7a40>),\n",
       " (481, <ViewBackward0 at 0x28e2350d0>),\n",
       " (482, <ViewBackward0 at 0x28e235d00>),\n",
       " (483, <SliceBackward0 at 0x28e20ddf0>),\n",
       " (484, <SliceBackward0 at 0x28e20db50>),\n",
       " (485, <SelectBackward0 at 0x28e20d700>),\n",
       " (486, <SliceBackward0 at 0x28e20d490>),\n",
       " (487, <SliceBackward0 at 0x28e20d250>),\n",
       " (488, <PermuteBackward0 at 0x28e235fa0>),\n",
       " (489, <SliceBackward0 at 0x28e20ddc0>),\n",
       " (490, <SliceBackward0 at 0x28e20db20>),\n",
       " (491, <SelectBackward0 at 0x28e20d790>),\n",
       " (492, <SliceBackward0 at 0x28e20d460>),\n",
       " (493, <SliceBackward0 at 0x28e20d220>),\n",
       " (494, <PermuteBackward0 at 0x28e235040>),\n",
       " (495, <SliceBackward0 at 0x28e235a90>),\n",
       " (496, <SliceBackward0 at 0x28e2357f0>),\n",
       " (497, <SelectBackward0 at 0x28e235520>),\n",
       " (498, <SliceBackward0 at 0x28e235250>),\n",
       " (499, <SliceBackward0 at 0x288d4cc10>),\n",
       " (500, <PermuteBackward0 at 0x28e2252e0>),\n",
       " (501, <ExpandBackward0 at 0x28e235c40>),\n",
       " (502, <ReshapeAliasBackward0 at 0x28e235a30>),\n",
       " (503, <ExpandBackward0 at 0x28e235cd0>),\n",
       " (504, <ReshapeAliasBackward0 at 0x28e235a00>),\n",
       " (505, <BmmBackward0 at 0x28e235760>),\n",
       " (506, <UnsafeViewBackward0 at 0x28e235550>),\n",
       " (507, <DivBackward0 at 0x28e2351c0>),\n",
       " (508, <AddBackward0 at 0x288d4c190>),\n",
       " (509, <SoftmaxBackward0 at 0x28e225940>),\n",
       " (510, <ExpandBackward0 at 0x28e225160>),\n",
       " (511, <ViewBackward0 at 0x28e2257f0>),\n",
       " (512, <ExpandBackward0 at 0x28e225af0>),\n",
       " (513, <ReshapeAliasBackward0 at 0x28e225760>),\n",
       " (514, <BmmBackward0 at 0x28da44640>),\n",
       " (515, <UnsafeViewBackward0 at 0x28e2128e0>),\n",
       " (516, <PermuteBackward0 at 0x28e212ac0>),\n",
       " (517, <ReshapeAliasBackward0 at 0x28e212430>),\n",
       " (518, <torch.autograd.function.IndexFirstAxisBackward at 0x28e3b7b40>),\n",
       " (519, <ViewBackward0 at 0x28e212040>),\n",
       " (520, <torch.autograd.function.LRPCheckpointBackward at 0x28e3b7c40>),\n",
       " (521, <TBackward0 at 0x28e212d00>),\n",
       " (522, <AddmmBackward0 at 0x28e212a30>),\n",
       " (523, <AddBackward0 at 0x28e212c40>),\n",
       " (524, <NativeLayerNormBackward0 at 0x28e212640>),\n",
       " (525, <TBackward0 at 0x28e212220>),\n",
       " (526, <MmBackward0 at 0x28e212070>),\n",
       " (527, <SliceBackward0 at 0x28e212100>),\n",
       " (528, <SliceBackward0 at 0x28e212d60>),\n",
       " (529, <SliceBackward0 at 0x28e212d30>),\n",
       " (530, <SliceBackward0 at 0x28e212a60>),\n",
       " (531, <GeluBackward0 at 0x28e212e50>),\n",
       " (532, <MulBackward0 at 0x28e212fd0>),\n",
       " (533, <TBackward0 at 0x28e212fa0>),\n",
       " (534, <AddmmBackward0 at 0x28e212670>),\n",
       " (535, <AddBackward0 at 0x28e2152e0>),\n",
       " (536, <NativeLayerNormBackward0 at 0x28e2159d0>),\n",
       " (537, <TBackward0 at 0x28e235c70>),\n",
       " (538, <AddmmBackward0 at 0x28e2359a0>),\n",
       " (539, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28e3b7d40>),\n",
       " (540, <ViewBackward0 at 0x28e2354c0>),\n",
       " (541, <ViewBackward0 at 0x28e2351f0>),\n",
       " (542, <SliceBackward0 at 0x28e20d1f0>),\n",
       " (543, <SliceBackward0 at 0x28e235f40>),\n",
       " (544, <SelectBackward0 at 0x28e235c10>),\n",
       " (545, <SliceBackward0 at 0x28e235940>),\n",
       " (546, <SliceBackward0 at 0x28e235700>),\n",
       " (547, <PermuteBackward0 at 0x28e235460>),\n",
       " (548, <SliceBackward0 at 0x28e20d1c0>),\n",
       " (549, <SliceBackward0 at 0x28e235fd0>),\n",
       " (550, <SelectBackward0 at 0x28e235be0>),\n",
       " (551, <SliceBackward0 at 0x28e2359d0>),\n",
       " (552, <SliceBackward0 at 0x28e235790>),\n",
       " (553, <PermuteBackward0 at 0x28e2354f0>),\n",
       " (554, <SliceBackward0 at 0x288d4cfa0>),\n",
       " (555, <SliceBackward0 at 0x28e225970>),\n",
       " (556, <SelectBackward0 at 0x28e225340>),\n",
       " (557, <SliceBackward0 at 0x28e225fa0>),\n",
       " (558, <SliceBackward0 at 0x28da44550>),\n",
       " (559, <PermuteBackward0 at 0x28e2128b0>),\n",
       " (560, <ExpandBackward0 at 0x28e235190>),\n",
       " (561, <ReshapeAliasBackward0 at 0x28e225e80>),\n",
       " (562, <ExpandBackward0 at 0x28e235160>),\n",
       " (563, <ReshapeAliasBackward0 at 0x28e2252b0>),\n",
       " (564, <BmmBackward0 at 0x28e225700>),\n",
       " (565, <UnsafeViewBackward0 at 0x28e225580>),\n",
       " (566, <DivBackward0 at 0x28e225610>),\n",
       " (567, <AddBackward0 at 0x28da448e0>),\n",
       " (568, <SoftmaxBackward0 at 0x28e212880>),\n",
       " (569, <ExpandBackward0 at 0x28e212610>),\n",
       " (570, <ViewBackward0 at 0x28e2123d0>),\n",
       " (571, <ExpandBackward0 at 0x28e212a90>),\n",
       " (572, <ReshapeAliasBackward0 at 0x28e212400>),\n",
       " (573, <BmmBackward0 at 0x28e2121f0>),\n",
       " (574, <UnsafeViewBackward0 at 0x28e212130>),\n",
       " (575, <PermuteBackward0 at 0x28e212d90>),\n",
       " (576, <ReshapeAliasBackward0 at 0x28e212e80>),\n",
       " (577, <torch.autograd.function.IndexFirstAxisBackward at 0x28e3b7e40>),\n",
       " (578, <ViewBackward0 at 0x28e2120a0>),\n",
       " (579, <torch.autograd.function.LRPCheckpointBackward at 0x28da3a040>),\n",
       " (580, <TBackward0 at 0x28e215370>),\n",
       " (581, <AddmmBackward0 at 0x28e2159a0>),\n",
       " (582, <AddBackward0 at 0x28e215ac0>),\n",
       " (583, <NativeLayerNormBackward0 at 0x28e215c10>),\n",
       " (584, <TBackward0 at 0x28e2120d0>),\n",
       " (585, <MmBackward0 at 0x28e2126a0>),\n",
       " (586, <SliceBackward0 at 0x28e212730>),\n",
       " (587, <SliceBackward0 at 0x28e215430>),\n",
       " (588, <SliceBackward0 at 0x28e2153a0>),\n",
       " (589, <SliceBackward0 at 0x28e215a30>),\n",
       " (590, <GeluBackward0 at 0x28e215a00>),\n",
       " (591, <MulBackward0 at 0x28e215b20>),\n",
       " (592, <TBackward0 at 0x28e215b50>),\n",
       " (593, <AddmmBackward0 at 0x28e215be0>),\n",
       " (594, <AddBackward0 at 0x28e215d30>),\n",
       " (595, <NativeLayerNormBackward0 at 0x28e215dc0>),\n",
       " (596, <TBackward0 at 0x28e235100>),\n",
       " (597, <AddmmBackward0 at 0x28e225040>),\n",
       " (598, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28da3a140>),\n",
       " (599, <ViewBackward0 at 0x28e2253a0>),\n",
       " (600, <ViewBackward0 at 0x28e2253d0>),\n",
       " (601, <SliceBackward0 at 0x28e2356a0>),\n",
       " (602, <SliceBackward0 at 0x28e235400>),\n",
       " (603, <SelectBackward0 at 0x28e2350a0>),\n",
       " (604, <SliceBackward0 at 0x28e225b20>),\n",
       " (605, <SliceBackward0 at 0x28e225550>),\n",
       " (606, <PermuteBackward0 at 0x28e2250a0>),\n",
       " (607, <SliceBackward0 at 0x28e235730>),\n",
       " (608, <SliceBackward0 at 0x28e235490>),\n",
       " (609, <SelectBackward0 at 0x28e235130>),\n",
       " (610, <SliceBackward0 at 0x28e225100>),\n",
       " (611, <SliceBackward0 at 0x28e225cd0>),\n",
       " (612, <PermuteBackward0 at 0x28e225370>),\n",
       " (613, <SliceBackward0 at 0x28da44b20>),\n",
       " (614, <SliceBackward0 at 0x28e212850>),\n",
       " (615, <SelectBackward0 at 0x28e2125e0>),\n",
       " (616, <SliceBackward0 at 0x28e2123a0>),\n",
       " (617, <SliceBackward0 at 0x28e2121c0>),\n",
       " (618, <PermuteBackward0 at 0x28e2129d0>),\n",
       " (619, <ExpandBackward0 at 0x28da449a0>),\n",
       " (620, <ReshapeAliasBackward0 at 0x28da44df0>),\n",
       " (621, <ExpandBackward0 at 0x28e2259d0>),\n",
       " (622, <ReshapeAliasBackward0 at 0x28da44af0>),\n",
       " (623, <BmmBackward0 at 0x28e212820>),\n",
       " (624, <UnsafeViewBackward0 at 0x28e2125b0>),\n",
       " (625, <DivBackward0 at 0x28e212370>),\n",
       " (626, <AddBackward0 at 0x28e212190>),\n",
       " (627, <SoftmaxBackward0 at 0x28e212c10>),\n",
       " (628, <ExpandBackward0 at 0x28e212df0>),\n",
       " (629, <ViewBackward0 at 0x28e212ee0>),\n",
       " (630, <ExpandBackward0 at 0x28e212dc0>),\n",
       " (631, <ReshapeAliasBackward0 at 0x28e212eb0>),\n",
       " (632, <BmmBackward0 at 0x28e212f10>),\n",
       " (633, <UnsafeViewBackward0 at 0x28e2151f0>),\n",
       " (634, <PermuteBackward0 at 0x28e215400>),\n",
       " (635, <ReshapeAliasBackward0 at 0x28e215a90>),\n",
       " (636, <torch.autograd.function.IndexFirstAxisBackward at 0x28da3a240>),\n",
       " (637, <ViewBackward0 at 0x28e215c70>),\n",
       " (638, <torch.autograd.function.LRPCheckpointBackward at 0x28da3a340>),\n",
       " (639, <TBackward0 at 0x28e215d00>),\n",
       " (640, <AddmmBackward0 at 0x28e215e50>),\n",
       " (641, <AddBackward0 at 0x28e215f10>),\n",
       " (642, <NativeLayerNormBackward0 at 0x28e215910>),\n",
       " (643, <TBackward0 at 0x28e215bb0>),\n",
       " (644, <MmBackward0 at 0x28e215c40>),\n",
       " (645, <SliceBackward0 at 0x28e215cd0>),\n",
       " (646, <SliceBackward0 at 0x28e215d60>),\n",
       " (647, <SliceBackward0 at 0x28e215d90>),\n",
       " (648, <SliceBackward0 at 0x28e215e20>),\n",
       " (649, <GeluBackward0 at 0x28e215eb0>),\n",
       " (650, <MulBackward0 at 0x28e215f70>),\n",
       " (651, <TBackward0 at 0x28e215ee0>),\n",
       " (652, <AddmmBackward0 at 0x28e215880>),\n",
       " (653, <AddBackward0 at 0x28e2157c0>),\n",
       " (654, <NativeLayerNormBackward0 at 0x28e215520>),\n",
       " (655, <TBackward0 at 0x28da44a60>),\n",
       " (656, <AddmmBackward0 at 0x28da44b50>),\n",
       " (657, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28da3a440>),\n",
       " (658, <ViewBackward0 at 0x28e212580>),\n",
       " (659, <ViewBackward0 at 0x28e212340>),\n",
       " (660, <SliceBackward0 at 0x28e225220>),\n",
       " (661, <SliceBackward0 at 0x28e225430>),\n",
       " (662, <SelectBackward0 at 0x28da44250>),\n",
       " (663, <SliceBackward0 at 0x28da449d0>),\n",
       " (664, <SliceBackward0 at 0x28e212760>),\n",
       " (665, <PermuteBackward0 at 0x28e212520>),\n",
       " (666, <SliceBackward0 at 0x28e225f10>),\n",
       " (667, <SliceBackward0 at 0x28e225730>),\n",
       " (668, <SelectBackward0 at 0x28da44eb0>),\n",
       " (669, <SliceBackward0 at 0x28da44ca0>),\n",
       " (670, <SliceBackward0 at 0x28e2127f0>),\n",
       " (671, <PermuteBackward0 at 0x28e212550>),\n",
       " (672, <SliceBackward0 at 0x28e212160>),\n",
       " (673, <SliceBackward0 at 0x28e212c70>),\n",
       " (674, <SelectBackward0 at 0x28e212940>),\n",
       " (675, <SliceBackward0 at 0x28e212f40>),\n",
       " (676, <SliceBackward0 at 0x28e212790>),\n",
       " (677, <PermuteBackward0 at 0x28e2151c0>),\n",
       " (678, <ExpandBackward0 at 0x28e2122e0>),\n",
       " (679, <ReshapeAliasBackward0 at 0x28e212bb0>),\n",
       " (680, <ExpandBackward0 at 0x28e212310>),\n",
       " (681, <ReshapeAliasBackward0 at 0x28e212be0>),\n",
       " (682, <BmmBackward0 at 0x28e212ca0>),\n",
       " (683, <UnsafeViewBackward0 at 0x28e212970>),\n",
       " (684, <DivBackward0 at 0x28e212f70>),\n",
       " (685, <AddBackward0 at 0x28e2127c0>),\n",
       " (686, <SoftmaxBackward0 at 0x28e215250>),\n",
       " (687, <ExpandBackward0 at 0x28e215940>),\n",
       " (688, <ViewBackward0 at 0x28e215af0>),\n",
       " (689, <ExpandBackward0 at 0x28e215970>),\n",
       " (690, <ReshapeAliasBackward0 at 0x28e215a60>),\n",
       " (691, <BmmBackward0 at 0x28e215b80>),\n",
       " (692, <UnsafeViewBackward0 at 0x28e215ca0>),\n",
       " (693, <PermuteBackward0 at 0x28e215df0>),\n",
       " (694, <ReshapeAliasBackward0 at 0x28e215e80>),\n",
       " (695, <torch.autograd.function.IndexFirstAxisBackward at 0x28da3a540>),\n",
       " (696, <ViewBackward0 at 0x28e2158b0>),\n",
       " (697, <torch.autograd.function.LRPCheckpointBackward at 0x28da3a640>),\n",
       " (698, <TBackward0 at 0x28e2157f0>),\n",
       " (699, <AddmmBackward0 at 0x28da11520>),\n",
       " (700, <AddBackward0 at 0x28e2150a0>),\n",
       " (701, <NativeLayerNormBackward0 at 0x28e215460>),\n",
       " (702, <TBackward0 at 0x28e2158e0>),\n",
       " (703, <MmBackward0 at 0x28e215820>),\n",
       " (704, <SliceBackward0 at 0x28e215850>),\n",
       " (705, <SliceBackward0 at 0x28e215700>),\n",
       " (706, <SliceBackward0 at 0x28e215760>),\n",
       " (707, <SliceBackward0 at 0x28e215730>),\n",
       " (708, <GeluBackward0 at 0x28e215130>),\n",
       " (709, <MulBackward0 at 0x28e215040>),\n",
       " (710, <TBackward0 at 0x28e2150d0>),\n",
       " (711, <AddmmBackward0 at 0x28e215550>),\n",
       " (712, <AddBackward0 at 0x28e2155b0>),\n",
       " (713, <NativeLayerNormBackward0 at 0x28e215070>),\n",
       " (714, <torch.autograd.function.IndexPutFirstAxisBackward at 0x28da3a740>),\n",
       " (715, <ViewBackward0 at 0x28e2154f0>),\n",
       " (716, <AccumulateGrad at 0x177dc0040>),\n",
       " (717, <AccumulateGrad at 0x1774380a0>),\n",
       " (718, <AccumulateGrad at 0x177438160>),\n",
       " (719, <AccumulateGrad at 0x177dc0190>),\n",
       " (720, <AccumulateGrad at 0x177438250>),\n",
       " (721, <AccumulateGrad at 0x1774382e0>),\n",
       " (722, <AccumulateGrad at 0x1774383a0>),\n",
       " (723, <AccumulateGrad at 0x177dc0400>),\n",
       " (724, <AccumulateGrad at 0x177dc04c0>),\n",
       " (725, <AccumulateGrad at 0x177438580>),\n",
       " (726, <AccumulateGrad at 0x1774385b0>),\n",
       " (727, <AccumulateGrad at 0x177438610>),\n",
       " (728, <AccumulateGrad at 0x1774a0670>),\n",
       " (729, <AccumulateGrad at 0x177438700>),\n",
       " (730, <AccumulateGrad at 0x177438790>),\n",
       " (731, <AccumulateGrad at 0x177438880>),\n",
       " (732, <AccumulateGrad at 0x177438a00>),\n",
       " (733, <AccumulateGrad at 0x177438a30>),\n",
       " (734, <AccumulateGrad at 0x177438a60>),\n",
       " (735, <AccumulateGrad at 0x177438c10>),\n",
       " (736, <AccumulateGrad at 0x177438c70>),\n",
       " (737, <AccumulateGrad at 0x177438d60>),\n",
       " (738, <AccumulateGrad at 0x177438fd0>),\n",
       " (739, <AccumulateGrad at 0x177449070>),\n",
       " (740, <AccumulateGrad at 0x177599070>),\n",
       " (741, <AccumulateGrad at 0x1774490a0>),\n",
       " (742, <AccumulateGrad at 0x177599130>),\n",
       " (743, <AccumulateGrad at 0x177dc9130>),\n",
       " (744, <AccumulateGrad at 0x177599160>),\n",
       " (745, <AccumulateGrad at 0x177dc9160>),\n",
       " (746, <AccumulateGrad at 0x177449190>),\n",
       " (747, <AccumulateGrad at 0x1774492e0>),\n",
       " (748, <AccumulateGrad at 0x1775993a0>),\n",
       " (749, <AccumulateGrad at 0x177dc93a0>),\n",
       " (750, <AccumulateGrad at 0x177599490>),\n",
       " (751, <AccumulateGrad at 0x1774494c0>),\n",
       " (752, <AccumulateGrad at 0x177449550>),\n",
       " (753, <AccumulateGrad at 0x177449580>),\n",
       " (754, <AccumulateGrad at 0x177dc95b0>),\n",
       " (755, <AccumulateGrad at 0x1775996a0>),\n",
       " (756, <AccumulateGrad at 0x177599760>),\n",
       " (757, <AccumulateGrad at 0x177599790>),\n",
       " (758, <AccumulateGrad at 0x15a211820>),\n",
       " (759, <AccumulateGrad at 0x177599820>),\n",
       " (760, <AccumulateGrad at 0x15a211940>),\n",
       " (761, <AccumulateGrad at 0x1775999a0>),\n",
       " (762, <AccumulateGrad at 0x177599a60>),\n",
       " (763, <AccumulateGrad at 0x177dc9a90>),\n",
       " (764, <AccumulateGrad at 0x177dc9c40>),\n",
       " (765, <AccumulateGrad at 0x177599d00>),\n",
       " (766, <AccumulateGrad at 0x177599dc0>),\n",
       " (767, <AccumulateGrad at 0x177599df0>),\n",
       " (768, <AccumulateGrad at 0x1775a2070>),\n",
       " (769, <AccumulateGrad at 0x177582130>),\n",
       " (770, <AccumulateGrad at 0x1775a2160>),\n",
       " (771, <AccumulateGrad at 0x1775a2370>),\n",
       " (772, <AccumulateGrad at 0x1775a2430>),\n",
       " (773, <AccumulateGrad at 0x177582460>),\n",
       " (774, <AccumulateGrad at 0x1775a2460>),\n",
       " (775, <AccumulateGrad at 0x1775a24f0>),\n",
       " (776, <AccumulateGrad at 0x1775a2670>),\n",
       " (777, <AccumulateGrad at 0x1775a2730>),\n",
       " (778, <AccumulateGrad at 0x1041ba790>),\n",
       " (779, <AccumulateGrad at 0x1041ba7c0>),\n",
       " (780, <AccumulateGrad at 0x1775827f0>),\n",
       " (781, <AccumulateGrad at 0x177582820>),\n",
       " (782, <AccumulateGrad at 0x1041ba940>),\n",
       " (783, <AccumulateGrad at 0x1775a29d0>),\n",
       " (784, <AccumulateGrad at 0x1775a2a90>),\n",
       " (785, <AccumulateGrad at 0x1775a2ac0>),\n",
       " (786, <AccumulateGrad at 0x177582be0>),\n",
       " (787, <AccumulateGrad at 0x1775a2d00>),\n",
       " (788, <AccumulateGrad at 0x1775a2df0>),\n",
       " (789, <AccumulateGrad at 0x1775a3040>),\n",
       " (790, <AccumulateGrad at 0x177433100>),\n",
       " (791, <AccumulateGrad at 0x1775a3100>),\n",
       " (792, <AccumulateGrad at 0x1774332b0>),\n",
       " (793, <AccumulateGrad at 0x1775a33a0>),\n",
       " (794, <AccumulateGrad at 0x1774333d0>),\n",
       " (795, <AccumulateGrad at 0x1775a3460>),\n",
       " (796, <AccumulateGrad at 0x1775a3490>),\n",
       " (797, <AccumulateGrad at 0x1775a36d0>),\n",
       " (798, <AccumulateGrad at 0x15a76b730>),\n",
       " (799, <AccumulateGrad at 0x1775a37c0>),\n",
       " (800, <AccumulateGrad at 0x1775a39d0>),\n",
       " (801, <AccumulateGrad at 0x177433a60>),\n",
       " (802, <AccumulateGrad at 0x177433a90>),\n",
       " (803, <AccumulateGrad at 0x1775a3a90>),\n",
       " (804, <AccumulateGrad at 0x177433ac0>),\n",
       " (805, <AccumulateGrad at 0x1775a3ac0>),\n",
       " (806, <AccumulateGrad at 0x1775a3b50>),\n",
       " (807, <AccumulateGrad at 0x1775a3cd0>),\n",
       " (808, <AccumulateGrad at 0x1775a3d90>),\n",
       " (809, <AccumulateGrad at 0x177433f70>),\n",
       " (810, <AccumulateGrad at 0x177dc4040>),\n",
       " (811, <AccumulateGrad at 0x177dc4100>),\n",
       " (812, <AccumulateGrad at 0x177dc4130>),\n",
       " (813, <AccumulateGrad at 0x177dc41c0>),\n",
       " (814, <AccumulateGrad at 0x1774142e0>),\n",
       " (815, <AccumulateGrad at 0x177dc4340>),\n",
       " (816, <AccumulateGrad at 0x177dc4400>),\n",
       " (817, <AccumulateGrad at 0x177dc4670>),\n",
       " (818, <AccumulateGrad at 0x1774146d0>),\n",
       " (819, <AccumulateGrad at 0x1774147c0>),\n",
       " (820, <AccumulateGrad at 0x177dc4940>),\n",
       " (821, <AccumulateGrad at 0x177dc4a00>),\n",
       " (822, <AccumulateGrad at 0x177dc4c40>),\n",
       " (823, <AccumulateGrad at 0x177dc4c70>),\n",
       " (824, <AccumulateGrad at 0x177dc4d00>),\n",
       " (825, <AccumulateGrad at 0x177dc4e80>),\n",
       " (826, <AccumulateGrad at 0x17740d3a0>),\n",
       " (827, <AccumulateGrad at 0x17740d490>),\n",
       " (828, <AccumulateGrad at 0x17740d550>),\n",
       " (829, <AccumulateGrad at 0x17740d580>),\n",
       " (830, <AccumulateGrad at 0x17740d8b0>),\n",
       " (831, <AccumulateGrad at 0x17740d940>),\n",
       " (832, <AccumulateGrad at 0x17740d970>),\n",
       " (833, <AccumulateGrad at 0x17740db80>),\n",
       " (834, <AccumulateGrad at 0x17740dbb0>),\n",
       " (835, <AccumulateGrad at 0x17740dca0>),\n",
       " (836, <AccumulateGrad at 0x17740df70>),\n",
       " (837, <AccumulateGrad at 0x17759e070>),\n",
       " (838, <AccumulateGrad at 0x17759e130>),\n",
       " (839, <AccumulateGrad at 0x17759e160>),\n",
       " (840, <AccumulateGrad at 0x17759e1f0>),\n",
       " (841, <AccumulateGrad at 0x17759e370>),\n",
       " (842, <AccumulateGrad at 0x17759e430>),\n",
       " (843, <AccumulateGrad at 0x17759e6d0>),\n",
       " (844, <AccumulateGrad at 0x17759e790>),\n",
       " (845, <AccumulateGrad at 0x17759e7c0>),\n",
       " (846, <AccumulateGrad at 0x17759ea00>),\n",
       " (847, <AccumulateGrad at 0x17759eaf0>),\n",
       " (848, <AccumulateGrad at 0x17759ed00>),\n",
       " (849, <AccumulateGrad at 0x17759edc0>),\n",
       " (850, <AccumulateGrad at 0x17759edf0>),\n",
       " (851, <AccumulateGrad at 0x17759ee80>)]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(visited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ca910056-cec9-4f95-85b0-f606f23f954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_autograd_function_id',\n",
       " '_bw_module',\n",
       " '_compiled_autograd_backward_state',\n",
       " '_compiled_autograd_key',\n",
       " '_forward_cls',\n",
       " '_get_compiled_autograd_symints',\n",
       " '_input_metadata',\n",
       " '_materialize_non_diff_grads',\n",
       " '_raw_saved_tensors',\n",
       " '_register_hook',\n",
       " '_register_hook_dict',\n",
       " '_sequence_nr',\n",
       " '_set_sequence_nr',\n",
       " 'apply',\n",
       " 'apply_jvp',\n",
       " 'dirty_tensors',\n",
       " 'mark_dirty',\n",
       " 'mark_non_differentiable',\n",
       " 'mark_shared_storage',\n",
       " 'materialize_grads',\n",
       " 'maybe_clear_saved_tensors',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'needs_input_grad',\n",
       " 'next_functions',\n",
       " 'non_differentiable',\n",
       " 'register_hook',\n",
       " 'register_prehook',\n",
       " 'requires_grad',\n",
       " 'save_for_backward',\n",
       " 'save_for_forward',\n",
       " 'saved_for_forward',\n",
       " 'saved_tensors',\n",
       " 'saved_variables',\n",
       " 'set_materialize_grads',\n",
       " 'to_save']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visited[107])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9851049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For denominator stability in relevance distribution\n",
    "epsilon = 10e-6\n",
    "\n",
    "def renormalize_epsilon(rz, rx, ry):\n",
    "    # Renormalizes output relevances after dividing by a denominator with epsilon added to preserve conservation\n",
    "    scale = rz / (rx + ry)\n",
    "    return rx * scale, ry * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "51abf176-b5df-4314-a419-2579a6594290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddBackwardPromise:\n",
    "    def __init__(self, promise, idx):\n",
    "        # promise: shared data between the promise origin and both branches.\n",
    "        # idx: specifies which argument/operand the branch is looking for.\n",
    "        # fwd: applies all operations to the operand found from a branch to the origin of the promise.\n",
    "        # bwd: applies all operations to the relevance of the operand from the origin of the promise\n",
    "        #   to the end of the branch, possibly in steps if one or more Checkpoints were on the branch.\n",
    "        #   Structure: [ (checkpoint1, fcn_to_get_from_origin_to_checkpoint1),\n",
    "        #                (checkpoint2, fcn_to_get_from_checkpoint1_to_checkpoint2),\n",
    "        #                ...\n",
    "        #                (None, fcn_to_get_from_last_checkpoint_to_curnode) ]\n",
    "        #   So you should apply from left to right, but the inner functions themselves nest right to left.\n",
    "        # fwd_shape: used as target shape for shape-modifying operations in fwd\n",
    "        self.promise = promise\n",
    "        self.parent = promise[\"parent\"]\n",
    "        self.children = None # Will be set to list[AddBackwardPromise] if further nested AddBackward Nodes are found.\n",
    "        self.idx = idx\n",
    "        self.fwd = lambda x: x\n",
    "        self.bwd = [ (None, lambda x: x) ] # This will chain in case we come across a Checkpoint partway through\n",
    "        self.fwd_shape = promise[\"rout\"].shape # This will update after a shape-modifying operation is added to fwd\n",
    "        self.other_branch = None\n",
    "\n",
    "    def nest_fwd(self, next_f):\n",
    "        # Nests a new operation for recovering the operand for the promise origin\n",
    "        self.fwd = lambda x: self.fwd(next_f(x))\n",
    "\n",
    "    def checkpoint(self, new_checkpoint):\n",
    "        # Marks a checkpoint in the backwards op chain and opens a new chain after the checkpoint\n",
    "        self.bwd[-1] = (new_checkpoint, self.bwd[-1][1])\n",
    "        self.bwd.append((None, lambda x: x))\n",
    "\n",
    "    def nest_bwd(self, next_f):\n",
    "        # Stacks on a new operation for transforming the promised relevance back down the branch\n",
    "        last_checkpoint, most_recent_f = self.bwd[-1] # last_checkpoint is actually always None here\n",
    "        self.bwd[-1] = (last_checkpoint, lambda x: next_f(most_recent_f(x)))\n",
    "\n",
    "    @property\n",
    "    def ready(self):\n",
    "        return self.promise[\"ready\"]\n",
    "\n",
    "    @property\n",
    "    def complete(self):\n",
    "        # Flags if the promise is done all forward and backward execution\n",
    "        # If the promise is complete and has children, it will have set its children's rout value to its bwd(rin)\n",
    "        # result. So the children need only check if parent.complete is True to begin their own exec_bwd().\n",
    "        return self.promise[\"complete\"]\n",
    "\n",
    "    @property\n",
    "    def arg1(self):\n",
    "        return self.promise[\"args\"][0] # TODO: see if we really need both of these or just the arg for the branch\n",
    "\n",
    "    @property\n",
    "    def arg2(self):\n",
    "        return self.promise[\"args\"][1]\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.fwd_shape\n",
    "\n",
    "    @property\n",
    "    def rin(self):\n",
    "        return self.promise[\"rins\"][self.idx]\n",
    "\n",
    "    @property\n",
    "    def rout(self):\n",
    "        return self.promise[\"rout\"]\n",
    "\n",
    "    def set_rout(self, new_rout):\n",
    "        self.promise[\"rout\"] = new_rout\n",
    "\n",
    "    def exec_bwd(self):\n",
    "        # Perform each saved backward execution chain to propagate relevance back down the branch.\n",
    "        # Save values for any checkpoints marked along the path and return them with their respective checkpoints.\n",
    "        assert(self.ready and (self.parent is None or self.parent.complete),\n",
    "               \"Promise backward execution was triggered before promise was ready or before parent promise was complete.\")\n",
    "        res = self.rin\n",
    "        checkpoints = []\n",
    "        for checkpoint, fcn in self.bwd:\n",
    "            res = fcn(res)\n",
    "            if checkpoint is not None:\n",
    "                checkpoints.append((checkpoint, res))\n",
    "        return checkpoints, res\n",
    "\n",
    "    def compute_rins(self):\n",
    "        # Compute base branch relevances based on sum of squares ratios.\n",
    "        assert(self.ready and (self.parent is None or self.parent.complete))\n",
    "        arg1, arg2 = self.promise[\"args\"]\n",
    "        r = self.promise[\"rout\"]\n",
    "        denom = arg1 ** 2 + arg2 ** 2 + epsilon\n",
    "        r1 = (arg1 ** 2 / denom) * r\n",
    "        r2 = (arg2 ** 2 / denom) * r\n",
    "        self.promise[\"rins\"][0], self.promise[\"rins\"][1] = renormalize_epsilon(r, r1, r2)\n",
    "\n",
    "    def trigger_promise_completion(self):\n",
    "        # This is only called once a promise receives its second argument.\n",
    "        assert(self.ready, \"Promise completion was triggered before promise was ready.\")\n",
    "        if self.parent is None or self.parent.complete:\n",
    "            # Either reached root of a promise tree, or we are in the exec_bwd call of a child of a completed promise.\n",
    "            self.compute_rins()\n",
    "            checkpoints1, res1 = self.exec_bwd()\n",
    "            checkpoints2, res2 = self.other_branch.exec_bwd()\n",
    "            # Save checkpoint relevances to their grad_fn metadatas to collect later.\n",
    "            for checkpoint, val in checkpoints1 + checkpoints2:\n",
    "                checkpoint.metadata[\"checkpoint_relevance\"] = val\n",
    "            self.complete = True\n",
    "\n",
    "            if self.children is not None:\n",
    "                # Now that we have calculated the end relevance_in of this branch, we can feed it to the children promises.\n",
    "                for child_promise in self.children:\n",
    "                    child_promise.set_rout(res1)\n",
    "                    child_promise.trigger_promise_completion()\n",
    "\n",
    "            if self.other_branch.children is not None:\n",
    "                # Do the same for the other branch in this promise. (I should really make Promise and Branch two different classes...)\n",
    "                for child_promise in self.other_branch.children:\n",
    "                    child_promise.set_rout(res2)\n",
    "                    child_promise.trigger_promise_completion()\n",
    "\n",
    "        else:\n",
    "            # If there is a parent promise, but it is not complete yet, we can now set its arg with this promise's result.\n",
    "            # This is what triggers the propagation of the arguments back to the root of the promise tree.\n",
    "            self.promise[\"parent\"].setarg(self.arg1 + self.arg2)\n",
    "\n",
    "    def setarg(self, value):\n",
    "        # Set the corresponding arg for this branch and check if the promise is ready\n",
    "        self.promise[\"args\"][self.idx] = self.fwd(value)\n",
    "        self.promise[\"ready\"] = all([ x is not None for x in self.promise[\"args\"] ])\n",
    "        if self.promise[\"ready\"]:\n",
    "            self.trigger_promise_completion()\n",
    "\n",
    "def AddBackwardProp(grad_fn, r):\n",
    "    # IMPORTANT: AddBackward0 does not actually store any operands of the addition, so we have\n",
    "    # to get a bit tricky.\n",
    "    # The idea is to return a \"promise\", a dict wrapped in a class which contains the outgoing relevance, and\n",
    "    # placeholders for the operands and their respective relevances.\n",
    "    # From what I know right now, AddBackward0 is the only math-op grad_fn that does this, so the hope is\n",
    "    # that we pass this promise down the graph, and we encounter one of:\n",
    "    #   1. AccumulateGrad or another math-op that we can get the result from\n",
    "    #   2. A function that follows the identity or uniform rule like GeluBackward0 or LayerNormBackward0\n",
    "    #   3. A mutation function like SliceBackward0 or ReshapeBackward0\n",
    "    #   4. (worst case) Another AddBackward0\n",
    "    # For case 2 and 3, we would have to keep an arbitrarily composable function which progressively\n",
    "    # nests the operations that must be done on the result, once it is found, to make it equivalent\n",
    "    # to the downstream addition operand. When we find a node with the result, we simply apply f(result)\n",
    "    # to get the actual operand for the original addition.\n",
    "    # However, we will also need to keep a similar function but for going backwards from the addition\n",
    "    # back to the result node, but this time for the relevance.\n",
    "    # If at this time, both operands have been found, compute and store the relevances for both in the\n",
    "    # promise. If not, move this node to the \n",
    "    # For case 4, we would simply have to nest a promise within the existing promise.\n",
    "    # So the only time this algorithm will branch is if there are multiple additions with no result-\n",
    "    # yielding grad_fn's in between.\n",
    "\n",
    "    promise = {\n",
    "        \"rout\": r,\n",
    "        \"args\": [None, None],\n",
    "        \"rins\": [None, None],\n",
    "        \"ready\": False,\n",
    "        \"complete\": False,\n",
    "        \"parent\": None,\n",
    "    }\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        promise[\"parent\"] = r\n",
    "        promise[\"rout\"] = torch.zeros(r.fwd_shape) # Placeholder for shape\n",
    "\n",
    "    promise1 = AddBackwardPromise(promise, 0)\n",
    "    promise2 = AddBackwardPromise(promise, 1)\n",
    "\n",
    "    promise1.other_branch = promise2\n",
    "    promise2.other_branch = promise1\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.children = [promise1, promise2]\n",
    "\n",
    "    grad_fn.metadata[\"promise\"] = promise\n",
    "\n",
    "    return promise1, promise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f53d6-6b27-4cd2-9052-8e7fbc3c84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling AddMmBackward0 is not the exact same as just AddBackward0. The calculation of the in-relevances\n",
    "# is slightly different because you need to consider the matmul after the addition is propagated.\n",
    "# AddMmBackward0 also has 3 inputs, rather than 2 as in AddBackward0, so they will not be easily\n",
    "# compatible with the current promise tree structure.\n",
    "# I created the promise and promise tree structure with the aim to not have to re-visit the promise\n",
    "# origin nodes after sending out the promises (we re-visit the promise tree nodes, but not the grad_fn\n",
    "# nodes themselves). AddMmBackward0 would add a good amount of extra work if we were to handle it with\n",
    "# promises, it would require a completely different promise completion handling sequence.\n",
    "# It would be much easier to simply decompose an AddMmBackward0 into an AddBackward0 and a MmBackward0\n",
    "# in our graph, then traverse using the normal AddBackward0 promises, where we can fill in the Mm side first.\n",
    "\n",
    "# Since the autograd Nodes are code-generated and not exposed to the torch API, we just redefine shell\n",
    "# classes for the ones we need to instantiate, with the fields we need according to the dir() of the\n",
    "# original classes.\n",
    "class AddBackward0:\n",
    "    def __init__(self, next_functions):\n",
    "        self.name = \"AddBackward0\"\n",
    "        self.next_functions = next_functions\n",
    "        self.metadata = {}\n",
    "\n",
    "class MmBackward0:\n",
    "    def __init__(self, next_functions, mat1, mat2):\n",
    "        self.name = \"MmBackward0\"\n",
    "        self.next_functions = next_functions\n",
    "        self._saved_self = mat1\n",
    "        self._saved_self_sym_sizes = mat1.shape\n",
    "        self._saved_mat2 = mat2\n",
    "        self._saved_mat2_sym_sizes = mat2.shape\n",
    "\n",
    "def decompose_addmmbackward(grad_fn):\n",
    "    # Assuming grad_fn is an instance of AddMmBackward, returns an AddBackward0 instance that is the parent\n",
    "    # of an MmBackward0 instance and the first function in grad_fn.next_functions.\n",
    "    # The MmBackward0 is then the parent of the last two functions in grad_fn.next_functions.\n",
    "    mm_fn = MmBackward0(grad_fn.next_functions[1:], grad_fn._saved_mat1, grad_fn._saved_mat2)\n",
    "    add_fn = AddBackward0((grad_fn.next_functions[0], (mm_fn, 0)))\n",
    "\n",
    "    return add_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a3ebc-d27e-4b2b-8a98-98f4dc8bfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "For all these functions, grad_fn is the autograd Node returned from traversing the autograd graph.\n",
    "r is the relevance tensor of the output of the given Node.\n",
    "\"\"\"\n",
    "\n",
    "def ViewBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        target_shape = r.fwd_shape\n",
    "        r.nest_fwd(lambda x: torch.view(x, target_shape))\n",
    "        r.nest_bwd(lambda x: torch.view(x, upstream_shape))\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return torch.view(r, upstream_shape)\n",
    "\n",
    "def UnsafeViewBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        target_shape = r.fwd_shape\n",
    "        r.nest_fwd(lambda x: torch.view(x, target_shape))\n",
    "        r.nest_bwd(lambda x: torch.view(x, upstream_shape))\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return torch.view(r, upstream_shape)\n",
    "\n",
    "def ReshapeBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        target_shape = r.fwd_shape\n",
    "        r.nest_fwd(lambda x: torch.reshape(x, target_shape))\n",
    "        r.nest_bwd(lambda x: torch.reshape(x, upstream_shape))\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return torch.reshape(r, grad_fn._saved_self_sym_sizes)\n",
    "\n",
    "def SliceBackwardProp(grad_fn, r):\n",
    "    # Assumes the index corresponding to _saved_start in the forward pass is non-negative.\n",
    "    # If it was negative-indexed, i.e. x[-i:] autograd saves the index as INT_MAX - i.\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    sliced_dim = grad_fn._saved_dim\n",
    "    start = grad_fn._saved_start # TODO: Come back to take care of the negative index case.\n",
    "    full_size = upstream_shape[sliced_dim]\n",
    "    end = start + r.shape[sliced_dim]\n",
    "\n",
    "    # We wish to pad r so that it becomes the correct size along the sliced dimension\n",
    "    pad = []\n",
    "    to_pad = [start, full_size - end]\n",
    "\n",
    "    # Iterate in reverse order, since F.pad() takes in dims from last to first,\n",
    "    # see https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.pad.html\n",
    "    # All dims other than sliced_dim should be 0, 0\n",
    "    for dim in range(len(upstream_shape) - 1, -1, -1):\n",
    "        pad += [0, 0] if dim != sliced_dim else to_pad\n",
    "    pad = tuple(pad)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(lambda x: torch.ops.aten.slice(x, sliced_dim, start, end))\n",
    "        r.nest_bwd(lambda x: F.pad(x, pad))\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return F.pad(r, pad)\n",
    "\n",
    "def IndexBackwardProp(grad_fn, r):\n",
    "    # An Index can be compound, unlike Slice, i.e. a[[0,1], [1,2]] is ONE Index op, whereas a[:,1:] is TWO Slice ops.\n",
    "    # This is because (in this case) the second Slice depends on the first. It's saying that from the result of\n",
    "    # the first slice, for each element, select index 1 from the first, and index 2 from the second (assuming of\n",
    "    # course that 1 and 2 are in bounds for each element returned by the first slice).\n",
    "    # Therefore, the length of the first Slice acts as an upper bound for the length of the Slices that succeed it.\n",
    "    # If you wanted it to select indices 1 and 2 for each resulting element, you would just use a Slice for the last\n",
    "    # dim instead of an Index.\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    \n",
    "    idxs = [ torch.tensor(x) if x is not None else None for x in grad_fn._saved_indices ]\n",
    "\n",
    "    def undoIndex(x):\n",
    "        out = torch.zeros(upstream_shape, dtype=x.dtype, device=x.device)\n",
    "        return torch.ops.aten.index_put(out, idxs, x)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(lambda x: torch.ops.aten.index(x, idxs))\n",
    "        r.nest_bwd(undoIndex)\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return undoIndex(r)\n",
    "            \n",
    "\n",
    "def SelectBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    dim = grad_fn._saved_dim\n",
    "    idx = grad_fn._saved_index\n",
    "\n",
    "    def undoSelect(x):\n",
    "        out = torch.zeros(upstream_shape, dtype=x.dtype, device=x.device)\n",
    "        x_expanded = torch.unsqueeze(x, dim)\n",
    "        out.select(dim, idx).copy_(x_expanded)\n",
    "        return out\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(lambda x: torch.select(x, dim, idx))\n",
    "        r.nest_bwd(undoSelect)\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "\n",
    "    return undoSelect(r)\n",
    "\n",
    "def TBackwardProp(grad_fn, r):\n",
    "    # Not sure why TBackward is different from TransposeBackward, but it seems like this is only\n",
    "    # in Linear layer matmuls on W for xW^T before Mm and Addmm operations.\n",
    "    assert(len(r.shape) == 2, \"Assumption was that matrix would be 2d Linear weights.\") # For now assume that it is only 2d matmuls for Linear layers.\n",
    "\n",
    "    transpose = lambda x: x.T\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(transpose)\n",
    "        r.nest_bwd(transpose)\n",
    "        new_shape = list(r.fwd_shape)\n",
    "        new_shape[0], new_shape[1] = new_shape[1], new_shape[0]\n",
    "        r.fwd_shape = tuple(new_shape)\n",
    "        return r\n",
    "\n",
    "    return transpose(r)\n",
    "\n",
    "def TransposeBackwardProp(grad_fn, r):\n",
    "    dim1 = grad_fn._saved_dim0\n",
    "    dim2 = grad_fn._saved_dim1\n",
    "\n",
    "    if dim1 == 2**32 - 2:\n",
    "        dim1 = -2\n",
    "    if dim2 == 2**32 - 1:\n",
    "        dim2 = -1\n",
    "\n",
    "    swapaxes = lambda x: torch.swapaxes(x, dim1, dim2)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(swapaxes)\n",
    "        r.nest_bwd(swapaxes)\n",
    "        new_shape = list(r.fwd_shape)\n",
    "        new_shape[dim1], new_shape[dim2] = new_shape[dim2], new_shape[dim1]\n",
    "        r.fwd_shape = tuple(new_shape)\n",
    "        return r\n",
    "    \n",
    "    return swapaxes(r)\n",
    "\n",
    "def PermuteBackwardProp(grad_fn, r):\n",
    "    dims = grad_fn._saved_dims\n",
    "    permute = lambda x: torch.permute(x, dims)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(permute)\n",
    "        r.nest_bwd(permute)\n",
    "        new_shape = list(r.fwd_shape)\n",
    "        for old_dim, new_dim in enumerate(dims):\n",
    "            new_shape[old_dim] = r.fwd_shape[new_dim]\n",
    "        r.fwd_shape = tuple(new_shape)\n",
    "        return r\n",
    "    return permute(r)\n",
    "\n",
    "def ExpandBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    downstream_shape = r.shape\n",
    "    assert(len(upstream_shape) == len(downstream_shape), \"Expand should not increase number of dimensions.\")\n",
    "\n",
    "    expand_input = [ dim2 if dim1 != dim2 else -1 for dim1, dim2 in zip(upstream_shape, downstream_shape) ]\n",
    "\n",
    "    def undoExpand(x):\n",
    "        for i, expand_dim in enumerate(expand_input):\n",
    "            if expand_dim != -1:\n",
    "                x = x.select(i, 0).unsqueeze(i)\n",
    "        return x\n",
    "\n",
    "    expand = lambda x: x.expand(*expand_input)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(expand)\n",
    "        r.nest_bwd(undoExpand)\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "\n",
    "    return undoExpand(r)\n",
    "\n",
    "def MulBackwardProp(grad_fn, r):\n",
    "    arg1 = grad_fn._saved_self\n",
    "    arg2 = grad_fn._saved_other\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        if arg1 is None:\n",
    "            r.nest_fwd(lambda x: x * arg2)\n",
    "        else:\n",
    "            r.setarg(arg1 * arg2)\n",
    "            if r.complete:\n",
    "                r = r.rin\n",
    "            else:\n",
    "                return None # Trigger requeue\n",
    "\n",
    "    if arg1 is None:\n",
    "        # Tensor-scalar product, disregard scalar\n",
    "        return r, 0.0\n",
    "\n",
    "    denom = arg1.abs() + arg2.abs() + epsilon\n",
    "    r1 = (arg1.abs() / denom) * r\n",
    "    r2 = (arg2.abs() / denom) * r\n",
    "\n",
    "    return renormalize_epsilon(r, r1, r2)\n",
    "\n",
    "def DivBackwardProp(grad_fn, r):\n",
    "    arg1 = grad_fn._saved_self\n",
    "    arg2 = grad_fn._saved_other\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        if arg1 is None:\n",
    "            r.nest_fwd(lambda x: x / arg2)\n",
    "        else:\n",
    "            r.setarg(arg1 / arg2)\n",
    "            if r.complete:\n",
    "                r = r.rin\n",
    "            else:\n",
    "                return None # Trigger requeue\n",
    "\n",
    "    if arg1 is None:\n",
    "        # Tensor-scalar product, disregard scalar\n",
    "        return r, 0.0\n",
    "\n",
    "    denom = arg1.abs() + (1 / arg2).abs() + epsilon\n",
    "    r1 = (arg1.abs() / denom) * r\n",
    "    r2 = ((1 / arg2).abs() / denom) * r\n",
    "\n",
    "    return renormalize_epsilon(r, r1, r2)\n",
    "\n",
    "def MmBackwardProp(grad_fn, r):\n",
    "    x = grad_fn._saved_mat1 # i j\n",
    "    weights = grad_fn._saved_mat2 # j k\n",
    "    z = torch.matmul(x, weights)\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.setarg(z)\n",
    "        if r.complete:\n",
    "            r = r.rin\n",
    "        else:\n",
    "            # If this is the first branch of the promise\n",
    "            return None # Make this trigger a requeue\n",
    "\n",
    "    i, j = x.shape\n",
    "    k = weights.shape[1]\n",
    "    intermediates = torch.einsum(\"ij, jk -> ijk\", x, weights)\n",
    "\n",
    "    z = z.unsqueeze(1).broadcast_to((i,j,k))\n",
    "\n",
    "    ratios = intermediates / z\n",
    "\n",
    "    # return relevance for input and relevance for weight\n",
    "    return ratios.sum(dim=2, keepdims=True) * r, ratios.sum(dim=0, keepdims=True) * r.T\n",
    "\n",
    "def BmmBackwardProp(grad_fn, r):\n",
    "    mat1 = grad_fn.saved_self\n",
    "    mat2 = grad_fn.saved_mat2\n",
    "    z = torch.matmul(mat1, mat2)\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.setarg(z)\n",
    "        if r.complete:\n",
    "            r = r.rin\n",
    "        else:\n",
    "            # If this is the first branch of the promise\n",
    "            return None # Make this trigger a requeue\n",
    "\n",
    "    b, i, j = mat1.shape\n",
    "    k = mat2.shape[-1]\n",
    "    intermediates = torch.einsum(\"bij, bjk -> bijk\", mat1, mat2)\n",
    "\n",
    "    z = z.unsqueeze(2).broadcast_to((b,i,j,k))\n",
    "\n",
    "    ratios = intermediates / z\n",
    "\n",
    "    # return relevance for mat1 and relevance for mat2\n",
    "    return ratios.sum(dim=2, keepdims=True) * r, ratios.sum(dim=1, keepdims=True) * r.T\n",
    "\n",
    "def NativeLayerNormBackwardProp(grad_fn, r):\n",
    "    # next_functions will correspond to input, weights, bias\n",
    "    # We only care about propagating through the input for LayerNorm.\n",
    "    return r, 0.0, 0.0\n",
    "\n",
    "def IdentityProp(grad_fn, r):\n",
    "    \"\"\"Placeholder for any missed operations, or general use for identity-rule operations.\"\"\"\n",
    "    return r\n",
    "    \n",
    "def AccumulateGradProp(grad_fn, r):\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.setarg(grad_fn.variable)\n",
    "    return 0.0\n",
    "\n",
    "def LRPCheckpointBackwardProp(grad_fn, r):\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.checkpoint(grad_fn)\n",
    "    else:\n",
    "        grad_fn.metadata[\"checkpoint_relevance\"] = r\n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "dd381d58-e580-4699-8f3c-2a03604c4442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 3072, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "start = 3072\n",
    "end = 6144\n",
    "to_pad = [start, 6144 - end]\n",
    "sliced_dim = 2\n",
    "pad = tuple(sum([ [0,0] if i != sliced_dim else to_pad for i in range(3, -1, -1) ], []))\n",
    "print(pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e4f1ff55-aee6-4e32-a0dd-68c669381033",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((1,17,3072,3))\n",
    "a.shape\n",
    "b = F.pad(a, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "004d4d1d-17bc-4699-9e63-9396f0d4ac99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited[:10].index(visited[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "64a23e69-3718-4da7-82c7-29e7d0964c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "out_adj = {}\n",
    "in_adj = {}\n",
    "\n",
    "root = hidden_states.grad_fn\n",
    "visited = set()\n",
    "fcns = [ [root] ]\n",
    "# idea: dynamically init relevance variables when branching occurs, assign them to the corresponding\n",
    "# downstream nodes they should belong to using next_functions and visited table. Requires 2 passes.\n",
    "# Perhaps need a last_saved_relevance for each node, in the case when a node is traversed more than once to accumulate relevance.\n",
    "# Need all incoming branches to land before we continue, else we need to compute the same downstream paths multiple times for\n",
    "# each incoming branch.\n",
    "# Modified DFS? Traverse down a path, creating all necessary relevance branches until a node with multiple in-edges is reached.\n",
    "# We will need a modified graph as well with in_children for each node to determine the above condition.\n",
    "\n",
    "# First pass will:\n",
    "# 1. Create in and out adjacency lists.\n",
    "# 2. Decompose AddMmBackward0's with AddBackward0 leading back to MmBackward0.\n",
    "while fcns:\n",
    "    new_fcns = []\n",
    "    for fcn_list in fcns:\n",
    "        for fcn in fcn_list:\n",
    "\n",
    "            if fcn is None or fcn in visited:\n",
    "                continue\n",
    "\n",
    "            if type(fcn).__name__ == \"AddMmBackward0\":\n",
    "                # Decompose the function into an Add + Mm, then re-assign its adjacencies.\n",
    "                decomposed_add = decompose_addmmbackward(fcn)\n",
    "                # Assign new Add's in-neighbours to the AddMm's in-neighbours.\n",
    "                in_adj[decomposed_add] = in_adj[fcn]\n",
    "                for in_neighbour in in_adj[fcn]:\n",
    "                    # Replace all out-edges going to the AddMm to point to the new Add.\n",
    "                    old_fcn_idx = out_adj[in_neighbour].index(fcn)\n",
    "                    out_adj[in_neighbour][old_fcn_idx] = decomposed_add\n",
    "                del in_adj[fcn]\n",
    "                fcn = decomposed_add\n",
    "\n",
    "            # Assign adjacencies\n",
    "            if fcn not in out_adj:\n",
    "                out_adj[fcn] = []\n",
    "            for (child, _) in fcn.next_functions:\n",
    "                out_adj[fcn].append(child)\n",
    "                if child not in in_adj:\n",
    "                    in_adj[child] = []\n",
    "                in_adj[child].append(fcn)\n",
    "\n",
    "            visited.add(fcn)\n",
    "\n",
    "            new_fcns.append([ fcn_tup[0] for fcn_tup in fcn.next_functions ])\n",
    "\n",
    "    # Iterate\n",
    "    fcns = new_fcns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1f317cab-d7e8-435f-8ed1-b95674160345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<ViewBackward0 object at 0x17757e100>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758c040>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758c040>: [<NativeLayerNormBackward0 object at 0x177461370>, None], <NativeLayerNormBackward0 object at 0x177461370>: [<AddBackward0 object at 0x177582f70>, <AccumulateGrad object at 0x177582be0>, <AccumulateGrad object at 0x1775827f0>], <AddBackward0 object at 0x177582f70>: [<AddmmBackward0 object at 0x177582a00>, <NativeLayerNormBackward0 object at 0x177582610>], <AccumulateGrad object at 0x177582be0>: [], <AccumulateGrad object at 0x1775827f0>: [], <AddmmBackward0 object at 0x177582a00>: [<AccumulateGrad object at 0x177582820>, <MulBackward0 object at 0x177582430>, <TBackward0 object at 0x177582640>], <NativeLayerNormBackward0 object at 0x177582610>: [<AddBackward0 object at 0x1775822b0>, <AccumulateGrad object at 0x177582460>, <AccumulateGrad object at 0x177582130>], <AccumulateGrad object at 0x177582820>: [], <MulBackward0 object at 0x177582430>: [<GeluBackward0 object at 0x177582250>, <SliceBackward0 object at 0x177582040>], <TBackward0 object at 0x177582640>: [<AccumulateGrad object at 0x1774a0670>], <AddBackward0 object at 0x1775822b0>: [<AddmmBackward0 object at 0x15b042f40>, <NativeLayerNormBackward0 object at 0x15b042ac0>], <AccumulateGrad object at 0x177582460>: [], <AccumulateGrad object at 0x177582130>: [], <GeluBackward0 object at 0x177582250>: [<SliceBackward0 object at 0x177414be0>], <SliceBackward0 object at 0x177582040>: [<SliceBackward0 object at 0x177414700>], <AccumulateGrad object at 0x1774a0670>: [], <AddmmBackward0 object at 0x15b042f40>: [<AccumulateGrad object at 0x1774147c0>, <ViewBackward0 object at 0x177414fa0>, <TBackward0 object at 0x177414820>], <NativeLayerNormBackward0 object at 0x15b042ac0>: [<AddBackward0 object at 0x177414040>, <AccumulateGrad object at 0x1774146d0>, <AccumulateGrad object at 0x1774142e0>], <SliceBackward0 object at 0x177414be0>: [<SliceBackward0 object at 0x1774146a0>], <SliceBackward0 object at 0x177414700>: [<MmBackward0 object at 0x1774142b0>], <AccumulateGrad object at 0x1774147c0>: [], <ViewBackward0 object at 0x177414fa0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758be40>], <TBackward0 object at 0x177414820>: [<AccumulateGrad object at 0x1041ba790>], <AddBackward0 object at 0x177414040>: [<AddmmBackward0 object at 0x1041ba850>, <NativeLayerNormBackward0 object at 0x1041ba430>], <AccumulateGrad object at 0x1774146d0>: [], <AccumulateGrad object at 0x1774142e0>: [], <SliceBackward0 object at 0x1774146a0>: [<MmBackward0 object at 0x1774142b0>], <MmBackward0 object at 0x1774142b0>: [<NativeLayerNormBackward0 object at 0x177582610>, <TBackward0 object at 0x1041ba880>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758be40>: [<ReshapeAliasBackward0 object at 0x1041ba640>, None], <AccumulateGrad object at 0x1041ba790>: [], <AddmmBackward0 object at 0x1041ba850>: [<AccumulateGrad object at 0x1041ba7c0>, <MulBackward0 object at 0x1041badf0>, <TBackward0 object at 0x1041ba520>], <NativeLayerNormBackward0 object at 0x1041ba430>: [<AddBackward0 object at 0x1041ba550>, <AccumulateGrad object at 0x1041ba940>, <AccumulateGrad object at 0x15a76b730>], <TBackward0 object at 0x1041ba880>: [<AccumulateGrad object at 0x15a211940>], <ReshapeAliasBackward0 object at 0x1041ba640>: [<PermuteBackward0 object at 0x15a211550>], <AccumulateGrad object at 0x1041ba7c0>: [], <MulBackward0 object at 0x1041badf0>: [<GeluBackward0 object at 0x15a211520>, <SliceBackward0 object at 0x15a2113d0>], <TBackward0 object at 0x1041ba520>: [<AccumulateGrad object at 0x15a211820>], <AddBackward0 object at 0x1041ba550>: [<AddmmBackward0 object at 0x15a2116d0>, <NativeLayerNormBackward0 object at 0x177438130>], <AccumulateGrad object at 0x1041ba940>: [], <AccumulateGrad object at 0x15a76b730>: [], <AccumulateGrad object at 0x15a211940>: [], <PermuteBackward0 object at 0x15a211550>: [<UnsafeViewBackward0 object at 0x1774388b0>], <GeluBackward0 object at 0x15a211520>: [<SliceBackward0 object at 0x177438190>], <SliceBackward0 object at 0x15a2113d0>: [<SliceBackward0 object at 0x177438220>], <AccumulateGrad object at 0x15a211820>: [], <AddmmBackward0 object at 0x15a2116d0>: [<AccumulateGrad object at 0x177438610>, <ViewBackward0 object at 0x177438f10>, <TBackward0 object at 0x177438670>], <NativeLayerNormBackward0 object at 0x177438130>: [<AddBackward0 object at 0x177438fa0>, <AccumulateGrad object at 0x177438fd0>, <AccumulateGrad object at 0x177438a60>], <UnsafeViewBackward0 object at 0x1774388b0>: [<BmmBackward0 object at 0x177438f70>], <SliceBackward0 object at 0x177438190>: [<SliceBackward0 object at 0x1774381c0>], <SliceBackward0 object at 0x177438220>: [<MmBackward0 object at 0x1774381f0>], <AccumulateGrad object at 0x177438610>: [], <ViewBackward0 object at 0x177438f10>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758bc40>], <TBackward0 object at 0x177438670>: [<AccumulateGrad object at 0x177438d60>], <AddBackward0 object at 0x177438fa0>: [<AddmmBackward0 object at 0x1774386a0>, <NativeLayerNormBackward0 object at 0x177438af0>], <AccumulateGrad object at 0x177438fd0>: [], <AccumulateGrad object at 0x177438a60>: [], <BmmBackward0 object at 0x177438f70>: [<ViewBackward0 object at 0x1774385e0>, <ReshapeAliasBackward0 object at 0x177438f40>], <SliceBackward0 object at 0x1774381c0>: [<MmBackward0 object at 0x1774381f0>], <MmBackward0 object at 0x1774381f0>: [<NativeLayerNormBackward0 object at 0x1041ba430>, <TBackward0 object at 0x1774386d0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758bc40>: [<ReshapeAliasBackward0 object at 0x177438ca0>, None], <AccumulateGrad object at 0x177438d60>: [], <AddmmBackward0 object at 0x1774386a0>: [<AccumulateGrad object at 0x177438c70>, <MulBackward0 object at 0x177438d00>, <TBackward0 object at 0x1774387c0>], <NativeLayerNormBackward0 object at 0x177438af0>: [<AddBackward0 object at 0x177438280>, <AccumulateGrad object at 0x177438250>, <AccumulateGrad object at 0x1774382e0>], <ViewBackward0 object at 0x1774385e0>: [<ExpandBackward0 object at 0x177438b50>], <ReshapeAliasBackward0 object at 0x177438f40>: [<ExpandBackward0 object at 0x177438910>], <TBackward0 object at 0x1774386d0>: [<AccumulateGrad object at 0x177438a30>], <ReshapeAliasBackward0 object at 0x177438ca0>: [<PermuteBackward0 object at 0x177438d90>], <AccumulateGrad object at 0x177438c70>: [], <MulBackward0 object at 0x177438d00>: [<GeluBackward0 object at 0x1774389d0>, <SliceBackward0 object at 0x177438550>], <TBackward0 object at 0x1774387c0>: [<AccumulateGrad object at 0x177438a00>], <AddBackward0 object at 0x177438280>: [<AddmmBackward0 object at 0x177438850>, <NativeLayerNormBackward0 object at 0x177438e20>], <AccumulateGrad object at 0x177438250>: [], <AccumulateGrad object at 0x1774382e0>: [], <ExpandBackward0 object at 0x177438b50>: [<SoftmaxBackward0 object at 0x177438e50>], <ExpandBackward0 object at 0x177438910>: [<PermuteBackward0 object at 0x177438d30>], <AccumulateGrad object at 0x177438a30>: [], <PermuteBackward0 object at 0x177438d90>: [<UnsafeViewBackward0 object at 0x177438df0>], <GeluBackward0 object at 0x1774389d0>: [<SliceBackward0 object at 0x177438ee0>], <SliceBackward0 object at 0x177438550>: [<SliceBackward0 object at 0x177438cd0>], <AccumulateGrad object at 0x177438a00>: [], <AddmmBackward0 object at 0x177438850>: [<AccumulateGrad object at 0x177438160>, <ViewBackward0 object at 0x1774380d0>, <TBackward0 object at 0x177438100>], <NativeLayerNormBackward0 object at 0x177438e20>: [<AddBackward0 object at 0x177438040>, <AccumulateGrad object at 0x1774380a0>, <AccumulateGrad object at 0x1774385b0>], <SoftmaxBackward0 object at 0x177438e50>: [<AddBackward0 object at 0x177438070>], <PermuteBackward0 object at 0x177438d30>: [<SliceBackward0 object at 0x177438640>], <UnsafeViewBackward0 object at 0x177438df0>: [<BmmBackward0 object at 0x1774382b0>], <SliceBackward0 object at 0x177438ee0>: [<SliceBackward0 object at 0x177438340>], <SliceBackward0 object at 0x177438cd0>: [<MmBackward0 object at 0x177438310>], <AccumulateGrad object at 0x177438160>: [], <ViewBackward0 object at 0x1774380d0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758ba40>], <TBackward0 object at 0x177438100>: [<AccumulateGrad object at 0x1774383a0>], <AddBackward0 object at 0x177438040>: [<AddmmBackward0 object at 0x177438370>, <NativeLayerNormBackward0 object at 0x177438430>], <AccumulateGrad object at 0x1774380a0>: [], <AccumulateGrad object at 0x1774385b0>: [], <AddBackward0 object at 0x177438070>: [<DivBackward0 object at 0x1774383d0>, None], <SliceBackward0 object at 0x177438640>: [<SliceBackward0 object at 0x177438490>], <BmmBackward0 object at 0x1774382b0>: [<ViewBackward0 object at 0x177438460>, <ReshapeAliasBackward0 object at 0x1774384f0>], <SliceBackward0 object at 0x177438340>: [<MmBackward0 object at 0x177438310>], <MmBackward0 object at 0x177438310>: [<NativeLayerNormBackward0 object at 0x177438af0>, <TBackward0 object at 0x1774384c0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758ba40>: [<ReshapeAliasBackward0 object at 0x177438400>, None], <AccumulateGrad object at 0x1774383a0>: [], <AddmmBackward0 object at 0x177438370>: [<AccumulateGrad object at 0x177438700>, <MulBackward0 object at 0x177438970>, <TBackward0 object at 0x177438730>], <NativeLayerNormBackward0 object at 0x177438430>: [<AddBackward0 object at 0x177438be0>, <AccumulateGrad object at 0x177438c10>, <AccumulateGrad object at 0x177438580>], <DivBackward0 object at 0x1774383d0>: [<UnsafeViewBackward0 object at 0x177438760>, None], <SliceBackward0 object at 0x177438490>: [<SelectBackward0 object at 0x177438820>], <ViewBackward0 object at 0x177438460>: [<ExpandBackward0 object at 0x177438a90>], <ReshapeAliasBackward0 object at 0x1774384f0>: [<ExpandBackward0 object at 0x1774387f0>], <TBackward0 object at 0x1774384c0>: [<AccumulateGrad object at 0x177438880>], <ReshapeAliasBackward0 object at 0x177438400>: [<PermuteBackward0 object at 0x177438bb0>], <AccumulateGrad object at 0x177438700>: [], <MulBackward0 object at 0x177438970>: [<GeluBackward0 object at 0x177438b80>, <SliceBackward0 object at 0x1774388e0>], <TBackward0 object at 0x177438730>: [<AccumulateGrad object at 0x177438790>], <AddBackward0 object at 0x177438be0>: [<AddmmBackward0 object at 0x177438520>, <NativeLayerNormBackward0 object at 0x177449790>], <AccumulateGrad object at 0x177438c10>: [], <AccumulateGrad object at 0x177438580>: [], <UnsafeViewBackward0 object at 0x177438760>: [<BmmBackward0 object at 0x177449af0>], <SelectBackward0 object at 0x177438820>: [<SliceBackward0 object at 0x177449820>], <ExpandBackward0 object at 0x177438a90>: [<SoftmaxBackward0 object at 0x177449a60>], <ExpandBackward0 object at 0x1774387f0>: [<PermuteBackward0 object at 0x1774498b0>], <AccumulateGrad object at 0x177438880>: [], <PermuteBackward0 object at 0x177438bb0>: [<UnsafeViewBackward0 object at 0x177449e80>], <GeluBackward0 object at 0x177438b80>: [<SliceBackward0 object at 0x177449760>], <SliceBackward0 object at 0x1774388e0>: [<SliceBackward0 object at 0x1774497c0>], <AccumulateGrad object at 0x177438790>: [], <AddmmBackward0 object at 0x177438520>: [<AccumulateGrad object at 0x177449190>, <ViewBackward0 object at 0x1774497f0>, <TBackward0 object at 0x177449040>], <NativeLayerNormBackward0 object at 0x177449790>: [<AddBackward0 object at 0x1774491c0>, <AccumulateGrad object at 0x1774490a0>, <AccumulateGrad object at 0x177449070>], <BmmBackward0 object at 0x177449af0>: [<ReshapeAliasBackward0 object at 0x177449100>, <ReshapeAliasBackward0 object at 0x1774490d0>], <SliceBackward0 object at 0x177449820>: [<SliceBackward0 object at 0x177449160>], <SoftmaxBackward0 object at 0x177449a60>: [<AddBackward0 object at 0x177449130>], <PermuteBackward0 object at 0x1774498b0>: [<SliceBackward0 object at 0x177449220>], <UnsafeViewBackward0 object at 0x177449e80>: [<BmmBackward0 object at 0x1774491f0>], <SliceBackward0 object at 0x177449760>: [<SliceBackward0 object at 0x177449280>], <SliceBackward0 object at 0x1774497c0>: [<MmBackward0 object at 0x177449250>], <AccumulateGrad object at 0x177449190>: [], <ViewBackward0 object at 0x1774497f0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b840>], <TBackward0 object at 0x177449040>: [<AccumulateGrad object at 0x1774492e0>], <AddBackward0 object at 0x1774491c0>: [<AddmmBackward0 object at 0x1774492b0>, <NativeLayerNormBackward0 object at 0x177449340>], <AccumulateGrad object at 0x1774490a0>: [], <AccumulateGrad object at 0x177449070>: [], <ReshapeAliasBackward0 object at 0x177449100>: [<ExpandBackward0 object at 0x177449310>], <ReshapeAliasBackward0 object at 0x1774490d0>: [<ExpandBackward0 object at 0x177449700>], <SliceBackward0 object at 0x177449160>: [<ViewBackward0 object at 0x177449370>], <AddBackward0 object at 0x177449130>: [<DivBackward0 object at 0x1774493a0>, None], <SliceBackward0 object at 0x177449220>: [<SliceBackward0 object at 0x177449730>], <BmmBackward0 object at 0x1774491f0>: [<ViewBackward0 object at 0x177449400>, <ReshapeAliasBackward0 object at 0x1774493d0>], <SliceBackward0 object at 0x177449280>: [<MmBackward0 object at 0x177449250>], <MmBackward0 object at 0x177449250>: [<NativeLayerNormBackward0 object at 0x177438430>, <TBackward0 object at 0x177449460>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b840>: [<ReshapeAliasBackward0 object at 0x177449430>, None], <AccumulateGrad object at 0x1774492e0>: [], <AddmmBackward0 object at 0x1774492b0>: [<AccumulateGrad object at 0x1774494c0>, <MulBackward0 object at 0x177449490>, <TBackward0 object at 0x177449520>], <NativeLayerNormBackward0 object at 0x177449340>: [<AddBackward0 object at 0x1774494f0>, <AccumulateGrad object at 0x177449580>, <AccumulateGrad object at 0x177449550>], <ExpandBackward0 object at 0x177449310>: [<PermuteBackward0 object at 0x1774495e0>], <ExpandBackward0 object at 0x177449700>: [<PermuteBackward0 object at 0x1774495b0>], <ViewBackward0 object at 0x177449370>: [<ViewBackward0 object at 0x177449640>], <DivBackward0 object at 0x1774493a0>: [<UnsafeViewBackward0 object at 0x177449610>, None], <SliceBackward0 object at 0x177449730>: [<SelectBackward0 object at 0x1774496d0>], <ViewBackward0 object at 0x177449400>: [<ExpandBackward0 object at 0x177449670>], <ReshapeAliasBackward0 object at 0x1774493d0>: [<ExpandBackward0 object at 0x1774496a0>], <TBackward0 object at 0x177449460>: [<AccumulateGrad object at 0x1774333d0>], <ReshapeAliasBackward0 object at 0x177449430>: [<PermuteBackward0 object at 0x1774338e0>], <AccumulateGrad object at 0x1774494c0>: [], <MulBackward0 object at 0x177449490>: [<GeluBackward0 object at 0x177433df0>, <SliceBackward0 object at 0x1774333a0>], <TBackward0 object at 0x177449520>: [<AccumulateGrad object at 0x177433f70>], <AddBackward0 object at 0x1774494f0>: [<AddmmBackward0 object at 0x177433b50>, <NativeLayerNormBackward0 object at 0x177433c70>], <AccumulateGrad object at 0x177449580>: [], <AccumulateGrad object at 0x177449550>: [], <PermuteBackward0 object at 0x1774495e0>: [<SliceBackward0 object at 0x177433d00>], <PermuteBackward0 object at 0x1774495b0>: [<SliceBackward0 object at 0x177433bb0>], <ViewBackward0 object at 0x177449640>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758bd40>], <UnsafeViewBackward0 object at 0x177449610>: [<BmmBackward0 object at 0x177433be0>], <SelectBackward0 object at 0x1774496d0>: [<SliceBackward0 object at 0x177433b80>], <ExpandBackward0 object at 0x177449670>: [<SoftmaxBackward0 object at 0x177433c10>], <ExpandBackward0 object at 0x1774496a0>: [<PermuteBackward0 object at 0x1774337f0>], <AccumulateGrad object at 0x1774333d0>: [], <PermuteBackward0 object at 0x1774338e0>: [<UnsafeViewBackward0 object at 0x177433880>], <GeluBackward0 object at 0x177433df0>: [<SliceBackward0 object at 0x177433700>], <SliceBackward0 object at 0x1774333a0>: [<SliceBackward0 object at 0x177433730>], <AccumulateGrad object at 0x177433f70>: [], <AddmmBackward0 object at 0x177433b50>: [<AccumulateGrad object at 0x177433ac0>, <ViewBackward0 object at 0x177433af0>, <TBackward0 object at 0x177433910>], <NativeLayerNormBackward0 object at 0x177433c70>: [<AddBackward0 object at 0x177433940>, <AccumulateGrad object at 0x177433a60>, <AccumulateGrad object at 0x177433a90>], <SliceBackward0 object at 0x177433d00>: [<SliceBackward0 object at 0x177433a00>], <SliceBackward0 object at 0x177433bb0>: [<SliceBackward0 object at 0x177433a30>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758bd40>: [<AddmmBackward0 object at 0x1774339a0>, None], <BmmBackward0 object at 0x177433be0>: [<ReshapeAliasBackward0 object at 0x1774339d0>, <ReshapeAliasBackward0 object at 0x177433430>], <SliceBackward0 object at 0x177433b80>: [<SliceBackward0 object at 0x177433d60>], <SoftmaxBackward0 object at 0x177433c10>: [<AddBackward0 object at 0x177433340>], <PermuteBackward0 object at 0x1774337f0>: [<SliceBackward0 object at 0x177433370>], <UnsafeViewBackward0 object at 0x177433880>: [<BmmBackward0 object at 0x1774332e0>], <SliceBackward0 object at 0x177433700>: [<SliceBackward0 object at 0x177433310>], <SliceBackward0 object at 0x177433730>: [<MmBackward0 object at 0x1774330d0>], <AccumulateGrad object at 0x177433ac0>: [], <ViewBackward0 object at 0x177433af0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b640>], <TBackward0 object at 0x177433910>: [<AccumulateGrad object at 0x177433100>], <AddBackward0 object at 0x177433940>: [<AddmmBackward0 object at 0x177433040>, <NativeLayerNormBackward0 object at 0x177433070>], <AccumulateGrad object at 0x177433a60>: [], <AccumulateGrad object at 0x177433a90>: [], <SliceBackward0 object at 0x177433a00>: [<SelectBackward0 object at 0x1774330a0>], <SliceBackward0 object at 0x177433a30>: [<SelectBackward0 object at 0x177433280>], <AddmmBackward0 object at 0x1774339a0>: [<AccumulateGrad object at 0x1774332b0>, <NativeLayerNormBackward0 object at 0x15b042ac0>, <TBackward0 object at 0x177433130>], <ReshapeAliasBackward0 object at 0x1774339d0>: [<ExpandBackward0 object at 0x177433160>], <ReshapeAliasBackward0 object at 0x177433430>: [<ExpandBackward0 object at 0x177433190>], <SliceBackward0 object at 0x177433d60>: [<ViewBackward0 object at 0x1774331c0>], <AddBackward0 object at 0x177433340>: [<DivBackward0 object at 0x1774331f0>, None], <SliceBackward0 object at 0x177433370>: [<SliceBackward0 object at 0x177433220>], <BmmBackward0 object at 0x1774332e0>: [<ViewBackward0 object at 0x177433250>, <ReshapeAliasBackward0 object at 0x17740d1f0>], <SliceBackward0 object at 0x177433310>: [<MmBackward0 object at 0x1774330d0>], <MmBackward0 object at 0x1774330d0>: [<NativeLayerNormBackward0 object at 0x177449340>, <TBackward0 object at 0x17740d220>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b640>: [<ReshapeAliasBackward0 object at 0x17740d2e0>, None], <AccumulateGrad object at 0x177433100>: [], <AddmmBackward0 object at 0x177433040>: [<AccumulateGrad object at 0x17740d550>, <MulBackward0 object at 0x17740df40>, <TBackward0 object at 0x17740deb0>], <NativeLayerNormBackward0 object at 0x177433070>: [<AddBackward0 object at 0x17740d0d0>, <AccumulateGrad object at 0x17740df70>, <AccumulateGrad object at 0x17740d3a0>], <SelectBackward0 object at 0x1774330a0>: [<SliceBackward0 object at 0x17740d880>], <SelectBackward0 object at 0x177433280>: [<SliceBackward0 object at 0x17740de50>], <AccumulateGrad object at 0x1774332b0>: [], <TBackward0 object at 0x177433130>: [<AccumulateGrad object at 0x17740d8b0>], <ExpandBackward0 object at 0x177433160>: [<PermuteBackward0 object at 0x17740d6a0>], <ExpandBackward0 object at 0x177433190>: [<PermuteBackward0 object at 0x17740d6d0>], <ViewBackward0 object at 0x1774331c0>: [<ViewBackward0 object at 0x17740d280>], <DivBackward0 object at 0x1774331f0>: [<UnsafeViewBackward0 object at 0x17740d3d0>, None], <SliceBackward0 object at 0x177433220>: [<SelectBackward0 object at 0x17740d400>], <ViewBackward0 object at 0x177433250>: [<ExpandBackward0 object at 0x17740d430>], <ReshapeAliasBackward0 object at 0x17740d1f0>: [<ExpandBackward0 object at 0x17740d460>], <TBackward0 object at 0x17740d220>: [<AccumulateGrad object at 0x17740d490>], <ReshapeAliasBackward0 object at 0x17740d2e0>: [<PermuteBackward0 object at 0x17740d4c0>], <AccumulateGrad object at 0x17740d550>: [], <MulBackward0 object at 0x17740df40>: [<GeluBackward0 object at 0x17740d4f0>, <SliceBackward0 object at 0x17740d520>], <TBackward0 object at 0x17740deb0>: [<AccumulateGrad object at 0x17740d580>], <AddBackward0 object at 0x17740d0d0>: [<AddmmBackward0 object at 0x17740d5b0>, <NativeLayerNormBackward0 object at 0x17740d5e0>], <AccumulateGrad object at 0x17740df70>: [], <AccumulateGrad object at 0x17740d3a0>: [], <SliceBackward0 object at 0x17740d880>: [<SliceBackward0 object at 0x17740d610>], <SliceBackward0 object at 0x17740de50>: [<SliceBackward0 object at 0x17740d640>], <AccumulateGrad object at 0x17740d8b0>: [], <PermuteBackward0 object at 0x17740d6a0>: [<SliceBackward0 object at 0x17740d670>], <PermuteBackward0 object at 0x17740d6d0>: [<SliceBackward0 object at 0x17740d7f0>], <ViewBackward0 object at 0x17740d280>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758bb40>], <UnsafeViewBackward0 object at 0x17740d3d0>: [<BmmBackward0 object at 0x17740d820>], <SelectBackward0 object at 0x17740d400>: [<SliceBackward0 object at 0x17740d700>], <ExpandBackward0 object at 0x17740d430>: [<SoftmaxBackward0 object at 0x17740d730>], <ExpandBackward0 object at 0x17740d460>: [<PermuteBackward0 object at 0x17740d760>], <AccumulateGrad object at 0x17740d490>: [], <PermuteBackward0 object at 0x17740d4c0>: [<UnsafeViewBackward0 object at 0x17740d790>], <GeluBackward0 object at 0x17740d4f0>: [<SliceBackward0 object at 0x17740d7c0>], <SliceBackward0 object at 0x17740d520>: [<SliceBackward0 object at 0x17740db50>], <AccumulateGrad object at 0x17740d580>: [], <AddmmBackward0 object at 0x17740d5b0>: [<AccumulateGrad object at 0x17740db80>, <ViewBackward0 object at 0x17740d850>, <TBackward0 object at 0x17740d8e0>], <NativeLayerNormBackward0 object at 0x17740d5e0>: [<AddBackward0 object at 0x17740d910>, <AccumulateGrad object at 0x17740d940>, <AccumulateGrad object at 0x17740d970>], <SliceBackward0 object at 0x17740d610>: [<ViewBackward0 object at 0x177449370>], <SliceBackward0 object at 0x17740d640>: [<ViewBackward0 object at 0x177449370>], <SliceBackward0 object at 0x17740d670>: [<SliceBackward0 object at 0x17740d9a0>], <SliceBackward0 object at 0x17740d7f0>: [<SliceBackward0 object at 0x17740d9d0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758bb40>: [<AddmmBackward0 object at 0x17740da00>, None], <BmmBackward0 object at 0x17740d820>: [<ReshapeAliasBackward0 object at 0x17740da30>, <ReshapeAliasBackward0 object at 0x17740da60>], <SliceBackward0 object at 0x17740d700>: [<SliceBackward0 object at 0x17740da90>], <SoftmaxBackward0 object at 0x17740d730>: [<AddBackward0 object at 0x17740dac0>], <PermuteBackward0 object at 0x17740d760>: [<SliceBackward0 object at 0x17740daf0>], <UnsafeViewBackward0 object at 0x17740d790>: [<BmmBackward0 object at 0x17740db20>], <SliceBackward0 object at 0x17740d7c0>: [<SliceBackward0 object at 0x17740dd00>], <SliceBackward0 object at 0x17740db50>: [<MmBackward0 object at 0x17740dd30>], <AccumulateGrad object at 0x17740db80>: [], <ViewBackward0 object at 0x17740d850>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b440>], <TBackward0 object at 0x17740d8e0>: [<AccumulateGrad object at 0x17740dbb0>], <AddBackward0 object at 0x17740d910>: [<AddmmBackward0 object at 0x17740dbe0>, <NativeLayerNormBackward0 object at 0x17740dc10>], <AccumulateGrad object at 0x17740d940>: [], <AccumulateGrad object at 0x17740d970>: [], <SliceBackward0 object at 0x17740d9a0>: [<SelectBackward0 object at 0x17740dc40>], <SliceBackward0 object at 0x17740d9d0>: [<SelectBackward0 object at 0x17740dc70>], <AddmmBackward0 object at 0x17740da00>: [<AccumulateGrad object at 0x17740dca0>, <NativeLayerNormBackward0 object at 0x177438130>, <TBackward0 object at 0x17740dcd0>], <ReshapeAliasBackward0 object at 0x17740da30>: [<ExpandBackward0 object at 0x17740dd60>], <ReshapeAliasBackward0 object at 0x17740da60>: [<ExpandBackward0 object at 0x17740dd90>], <SliceBackward0 object at 0x17740da90>: [<ViewBackward0 object at 0x17740ddc0>], <AddBackward0 object at 0x17740dac0>: [<DivBackward0 object at 0x17740ddf0>, None], <SliceBackward0 object at 0x17740daf0>: [<SliceBackward0 object at 0x17740de20>], <BmmBackward0 object at 0x17740db20>: [<ViewBackward0 object at 0x17740d250>, <ReshapeAliasBackward0 object at 0x17740d1c0>], <SliceBackward0 object at 0x17740dd00>: [<MmBackward0 object at 0x17740dd30>], <MmBackward0 object at 0x17740dd30>: [<NativeLayerNormBackward0 object at 0x177433070>, <TBackward0 object at 0x17740dfd0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b440>: [<ReshapeAliasBackward0 object at 0x17759e040>, None], <AccumulateGrad object at 0x17740dbb0>: [], <AddmmBackward0 object at 0x17740dbe0>: [<AccumulateGrad object at 0x17759e070>, <MulBackward0 object at 0x17759e0a0>, <TBackward0 object at 0x17759e0d0>], <NativeLayerNormBackward0 object at 0x17740dc10>: [<AddBackward0 object at 0x17759e100>, <AccumulateGrad object at 0x17759e130>, <AccumulateGrad object at 0x17759e160>], <SelectBackward0 object at 0x17740dc40>: [<SliceBackward0 object at 0x17759e190>], <SelectBackward0 object at 0x17740dc70>: [<SliceBackward0 object at 0x17759e1c0>], <AccumulateGrad object at 0x17740dca0>: [], <TBackward0 object at 0x17740dcd0>: [<AccumulateGrad object at 0x17759e1f0>], <ExpandBackward0 object at 0x17740dd60>: [<PermuteBackward0 object at 0x17759e220>], <ExpandBackward0 object at 0x17740dd90>: [<PermuteBackward0 object at 0x17759e250>], <ViewBackward0 object at 0x17740ddc0>: [<ViewBackward0 object at 0x17759e280>], <DivBackward0 object at 0x17740ddf0>: [<UnsafeViewBackward0 object at 0x17759e2b0>, None], <SliceBackward0 object at 0x17740de20>: [<SelectBackward0 object at 0x17759e2e0>], <ViewBackward0 object at 0x17740d250>: [<ExpandBackward0 object at 0x17759e310>], <ReshapeAliasBackward0 object at 0x17740d1c0>: [<ExpandBackward0 object at 0x17759e340>], <TBackward0 object at 0x17740dfd0>: [<AccumulateGrad object at 0x17759e370>], <ReshapeAliasBackward0 object at 0x17759e040>: [<PermuteBackward0 object at 0x17759e3a0>], <AccumulateGrad object at 0x17759e070>: [], <MulBackward0 object at 0x17759e0a0>: [<GeluBackward0 object at 0x17759e3d0>, <SliceBackward0 object at 0x17759e400>], <TBackward0 object at 0x17759e0d0>: [<AccumulateGrad object at 0x17759e430>], <AddBackward0 object at 0x17759e100>: [<AddmmBackward0 object at 0x17759e460>, <NativeLayerNormBackward0 object at 0x17759e490>], <AccumulateGrad object at 0x17759e130>: [], <AccumulateGrad object at 0x17759e160>: [], <SliceBackward0 object at 0x17759e190>: [<SliceBackward0 object at 0x17759e4c0>], <SliceBackward0 object at 0x17759e1c0>: [<SliceBackward0 object at 0x17759e4f0>], <AccumulateGrad object at 0x17759e1f0>: [], <PermuteBackward0 object at 0x17759e220>: [<SliceBackward0 object at 0x17759e520>], <PermuteBackward0 object at 0x17759e250>: [<SliceBackward0 object at 0x17759e550>], <ViewBackward0 object at 0x17759e280>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b940>], <UnsafeViewBackward0 object at 0x17759e2b0>: [<BmmBackward0 object at 0x17759e580>], <SelectBackward0 object at 0x17759e2e0>: [<SliceBackward0 object at 0x17759e5b0>], <ExpandBackward0 object at 0x17759e310>: [<SoftmaxBackward0 object at 0x17759e5e0>], <ExpandBackward0 object at 0x17759e340>: [<PermuteBackward0 object at 0x17759e610>], <AccumulateGrad object at 0x17759e370>: [], <PermuteBackward0 object at 0x17759e3a0>: [<UnsafeViewBackward0 object at 0x17759e640>], <GeluBackward0 object at 0x17759e3d0>: [<SliceBackward0 object at 0x17759e670>], <SliceBackward0 object at 0x17759e400>: [<SliceBackward0 object at 0x17759e6a0>], <AccumulateGrad object at 0x17759e430>: [], <AddmmBackward0 object at 0x17759e460>: [<AccumulateGrad object at 0x17759e6d0>, <ViewBackward0 object at 0x17759e700>, <TBackward0 object at 0x17759e730>], <NativeLayerNormBackward0 object at 0x17759e490>: [<AddBackward0 object at 0x17759e760>, <AccumulateGrad object at 0x17759e790>, <AccumulateGrad object at 0x17759e7c0>], <SliceBackward0 object at 0x17759e4c0>: [<ViewBackward0 object at 0x1774331c0>], <SliceBackward0 object at 0x17759e4f0>: [<ViewBackward0 object at 0x1774331c0>], <SliceBackward0 object at 0x17759e520>: [<SliceBackward0 object at 0x17759e7f0>], <SliceBackward0 object at 0x17759e550>: [<SliceBackward0 object at 0x17759e820>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b940>: [<AddmmBackward0 object at 0x17759e850>, None], <BmmBackward0 object at 0x17759e580>: [<ReshapeAliasBackward0 object at 0x17759e880>, <ReshapeAliasBackward0 object at 0x17759e8b0>], <SliceBackward0 object at 0x17759e5b0>: [<SliceBackward0 object at 0x17759e8e0>], <SoftmaxBackward0 object at 0x17759e5e0>: [<AddBackward0 object at 0x17759e910>], <PermuteBackward0 object at 0x17759e610>: [<SliceBackward0 object at 0x17759e940>], <UnsafeViewBackward0 object at 0x17759e640>: [<BmmBackward0 object at 0x17759e970>], <SliceBackward0 object at 0x17759e670>: [<SliceBackward0 object at 0x17759e9a0>], <SliceBackward0 object at 0x17759e6a0>: [<MmBackward0 object at 0x17759e9d0>], <AccumulateGrad object at 0x17759e6d0>: [], <ViewBackward0 object at 0x17759e700>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b240>], <TBackward0 object at 0x17759e730>: [<AccumulateGrad object at 0x17759ea00>], <AddBackward0 object at 0x17759e760>: [<AddmmBackward0 object at 0x17759ea30>, <NativeLayerNormBackward0 object at 0x17759ea60>], <AccumulateGrad object at 0x17759e790>: [], <AccumulateGrad object at 0x17759e7c0>: [], <SliceBackward0 object at 0x17759e7f0>: [<SelectBackward0 object at 0x17759ea90>], <SliceBackward0 object at 0x17759e820>: [<SelectBackward0 object at 0x17759eac0>], <AddmmBackward0 object at 0x17759e850>: [<AccumulateGrad object at 0x17759eaf0>, <NativeLayerNormBackward0 object at 0x177438e20>, <TBackward0 object at 0x17759eb20>], <ReshapeAliasBackward0 object at 0x17759e880>: [<ExpandBackward0 object at 0x17759eb50>], <ReshapeAliasBackward0 object at 0x17759e8b0>: [<ExpandBackward0 object at 0x17759eb80>], <SliceBackward0 object at 0x17759e8e0>: [<ViewBackward0 object at 0x17759ebb0>], <AddBackward0 object at 0x17759e910>: [<DivBackward0 object at 0x17759ebe0>, None], <SliceBackward0 object at 0x17759e940>: [<SliceBackward0 object at 0x17759ec10>], <BmmBackward0 object at 0x17759e970>: [<ViewBackward0 object at 0x17759ec40>, <ReshapeAliasBackward0 object at 0x17759ec70>], <SliceBackward0 object at 0x17759e9a0>: [<MmBackward0 object at 0x17759e9d0>], <MmBackward0 object at 0x17759e9d0>: [<NativeLayerNormBackward0 object at 0x17740dc10>, <TBackward0 object at 0x17759eca0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b240>: [<ReshapeAliasBackward0 object at 0x17759ecd0>, None], <AccumulateGrad object at 0x17759ea00>: [], <AddmmBackward0 object at 0x17759ea30>: [<AccumulateGrad object at 0x17759ed00>, <MulBackward0 object at 0x17759ed30>, <TBackward0 object at 0x17759ed60>], <NativeLayerNormBackward0 object at 0x17759ea60>: [<AddBackward0 object at 0x17759ed90>, <AccumulateGrad object at 0x17759edc0>, <AccumulateGrad object at 0x17759edf0>], <SelectBackward0 object at 0x17759ea90>: [<SliceBackward0 object at 0x17759ee20>], <SelectBackward0 object at 0x17759eac0>: [<SliceBackward0 object at 0x17759ee50>], <AccumulateGrad object at 0x17759eaf0>: [], <TBackward0 object at 0x17759eb20>: [<AccumulateGrad object at 0x17759ee80>], <ExpandBackward0 object at 0x17759eb50>: [<PermuteBackward0 object at 0x17759eeb0>], <ExpandBackward0 object at 0x17759eb80>: [<PermuteBackward0 object at 0x17759eee0>], <ViewBackward0 object at 0x17759ebb0>: [<ViewBackward0 object at 0x17759ef10>], <DivBackward0 object at 0x17759ebe0>: [<UnsafeViewBackward0 object at 0x17759ef40>, None], <SliceBackward0 object at 0x17759ec10>: [<SelectBackward0 object at 0x17759ef70>], <ViewBackward0 object at 0x17759ec40>: [<ExpandBackward0 object at 0x17759efa0>], <ReshapeAliasBackward0 object at 0x17759ec70>: [<ExpandBackward0 object at 0x17759efd0>], <TBackward0 object at 0x17759eca0>: [<AccumulateGrad object at 0x1775a3040>], <ReshapeAliasBackward0 object at 0x17759ecd0>: [<PermuteBackward0 object at 0x1775a3070>], <AccumulateGrad object at 0x17759ed00>: [], <MulBackward0 object at 0x17759ed30>: [<GeluBackward0 object at 0x1775a30a0>, <SliceBackward0 object at 0x1775a30d0>], <TBackward0 object at 0x17759ed60>: [<AccumulateGrad object at 0x1775a3100>], <AddBackward0 object at 0x17759ed90>: [<AddmmBackward0 object at 0x1775a3130>, <NativeLayerNormBackward0 object at 0x1775a3160>], <AccumulateGrad object at 0x17759edc0>: [], <AccumulateGrad object at 0x17759edf0>: [], <SliceBackward0 object at 0x17759ee20>: [<SliceBackward0 object at 0x1775a3190>], <SliceBackward0 object at 0x17759ee50>: [<SliceBackward0 object at 0x1775a31c0>], <AccumulateGrad object at 0x17759ee80>: [], <PermuteBackward0 object at 0x17759eeb0>: [<SliceBackward0 object at 0x1775a31f0>], <PermuteBackward0 object at 0x17759eee0>: [<SliceBackward0 object at 0x1775a3220>], <ViewBackward0 object at 0x17759ef10>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b740>], <UnsafeViewBackward0 object at 0x17759ef40>: [<BmmBackward0 object at 0x1775a3250>], <SelectBackward0 object at 0x17759ef70>: [<SliceBackward0 object at 0x1775a3280>], <ExpandBackward0 object at 0x17759efa0>: [<SoftmaxBackward0 object at 0x1775a32b0>], <ExpandBackward0 object at 0x17759efd0>: [<PermuteBackward0 object at 0x1775a32e0>], <AccumulateGrad object at 0x1775a3040>: [], <PermuteBackward0 object at 0x1775a3070>: [<UnsafeViewBackward0 object at 0x1775a3310>], <GeluBackward0 object at 0x1775a30a0>: [<SliceBackward0 object at 0x1775a3340>], <SliceBackward0 object at 0x1775a30d0>: [<SliceBackward0 object at 0x1775a3370>], <AccumulateGrad object at 0x1775a3100>: [], <AddmmBackward0 object at 0x1775a3130>: [<AccumulateGrad object at 0x1775a33a0>, <ViewBackward0 object at 0x1775a33d0>, <TBackward0 object at 0x1775a3400>], <NativeLayerNormBackward0 object at 0x1775a3160>: [<AddBackward0 object at 0x1775a3430>, <AccumulateGrad object at 0x1775a3460>, <AccumulateGrad object at 0x1775a3490>], <SliceBackward0 object at 0x1775a3190>: [<ViewBackward0 object at 0x17740ddc0>], <SliceBackward0 object at 0x1775a31c0>: [<ViewBackward0 object at 0x17740ddc0>], <SliceBackward0 object at 0x1775a31f0>: [<SliceBackward0 object at 0x1775a34c0>], <SliceBackward0 object at 0x1775a3220>: [<SliceBackward0 object at 0x1775a34f0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b740>: [<AddmmBackward0 object at 0x1775a3520>, None], <BmmBackward0 object at 0x1775a3250>: [<ReshapeAliasBackward0 object at 0x1775a3550>, <ReshapeAliasBackward0 object at 0x1775a3580>], <SliceBackward0 object at 0x1775a3280>: [<SliceBackward0 object at 0x1775a35b0>], <SoftmaxBackward0 object at 0x1775a32b0>: [<AddBackward0 object at 0x1775a35e0>], <PermuteBackward0 object at 0x1775a32e0>: [<SliceBackward0 object at 0x1775a3610>], <UnsafeViewBackward0 object at 0x1775a3310>: [<BmmBackward0 object at 0x1775a3640>], <SliceBackward0 object at 0x1775a3340>: [<SliceBackward0 object at 0x1775a3670>], <SliceBackward0 object at 0x1775a3370>: [<MmBackward0 object at 0x1775a36a0>], <AccumulateGrad object at 0x1775a33a0>: [], <ViewBackward0 object at 0x1775a33d0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b040>], <TBackward0 object at 0x1775a3400>: [<AccumulateGrad object at 0x1775a36d0>], <AddBackward0 object at 0x1775a3430>: [<AddmmBackward0 object at 0x1775a3700>, <NativeLayerNormBackward0 object at 0x1775a3730>], <AccumulateGrad object at 0x1775a3460>: [], <AccumulateGrad object at 0x1775a3490>: [], <SliceBackward0 object at 0x1775a34c0>: [<SelectBackward0 object at 0x1775a3760>], <SliceBackward0 object at 0x1775a34f0>: [<SelectBackward0 object at 0x1775a3790>], <AddmmBackward0 object at 0x1775a3520>: [<AccumulateGrad object at 0x1775a37c0>, <NativeLayerNormBackward0 object at 0x177449790>, <TBackward0 object at 0x1775a37f0>], <ReshapeAliasBackward0 object at 0x1775a3550>: [<ExpandBackward0 object at 0x1775a3820>], <ReshapeAliasBackward0 object at 0x1775a3580>: [<ExpandBackward0 object at 0x1775a3850>], <SliceBackward0 object at 0x1775a35b0>: [<ViewBackward0 object at 0x1775a3880>], <AddBackward0 object at 0x1775a35e0>: [<DivBackward0 object at 0x1775a38b0>, None], <SliceBackward0 object at 0x1775a3610>: [<SliceBackward0 object at 0x1775a38e0>], <BmmBackward0 object at 0x1775a3640>: [<ViewBackward0 object at 0x1775a3910>, <ReshapeAliasBackward0 object at 0x1775a3940>], <SliceBackward0 object at 0x1775a3670>: [<MmBackward0 object at 0x1775a36a0>], <MmBackward0 object at 0x1775a36a0>: [<NativeLayerNormBackward0 object at 0x17759ea60>, <TBackward0 object at 0x1775a3970>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b040>: [<ReshapeAliasBackward0 object at 0x1775a39a0>, None], <AccumulateGrad object at 0x1775a36d0>: [], <AddmmBackward0 object at 0x1775a3700>: [<AccumulateGrad object at 0x1775a39d0>, <MulBackward0 object at 0x1775a3a00>, <TBackward0 object at 0x1775a3a30>], <NativeLayerNormBackward0 object at 0x1775a3730>: [<AddBackward0 object at 0x1775a3a60>, <AccumulateGrad object at 0x1775a3a90>, <AccumulateGrad object at 0x1775a3ac0>], <SelectBackward0 object at 0x1775a3760>: [<SliceBackward0 object at 0x1775a3af0>], <SelectBackward0 object at 0x1775a3790>: [<SliceBackward0 object at 0x1775a3b20>], <AccumulateGrad object at 0x1775a37c0>: [], <TBackward0 object at 0x1775a37f0>: [<AccumulateGrad object at 0x1775a3b50>], <ExpandBackward0 object at 0x1775a3820>: [<PermuteBackward0 object at 0x1775a3b80>], <ExpandBackward0 object at 0x1775a3850>: [<PermuteBackward0 object at 0x1775a3bb0>], <ViewBackward0 object at 0x1775a3880>: [<ViewBackward0 object at 0x1775a3be0>], <DivBackward0 object at 0x1775a38b0>: [<UnsafeViewBackward0 object at 0x1775a3c10>, None], <SliceBackward0 object at 0x1775a38e0>: [<SelectBackward0 object at 0x1775a3c40>], <ViewBackward0 object at 0x1775a3910>: [<ExpandBackward0 object at 0x1775a3c70>], <ReshapeAliasBackward0 object at 0x1775a3940>: [<ExpandBackward0 object at 0x1775a3ca0>], <TBackward0 object at 0x1775a3970>: [<AccumulateGrad object at 0x1775a3cd0>], <ReshapeAliasBackward0 object at 0x1775a39a0>: [<PermuteBackward0 object at 0x1775a3d00>], <AccumulateGrad object at 0x1775a39d0>: [], <MulBackward0 object at 0x1775a3a00>: [<GeluBackward0 object at 0x1775a3d30>, <SliceBackward0 object at 0x1775a3d60>], <TBackward0 object at 0x1775a3a30>: [<AccumulateGrad object at 0x1775a3d90>], <AddBackward0 object at 0x1775a3a60>: [<AddmmBackward0 object at 0x1775a3dc0>, <NativeLayerNormBackward0 object at 0x1775a3df0>], <AccumulateGrad object at 0x1775a3a90>: [], <AccumulateGrad object at 0x1775a3ac0>: [], <SliceBackward0 object at 0x1775a3af0>: [<SliceBackward0 object at 0x1775a3e20>], <SliceBackward0 object at 0x1775a3b20>: [<SliceBackward0 object at 0x1775a3e50>], <AccumulateGrad object at 0x1775a3b50>: [], <PermuteBackward0 object at 0x1775a3b80>: [<SliceBackward0 object at 0x1775a3e80>], <PermuteBackward0 object at 0x1775a3bb0>: [<SliceBackward0 object at 0x1775a3eb0>], <ViewBackward0 object at 0x1775a3be0>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b540>], <UnsafeViewBackward0 object at 0x1775a3c10>: [<BmmBackward0 object at 0x1775a3ee0>], <SelectBackward0 object at 0x1775a3c40>: [<SliceBackward0 object at 0x1775a3f10>], <ExpandBackward0 object at 0x1775a3c70>: [<SoftmaxBackward0 object at 0x1775a3f40>], <ExpandBackward0 object at 0x1775a3ca0>: [<PermuteBackward0 object at 0x1775a3f70>], <AccumulateGrad object at 0x1775a3cd0>: [], <PermuteBackward0 object at 0x1775a3d00>: [<UnsafeViewBackward0 object at 0x1775a3fa0>], <GeluBackward0 object at 0x1775a3d30>: [<SliceBackward0 object at 0x1775a3fd0>], <SliceBackward0 object at 0x1775a3d60>: [<SliceBackward0 object at 0x177599040>], <AccumulateGrad object at 0x1775a3d90>: [], <AddmmBackward0 object at 0x1775a3dc0>: [<AccumulateGrad object at 0x177599070>, <ViewBackward0 object at 0x1775990a0>, <TBackward0 object at 0x1775990d0>], <NativeLayerNormBackward0 object at 0x1775a3df0>: [<AddBackward0 object at 0x177599100>, <AccumulateGrad object at 0x177599130>, <AccumulateGrad object at 0x177599160>], <SliceBackward0 object at 0x1775a3e20>: [<ViewBackward0 object at 0x17759ebb0>], <SliceBackward0 object at 0x1775a3e50>: [<ViewBackward0 object at 0x17759ebb0>], <SliceBackward0 object at 0x1775a3e80>: [<SliceBackward0 object at 0x177599190>], <SliceBackward0 object at 0x1775a3eb0>: [<SliceBackward0 object at 0x1775991c0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b540>: [<AddmmBackward0 object at 0x1775991f0>, None], <BmmBackward0 object at 0x1775a3ee0>: [<ReshapeAliasBackward0 object at 0x177599220>, <ReshapeAliasBackward0 object at 0x177599250>], <SliceBackward0 object at 0x1775a3f10>: [<SliceBackward0 object at 0x177599280>], <SoftmaxBackward0 object at 0x1775a3f40>: [<AddBackward0 object at 0x1775992b0>], <PermuteBackward0 object at 0x1775a3f70>: [<SliceBackward0 object at 0x1775992e0>], <UnsafeViewBackward0 object at 0x1775a3fa0>: [<BmmBackward0 object at 0x177599310>], <SliceBackward0 object at 0x1775a3fd0>: [<SliceBackward0 object at 0x177599340>], <SliceBackward0 object at 0x177599040>: [<MmBackward0 object at 0x177599370>], <AccumulateGrad object at 0x177599070>: [], <ViewBackward0 object at 0x1775990a0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x177430d40>], <TBackward0 object at 0x1775990d0>: [<AccumulateGrad object at 0x1775993a0>], <AddBackward0 object at 0x177599100>: [<AddmmBackward0 object at 0x1775993d0>, <NativeLayerNormBackward0 object at 0x177599400>], <AccumulateGrad object at 0x177599130>: [], <AccumulateGrad object at 0x177599160>: [], <SliceBackward0 object at 0x177599190>: [<SelectBackward0 object at 0x177599430>], <SliceBackward0 object at 0x1775991c0>: [<SelectBackward0 object at 0x177599460>], <AddmmBackward0 object at 0x1775991f0>: [<AccumulateGrad object at 0x177599490>, <NativeLayerNormBackward0 object at 0x177433c70>, <TBackward0 object at 0x1775994c0>], <ReshapeAliasBackward0 object at 0x177599220>: [<ExpandBackward0 object at 0x1775994f0>], <ReshapeAliasBackward0 object at 0x177599250>: [<ExpandBackward0 object at 0x177599520>], <SliceBackward0 object at 0x177599280>: [<ViewBackward0 object at 0x177599550>], <AddBackward0 object at 0x1775992b0>: [<DivBackward0 object at 0x177599580>, None], <SliceBackward0 object at 0x1775992e0>: [<SliceBackward0 object at 0x1775995b0>], <BmmBackward0 object at 0x177599310>: [<ViewBackward0 object at 0x1775995e0>, <ReshapeAliasBackward0 object at 0x177599610>], <SliceBackward0 object at 0x177599340>: [<MmBackward0 object at 0x177599370>], <MmBackward0 object at 0x177599370>: [<NativeLayerNormBackward0 object at 0x1775a3730>, <TBackward0 object at 0x177599640>], <torch.autograd.function.IndexFirstAxisBackward object at 0x177430d40>: [<ReshapeAliasBackward0 object at 0x177599670>, None], <AccumulateGrad object at 0x1775993a0>: [], <AddmmBackward0 object at 0x1775993d0>: [<AccumulateGrad object at 0x1775996a0>, <MulBackward0 object at 0x1775996d0>, <TBackward0 object at 0x177599700>], <NativeLayerNormBackward0 object at 0x177599400>: [<AddBackward0 object at 0x177599730>, <AccumulateGrad object at 0x177599760>, <AccumulateGrad object at 0x177599790>], <SelectBackward0 object at 0x177599430>: [<SliceBackward0 object at 0x1775997c0>], <SelectBackward0 object at 0x177599460>: [<SliceBackward0 object at 0x1775997f0>], <AccumulateGrad object at 0x177599490>: [], <TBackward0 object at 0x1775994c0>: [<AccumulateGrad object at 0x177599820>], <ExpandBackward0 object at 0x1775994f0>: [<PermuteBackward0 object at 0x177599850>], <ExpandBackward0 object at 0x177599520>: [<PermuteBackward0 object at 0x177599880>], <ViewBackward0 object at 0x177599550>: [<ViewBackward0 object at 0x1775998b0>], <DivBackward0 object at 0x177599580>: [<UnsafeViewBackward0 object at 0x1775998e0>, None], <SliceBackward0 object at 0x1775995b0>: [<SelectBackward0 object at 0x177599910>], <ViewBackward0 object at 0x1775995e0>: [<ExpandBackward0 object at 0x177599940>], <ReshapeAliasBackward0 object at 0x177599610>: [<ExpandBackward0 object at 0x177599970>], <TBackward0 object at 0x177599640>: [<AccumulateGrad object at 0x1775999a0>], <ReshapeAliasBackward0 object at 0x177599670>: [<PermuteBackward0 object at 0x1775999d0>], <AccumulateGrad object at 0x1775996a0>: [], <MulBackward0 object at 0x1775996d0>: [<GeluBackward0 object at 0x177599a00>, <SliceBackward0 object at 0x177599a30>], <TBackward0 object at 0x177599700>: [<AccumulateGrad object at 0x177599a60>], <AddBackward0 object at 0x177599730>: [<AddmmBackward0 object at 0x177599a90>, <NativeLayerNormBackward0 object at 0x177599ac0>], <AccumulateGrad object at 0x177599760>: [], <AccumulateGrad object at 0x177599790>: [], <SliceBackward0 object at 0x1775997c0>: [<SliceBackward0 object at 0x177599af0>], <SliceBackward0 object at 0x1775997f0>: [<SliceBackward0 object at 0x177599b20>], <AccumulateGrad object at 0x177599820>: [], <PermuteBackward0 object at 0x177599850>: [<SliceBackward0 object at 0x177599b50>], <PermuteBackward0 object at 0x177599880>: [<SliceBackward0 object at 0x177599b80>], <ViewBackward0 object at 0x1775998b0>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b340>], <UnsafeViewBackward0 object at 0x1775998e0>: [<BmmBackward0 object at 0x177599bb0>], <SelectBackward0 object at 0x177599910>: [<SliceBackward0 object at 0x177599be0>], <ExpandBackward0 object at 0x177599940>: [<SoftmaxBackward0 object at 0x177599c10>], <ExpandBackward0 object at 0x177599970>: [<PermuteBackward0 object at 0x177599c40>], <AccumulateGrad object at 0x1775999a0>: [], <PermuteBackward0 object at 0x1775999d0>: [<UnsafeViewBackward0 object at 0x177599c70>], <GeluBackward0 object at 0x177599a00>: [<SliceBackward0 object at 0x177599ca0>], <SliceBackward0 object at 0x177599a30>: [<SliceBackward0 object at 0x177599cd0>], <AccumulateGrad object at 0x177599a60>: [], <AddmmBackward0 object at 0x177599a90>: [<AccumulateGrad object at 0x177599d00>, <ViewBackward0 object at 0x177599d30>, <TBackward0 object at 0x177599d60>], <NativeLayerNormBackward0 object at 0x177599ac0>: [<AddBackward0 object at 0x177599d90>, <AccumulateGrad object at 0x177599dc0>, <AccumulateGrad object at 0x177599df0>], <SliceBackward0 object at 0x177599af0>: [<ViewBackward0 object at 0x1775a3880>], <SliceBackward0 object at 0x177599b20>: [<ViewBackward0 object at 0x1775a3880>], <SliceBackward0 object at 0x177599b50>: [<SliceBackward0 object at 0x177599e20>], <SliceBackward0 object at 0x177599b80>: [<SliceBackward0 object at 0x177599e50>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b340>: [<AddmmBackward0 object at 0x177599e80>, None], <BmmBackward0 object at 0x177599bb0>: [<ReshapeAliasBackward0 object at 0x177599eb0>, <ReshapeAliasBackward0 object at 0x177599ee0>], <SliceBackward0 object at 0x177599be0>: [<SliceBackward0 object at 0x177599f10>], <SoftmaxBackward0 object at 0x177599c10>: [<AddBackward0 object at 0x177599f40>], <PermuteBackward0 object at 0x177599c40>: [<SliceBackward0 object at 0x177599f70>], <UnsafeViewBackward0 object at 0x177599c70>: [<BmmBackward0 object at 0x177599fa0>], <SliceBackward0 object at 0x177599ca0>: [<SliceBackward0 object at 0x177599fd0>], <SliceBackward0 object at 0x177599cd0>: [<MmBackward0 object at 0x1775a2040>], <AccumulateGrad object at 0x177599d00>: [], <ViewBackward0 object at 0x177599d30>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x177430a40>], <TBackward0 object at 0x177599d60>: [<AccumulateGrad object at 0x1775a2070>], <AddBackward0 object at 0x177599d90>: [<AddmmBackward0 object at 0x1775a20a0>, <NativeLayerNormBackward0 object at 0x1775a20d0>], <AccumulateGrad object at 0x177599dc0>: [], <AccumulateGrad object at 0x177599df0>: [], <SliceBackward0 object at 0x177599e20>: [<SelectBackward0 object at 0x1775a2100>], <SliceBackward0 object at 0x177599e50>: [<SelectBackward0 object at 0x1775a2130>], <AddmmBackward0 object at 0x177599e80>: [<AccumulateGrad object at 0x1775a2160>, <NativeLayerNormBackward0 object at 0x17740d5e0>, <TBackward0 object at 0x1775a2190>], <ReshapeAliasBackward0 object at 0x177599eb0>: [<ExpandBackward0 object at 0x1775a21c0>], <ReshapeAliasBackward0 object at 0x177599ee0>: [<ExpandBackward0 object at 0x1775a21f0>], <SliceBackward0 object at 0x177599f10>: [<ViewBackward0 object at 0x1775a2220>], <AddBackward0 object at 0x177599f40>: [<DivBackward0 object at 0x1775a2250>, None], <SliceBackward0 object at 0x177599f70>: [<SliceBackward0 object at 0x1775a2280>], <BmmBackward0 object at 0x177599fa0>: [<ViewBackward0 object at 0x1775a22b0>, <ReshapeAliasBackward0 object at 0x1775a22e0>], <SliceBackward0 object at 0x177599fd0>: [<MmBackward0 object at 0x1775a2040>], <MmBackward0 object at 0x1775a2040>: [<NativeLayerNormBackward0 object at 0x177599400>, <TBackward0 object at 0x1775a2310>], <torch.autograd.function.IndexFirstAxisBackward object at 0x177430a40>: [<ReshapeAliasBackward0 object at 0x1775a2340>, None], <AccumulateGrad object at 0x1775a2070>: [], <AddmmBackward0 object at 0x1775a20a0>: [<AccumulateGrad object at 0x1775a2370>, <MulBackward0 object at 0x1775a23a0>, <TBackward0 object at 0x1775a23d0>], <NativeLayerNormBackward0 object at 0x1775a20d0>: [<AddBackward0 object at 0x1775a2400>, <AccumulateGrad object at 0x1775a2430>, <AccumulateGrad object at 0x1775a2460>], <SelectBackward0 object at 0x1775a2100>: [<SliceBackward0 object at 0x1775a2490>], <SelectBackward0 object at 0x1775a2130>: [<SliceBackward0 object at 0x1775a24c0>], <AccumulateGrad object at 0x1775a2160>: [], <TBackward0 object at 0x1775a2190>: [<AccumulateGrad object at 0x1775a24f0>], <ExpandBackward0 object at 0x1775a21c0>: [<PermuteBackward0 object at 0x1775a2520>], <ExpandBackward0 object at 0x1775a21f0>: [<PermuteBackward0 object at 0x1775a2550>], <ViewBackward0 object at 0x1775a2220>: [<ViewBackward0 object at 0x1775a2580>], <DivBackward0 object at 0x1775a2250>: [<UnsafeViewBackward0 object at 0x1775a25b0>, None], <SliceBackward0 object at 0x1775a2280>: [<SelectBackward0 object at 0x1775a25e0>], <ViewBackward0 object at 0x1775a22b0>: [<ExpandBackward0 object at 0x1775a2610>], <ReshapeAliasBackward0 object at 0x1775a22e0>: [<ExpandBackward0 object at 0x1775a2640>], <TBackward0 object at 0x1775a2310>: [<AccumulateGrad object at 0x1775a2670>], <ReshapeAliasBackward0 object at 0x1775a2340>: [<PermuteBackward0 object at 0x1775a26a0>], <AccumulateGrad object at 0x1775a2370>: [], <MulBackward0 object at 0x1775a23a0>: [<GeluBackward0 object at 0x1775a26d0>, <SliceBackward0 object at 0x1775a2700>], <TBackward0 object at 0x1775a23d0>: [<AccumulateGrad object at 0x1775a2730>], <AddBackward0 object at 0x1775a2400>: [<AddmmBackward0 object at 0x1775a2760>, <NativeLayerNormBackward0 object at 0x1775a2790>], <AccumulateGrad object at 0x1775a2430>: [], <AccumulateGrad object at 0x1775a2460>: [], <SliceBackward0 object at 0x1775a2490>: [<SliceBackward0 object at 0x1775a27c0>], <SliceBackward0 object at 0x1775a24c0>: [<SliceBackward0 object at 0x1775a27f0>], <AccumulateGrad object at 0x1775a24f0>: [], <PermuteBackward0 object at 0x1775a2520>: [<SliceBackward0 object at 0x1775a2820>], <PermuteBackward0 object at 0x1775a2550>: [<SliceBackward0 object at 0x1775a2850>], <ViewBackward0 object at 0x1775a2580>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b140>], <UnsafeViewBackward0 object at 0x1775a25b0>: [<BmmBackward0 object at 0x1775a2880>], <SelectBackward0 object at 0x1775a25e0>: [<SliceBackward0 object at 0x1775a28b0>], <ExpandBackward0 object at 0x1775a2610>: [<SoftmaxBackward0 object at 0x1775a28e0>], <ExpandBackward0 object at 0x1775a2640>: [<PermuteBackward0 object at 0x1775a2910>], <AccumulateGrad object at 0x1775a2670>: [], <PermuteBackward0 object at 0x1775a26a0>: [<UnsafeViewBackward0 object at 0x1775a2940>], <GeluBackward0 object at 0x1775a26d0>: [<SliceBackward0 object at 0x1775a2970>], <SliceBackward0 object at 0x1775a2700>: [<SliceBackward0 object at 0x1775a29a0>], <AccumulateGrad object at 0x1775a2730>: [], <AddmmBackward0 object at 0x1775a2760>: [<AccumulateGrad object at 0x1775a29d0>, <ViewBackward0 object at 0x1775a2a00>, <TBackward0 object at 0x1775a2a30>], <NativeLayerNormBackward0 object at 0x1775a2790>: [<AddBackward0 object at 0x1775a2a60>, <AccumulateGrad object at 0x1775a2a90>, <AccumulateGrad object at 0x1775a2ac0>], <SliceBackward0 object at 0x1775a27c0>: [<ViewBackward0 object at 0x177599550>], <SliceBackward0 object at 0x1775a27f0>: [<ViewBackward0 object at 0x177599550>], <SliceBackward0 object at 0x1775a2820>: [<SliceBackward0 object at 0x1775a2af0>], <SliceBackward0 object at 0x1775a2850>: [<SliceBackward0 object at 0x1775a2b20>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b140>: [<AddmmBackward0 object at 0x1775a2b50>, None], <BmmBackward0 object at 0x1775a2880>: [<ReshapeAliasBackward0 object at 0x1775a2b80>, <ReshapeAliasBackward0 object at 0x1775a2bb0>], <SliceBackward0 object at 0x1775a28b0>: [<SliceBackward0 object at 0x1775a2be0>], <SoftmaxBackward0 object at 0x1775a28e0>: [<AddBackward0 object at 0x1775a2c10>], <PermuteBackward0 object at 0x1775a2910>: [<SliceBackward0 object at 0x1775a2c40>], <UnsafeViewBackward0 object at 0x1775a2940>: [<BmmBackward0 object at 0x1775a2c70>], <SliceBackward0 object at 0x1775a2970>: [<SliceBackward0 object at 0x1775a2ca0>], <SliceBackward0 object at 0x1775a29a0>: [<MmBackward0 object at 0x1775a2cd0>], <AccumulateGrad object at 0x1775a29d0>: [], <ViewBackward0 object at 0x1775a2a00>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x177430840>], <TBackward0 object at 0x1775a2a30>: [<AccumulateGrad object at 0x1775a2d00>], <AddBackward0 object at 0x1775a2a60>: [<AddmmBackward0 object at 0x1775a2d30>, <NativeLayerNormBackward0 object at 0x1775a2d60>], <AccumulateGrad object at 0x1775a2a90>: [], <AccumulateGrad object at 0x1775a2ac0>: [], <SliceBackward0 object at 0x1775a2af0>: [<SelectBackward0 object at 0x1775a2d90>], <SliceBackward0 object at 0x1775a2b20>: [<SelectBackward0 object at 0x1775a2dc0>], <AddmmBackward0 object at 0x1775a2b50>: [<AccumulateGrad object at 0x1775a2df0>, <NativeLayerNormBackward0 object at 0x17759e490>, <TBackward0 object at 0x1775a2e20>], <ReshapeAliasBackward0 object at 0x1775a2b80>: [<ExpandBackward0 object at 0x1775a2e50>], <ReshapeAliasBackward0 object at 0x1775a2bb0>: [<ExpandBackward0 object at 0x1775a2e80>], <SliceBackward0 object at 0x1775a2be0>: [<ViewBackward0 object at 0x1775a2eb0>], <AddBackward0 object at 0x1775a2c10>: [<DivBackward0 object at 0x1775a2ee0>, None], <SliceBackward0 object at 0x1775a2c40>: [<SliceBackward0 object at 0x1775a2f10>], <BmmBackward0 object at 0x1775a2c70>: [<ViewBackward0 object at 0x1775a2f40>, <ReshapeAliasBackward0 object at 0x1775a2f70>], <SliceBackward0 object at 0x1775a2ca0>: [<MmBackward0 object at 0x1775a2cd0>], <MmBackward0 object at 0x1775a2cd0>: [<NativeLayerNormBackward0 object at 0x1775a20d0>, <TBackward0 object at 0x1775a2fa0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x177430840>: [<ReshapeAliasBackward0 object at 0x1775a2fd0>, None], <AccumulateGrad object at 0x1775a2d00>: [], <AddmmBackward0 object at 0x1775a2d30>: [<AccumulateGrad object at 0x177dc4040>, <MulBackward0 object at 0x177dc4070>, <TBackward0 object at 0x177dc40a0>], <NativeLayerNormBackward0 object at 0x1775a2d60>: [<AddBackward0 object at 0x177dc40d0>, <AccumulateGrad object at 0x177dc4100>, <AccumulateGrad object at 0x177dc4130>], <SelectBackward0 object at 0x1775a2d90>: [<SliceBackward0 object at 0x177dc4160>], <SelectBackward0 object at 0x1775a2dc0>: [<SliceBackward0 object at 0x177dc4190>], <AccumulateGrad object at 0x1775a2df0>: [], <TBackward0 object at 0x1775a2e20>: [<AccumulateGrad object at 0x177dc41c0>], <ExpandBackward0 object at 0x1775a2e50>: [<PermuteBackward0 object at 0x177dc41f0>], <ExpandBackward0 object at 0x1775a2e80>: [<PermuteBackward0 object at 0x177dc4220>], <ViewBackward0 object at 0x1775a2eb0>: [<ViewBackward0 object at 0x177dc4250>], <DivBackward0 object at 0x1775a2ee0>: [<UnsafeViewBackward0 object at 0x177dc4280>, None], <SliceBackward0 object at 0x1775a2f10>: [<SelectBackward0 object at 0x177dc42b0>], <ViewBackward0 object at 0x1775a2f40>: [<ExpandBackward0 object at 0x177dc42e0>], <ReshapeAliasBackward0 object at 0x1775a2f70>: [<ExpandBackward0 object at 0x177dc4310>], <TBackward0 object at 0x1775a2fa0>: [<AccumulateGrad object at 0x177dc4340>], <ReshapeAliasBackward0 object at 0x1775a2fd0>: [<PermuteBackward0 object at 0x177dc4370>], <AccumulateGrad object at 0x177dc4040>: [], <MulBackward0 object at 0x177dc4070>: [<GeluBackward0 object at 0x177dc43a0>, <SliceBackward0 object at 0x177dc43d0>], <TBackward0 object at 0x177dc40a0>: [<AccumulateGrad object at 0x177dc4400>], <AddBackward0 object at 0x177dc40d0>: [<AddmmBackward0 object at 0x177dc4430>, <torch.autograd.function.IndexFirstAxisBackward object at 0x1773b8e40>], <AccumulateGrad object at 0x177dc4100>: [], <AccumulateGrad object at 0x177dc4130>: [], <SliceBackward0 object at 0x177dc4160>: [<SliceBackward0 object at 0x177dc4460>], <SliceBackward0 object at 0x177dc4190>: [<SliceBackward0 object at 0x177dc4490>], <AccumulateGrad object at 0x177dc41c0>: [], <PermuteBackward0 object at 0x177dc41f0>: [<SliceBackward0 object at 0x177dc44c0>], <PermuteBackward0 object at 0x177dc4220>: [<SliceBackward0 object at 0x177dc44f0>], <ViewBackward0 object at 0x177dc4250>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430e40>], <UnsafeViewBackward0 object at 0x177dc4280>: [<BmmBackward0 object at 0x177dc4520>], <SelectBackward0 object at 0x177dc42b0>: [<SliceBackward0 object at 0x177dc4550>], <ExpandBackward0 object at 0x177dc42e0>: [<SoftmaxBackward0 object at 0x177dc4580>], <ExpandBackward0 object at 0x177dc4310>: [<PermuteBackward0 object at 0x177dc45b0>], <AccumulateGrad object at 0x177dc4340>: [], <PermuteBackward0 object at 0x177dc4370>: [<UnsafeViewBackward0 object at 0x177dc45e0>], <GeluBackward0 object at 0x177dc43a0>: [<SliceBackward0 object at 0x177dc4610>], <SliceBackward0 object at 0x177dc43d0>: [<SliceBackward0 object at 0x177dc4640>], <AccumulateGrad object at 0x177dc4400>: [], <AddmmBackward0 object at 0x177dc4430>: [<AccumulateGrad object at 0x177dc4670>, <ViewBackward0 object at 0x177dc46a0>, <TBackward0 object at 0x177dc46d0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x1773b8e40>: [<ViewBackward0 object at 0x177dc4700>, None], <SliceBackward0 object at 0x177dc4460>: [<ViewBackward0 object at 0x1775a2220>], <SliceBackward0 object at 0x177dc4490>: [<ViewBackward0 object at 0x1775a2220>], <SliceBackward0 object at 0x177dc44c0>: [<SliceBackward0 object at 0x177dc4730>], <SliceBackward0 object at 0x177dc44f0>: [<SliceBackward0 object at 0x177dc4760>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430e40>: [<AddmmBackward0 object at 0x177dc4790>, None], <BmmBackward0 object at 0x177dc4520>: [<ReshapeAliasBackward0 object at 0x177dc47c0>, <ReshapeAliasBackward0 object at 0x177dc47f0>], <SliceBackward0 object at 0x177dc4550>: [<SliceBackward0 object at 0x177dc4820>], <SoftmaxBackward0 object at 0x177dc4580>: [<AddBackward0 object at 0x177dc4850>], <PermuteBackward0 object at 0x177dc45b0>: [<SliceBackward0 object at 0x177dc4880>], <UnsafeViewBackward0 object at 0x177dc45e0>: [<BmmBackward0 object at 0x177dc48b0>], <SliceBackward0 object at 0x177dc4610>: [<SliceBackward0 object at 0x177dc48e0>], <SliceBackward0 object at 0x177dc4640>: [<MmBackward0 object at 0x177dc4910>], <AccumulateGrad object at 0x177dc4670>: [], <ViewBackward0 object at 0x177dc46a0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x177430040>], <TBackward0 object at 0x177dc46d0>: [<AccumulateGrad object at 0x177dc4940>], <ViewBackward0 object at 0x177dc4700>: [<NativeLayerNormBackward0 object at 0x177dc4970>], <SliceBackward0 object at 0x177dc4730>: [<SelectBackward0 object at 0x177dc49a0>], <SliceBackward0 object at 0x177dc4760>: [<SelectBackward0 object at 0x177dc49d0>], <AddmmBackward0 object at 0x177dc4790>: [<AccumulateGrad object at 0x177dc4a00>, <NativeLayerNormBackward0 object at 0x1775a3160>, <TBackward0 object at 0x177dc4a30>], <ReshapeAliasBackward0 object at 0x177dc47c0>: [<ExpandBackward0 object at 0x177dc4a60>], <ReshapeAliasBackward0 object at 0x177dc47f0>: [<ExpandBackward0 object at 0x177dc4a90>], <SliceBackward0 object at 0x177dc4820>: [<ViewBackward0 object at 0x177dc4ac0>], <AddBackward0 object at 0x177dc4850>: [<DivBackward0 object at 0x177dc4af0>, None], <SliceBackward0 object at 0x177dc4880>: [<SliceBackward0 object at 0x177dc4b20>], <BmmBackward0 object at 0x177dc48b0>: [<ViewBackward0 object at 0x177dc4b50>, <ReshapeAliasBackward0 object at 0x177dc4b80>], <SliceBackward0 object at 0x177dc48e0>: [<MmBackward0 object at 0x177dc4910>], <MmBackward0 object at 0x177dc4910>: [<NativeLayerNormBackward0 object at 0x1775a2d60>, <TBackward0 object at 0x177dc4bb0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x177430040>: [<ReshapeAliasBackward0 object at 0x177dc4be0>, None], <AccumulateGrad object at 0x177dc4940>: [], <NativeLayerNormBackward0 object at 0x177dc4970>: [<AddBackward0 object at 0x177dc4c10>, <AccumulateGrad object at 0x177dc4c40>, <AccumulateGrad object at 0x177dc4c70>], <SelectBackward0 object at 0x177dc49a0>: [<SliceBackward0 object at 0x177dc4ca0>], <SelectBackward0 object at 0x177dc49d0>: [<SliceBackward0 object at 0x177dc4cd0>], <AccumulateGrad object at 0x177dc4a00>: [], <TBackward0 object at 0x177dc4a30>: [<AccumulateGrad object at 0x177dc4d00>], <ExpandBackward0 object at 0x177dc4a60>: [<PermuteBackward0 object at 0x177dc4d30>], <ExpandBackward0 object at 0x177dc4a90>: [<PermuteBackward0 object at 0x177dc4d60>], <ViewBackward0 object at 0x177dc4ac0>: [<ViewBackward0 object at 0x177dc4d90>], <DivBackward0 object at 0x177dc4af0>: [<UnsafeViewBackward0 object at 0x177dc4dc0>, None], <SliceBackward0 object at 0x177dc4b20>: [<SelectBackward0 object at 0x177dc4df0>], <ViewBackward0 object at 0x177dc4b50>: [<ExpandBackward0 object at 0x177dc4e20>], <ReshapeAliasBackward0 object at 0x177dc4b80>: [<ExpandBackward0 object at 0x177dc4e50>], <TBackward0 object at 0x177dc4bb0>: [<AccumulateGrad object at 0x177dc4e80>], <ReshapeAliasBackward0 object at 0x177dc4be0>: [<PermuteBackward0 object at 0x177dc4eb0>], <AddBackward0 object at 0x177dc4c10>: [<EmbeddingBackward0 object at 0x177dc4ee0>, <EmbeddingBackward0 object at 0x177dc4f10>], <AccumulateGrad object at 0x177dc4c40>: [], <AccumulateGrad object at 0x177dc4c70>: [], <SliceBackward0 object at 0x177dc4ca0>: [<SliceBackward0 object at 0x177dc4f40>], <SliceBackward0 object at 0x177dc4cd0>: [<SliceBackward0 object at 0x177dc4f70>], <AccumulateGrad object at 0x177dc4d00>: [], <PermuteBackward0 object at 0x177dc4d30>: [<SliceBackward0 object at 0x177dc4fa0>], <PermuteBackward0 object at 0x177dc4d60>: [<SliceBackward0 object at 0x177dc4fd0>], <ViewBackward0 object at 0x177dc4d90>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430c40>], <UnsafeViewBackward0 object at 0x177dc4dc0>: [<BmmBackward0 object at 0x177dc9040>], <SelectBackward0 object at 0x177dc4df0>: [<SliceBackward0 object at 0x177dc9070>], <ExpandBackward0 object at 0x177dc4e20>: [<SoftmaxBackward0 object at 0x177dc90a0>], <ExpandBackward0 object at 0x177dc4e50>: [<PermuteBackward0 object at 0x177dc90d0>], <AccumulateGrad object at 0x177dc4e80>: [], <PermuteBackward0 object at 0x177dc4eb0>: [<UnsafeViewBackward0 object at 0x177dc9100>], <EmbeddingBackward0 object at 0x177dc4ee0>: [<AccumulateGrad object at 0x177dc9130>], <EmbeddingBackward0 object at 0x177dc4f10>: [<AccumulateGrad object at 0x177dc9160>], <SliceBackward0 object at 0x177dc4f40>: [<ViewBackward0 object at 0x1775a2eb0>], <SliceBackward0 object at 0x177dc4f70>: [<ViewBackward0 object at 0x1775a2eb0>], <SliceBackward0 object at 0x177dc4fa0>: [<SliceBackward0 object at 0x177dc9190>], <SliceBackward0 object at 0x177dc4fd0>: [<SliceBackward0 object at 0x177dc91c0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430c40>: [<AddmmBackward0 object at 0x177dc91f0>, None], <BmmBackward0 object at 0x177dc9040>: [<ReshapeAliasBackward0 object at 0x177dc9220>, <ReshapeAliasBackward0 object at 0x177dc9250>], <SliceBackward0 object at 0x177dc9070>: [<SliceBackward0 object at 0x177dc9280>], <SoftmaxBackward0 object at 0x177dc90a0>: [<AddBackward0 object at 0x177dc92b0>], <PermuteBackward0 object at 0x177dc90d0>: [<SliceBackward0 object at 0x177dc92e0>], <UnsafeViewBackward0 object at 0x177dc9100>: [<BmmBackward0 object at 0x177dc9310>], <AccumulateGrad object at 0x177dc9130>: [], <AccumulateGrad object at 0x177dc9160>: [], <SliceBackward0 object at 0x177dc9190>: [<SelectBackward0 object at 0x177dc9340>], <SliceBackward0 object at 0x177dc91c0>: [<SelectBackward0 object at 0x177dc9370>], <AddmmBackward0 object at 0x177dc91f0>: [<AccumulateGrad object at 0x177dc93a0>, <NativeLayerNormBackward0 object at 0x1775a3df0>, <TBackward0 object at 0x177dc93d0>], <ReshapeAliasBackward0 object at 0x177dc9220>: [<ExpandBackward0 object at 0x177dc9400>], <ReshapeAliasBackward0 object at 0x177dc9250>: [<ExpandBackward0 object at 0x177dc9430>], <SliceBackward0 object at 0x177dc9280>: [<ViewBackward0 object at 0x177dc9460>], <AddBackward0 object at 0x177dc92b0>: [<DivBackward0 object at 0x177dc9490>, None], <SliceBackward0 object at 0x177dc92e0>: [<SliceBackward0 object at 0x177dc94c0>], <BmmBackward0 object at 0x177dc9310>: [<ViewBackward0 object at 0x177dc94f0>, <ReshapeAliasBackward0 object at 0x177dc9520>], <SelectBackward0 object at 0x177dc9340>: [<SliceBackward0 object at 0x177dc9550>], <SelectBackward0 object at 0x177dc9370>: [<SliceBackward0 object at 0x177dc9580>], <AccumulateGrad object at 0x177dc93a0>: [], <TBackward0 object at 0x177dc93d0>: [<AccumulateGrad object at 0x177dc95b0>], <ExpandBackward0 object at 0x177dc9400>: [<PermuteBackward0 object at 0x177dc95e0>], <ExpandBackward0 object at 0x177dc9430>: [<PermuteBackward0 object at 0x177dc9610>], <ViewBackward0 object at 0x177dc9460>: [<ViewBackward0 object at 0x177dc9640>], <DivBackward0 object at 0x177dc9490>: [<UnsafeViewBackward0 object at 0x177dc9670>, None], <SliceBackward0 object at 0x177dc94c0>: [<SelectBackward0 object at 0x177dc96a0>], <ViewBackward0 object at 0x177dc94f0>: [<ExpandBackward0 object at 0x177dc96d0>], <ReshapeAliasBackward0 object at 0x177dc9520>: [<ExpandBackward0 object at 0x177dc9700>], <SliceBackward0 object at 0x177dc9550>: [<SliceBackward0 object at 0x177dc9730>], <SliceBackward0 object at 0x177dc9580>: [<SliceBackward0 object at 0x177dc9760>], <AccumulateGrad object at 0x177dc95b0>: [], <PermuteBackward0 object at 0x177dc95e0>: [<SliceBackward0 object at 0x177dc9790>], <PermuteBackward0 object at 0x177dc9610>: [<SliceBackward0 object at 0x177dc97c0>], <ViewBackward0 object at 0x177dc9640>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430940>], <UnsafeViewBackward0 object at 0x177dc9670>: [<BmmBackward0 object at 0x177dc97f0>], <SelectBackward0 object at 0x177dc96a0>: [<SliceBackward0 object at 0x177dc9820>], <ExpandBackward0 object at 0x177dc96d0>: [<SoftmaxBackward0 object at 0x177dc9850>], <ExpandBackward0 object at 0x177dc9700>: [<PermuteBackward0 object at 0x177dc9880>], <SliceBackward0 object at 0x177dc9730>: [<ViewBackward0 object at 0x177dc4ac0>], <SliceBackward0 object at 0x177dc9760>: [<ViewBackward0 object at 0x177dc4ac0>], <SliceBackward0 object at 0x177dc9790>: [<SliceBackward0 object at 0x177dc98b0>], <SliceBackward0 object at 0x177dc97c0>: [<SliceBackward0 object at 0x177dc98e0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430940>: [<AddmmBackward0 object at 0x177dc9910>, None], <BmmBackward0 object at 0x177dc97f0>: [<ReshapeAliasBackward0 object at 0x177dc9940>, <ReshapeAliasBackward0 object at 0x177dc9970>], <SliceBackward0 object at 0x177dc9820>: [<SliceBackward0 object at 0x177dc99a0>], <SoftmaxBackward0 object at 0x177dc9850>: [<AddBackward0 object at 0x177dc99d0>], <PermuteBackward0 object at 0x177dc9880>: [<SliceBackward0 object at 0x177dc9a00>], <SliceBackward0 object at 0x177dc98b0>: [<SelectBackward0 object at 0x177dc9a30>], <SliceBackward0 object at 0x177dc98e0>: [<SelectBackward0 object at 0x177dc9a60>], <AddmmBackward0 object at 0x177dc9910>: [<AccumulateGrad object at 0x177dc9a90>, <NativeLayerNormBackward0 object at 0x177599ac0>, <TBackward0 object at 0x177dc9ac0>], <ReshapeAliasBackward0 object at 0x177dc9940>: [<ExpandBackward0 object at 0x177dc9af0>], <ReshapeAliasBackward0 object at 0x177dc9970>: [<ExpandBackward0 object at 0x177dc9b20>], <SliceBackward0 object at 0x177dc99a0>: [<ViewBackward0 object at 0x177dc9b50>], <AddBackward0 object at 0x177dc99d0>: [<DivBackward0 object at 0x177dc9b80>, None], <SliceBackward0 object at 0x177dc9a00>: [<SliceBackward0 object at 0x177dc9bb0>], <SelectBackward0 object at 0x177dc9a30>: [<SliceBackward0 object at 0x177dc9be0>], <SelectBackward0 object at 0x177dc9a60>: [<SliceBackward0 object at 0x177dc9c10>], <AccumulateGrad object at 0x177dc9a90>: [], <TBackward0 object at 0x177dc9ac0>: [<AccumulateGrad object at 0x177dc9c40>], <ExpandBackward0 object at 0x177dc9af0>: [<PermuteBackward0 object at 0x177dc9c70>], <ExpandBackward0 object at 0x177dc9b20>: [<PermuteBackward0 object at 0x177dc9ca0>], <ViewBackward0 object at 0x177dc9b50>: [<ViewBackward0 object at 0x177dc9cd0>], <DivBackward0 object at 0x177dc9b80>: [<UnsafeViewBackward0 object at 0x177dc9d00>, None], <SliceBackward0 object at 0x177dc9bb0>: [<SelectBackward0 object at 0x177dc9d30>], <SliceBackward0 object at 0x177dc9be0>: [<SliceBackward0 object at 0x177dc9d60>], <SliceBackward0 object at 0x177dc9c10>: [<SliceBackward0 object at 0x177dc9d90>], <AccumulateGrad object at 0x177dc9c40>: [], <PermuteBackward0 object at 0x177dc9c70>: [<SliceBackward0 object at 0x177dc9dc0>], <PermuteBackward0 object at 0x177dc9ca0>: [<SliceBackward0 object at 0x177dc9df0>], <ViewBackward0 object at 0x177dc9cd0>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430740>], <UnsafeViewBackward0 object at 0x177dc9d00>: [<BmmBackward0 object at 0x177dc9e20>], <SelectBackward0 object at 0x177dc9d30>: [<SliceBackward0 object at 0x177dc9e50>], <SliceBackward0 object at 0x177dc9d60>: [<ViewBackward0 object at 0x177dc9460>], <SliceBackward0 object at 0x177dc9d90>: [<ViewBackward0 object at 0x177dc9460>], <SliceBackward0 object at 0x177dc9dc0>: [<SliceBackward0 object at 0x177dc9e80>], <SliceBackward0 object at 0x177dc9df0>: [<SliceBackward0 object at 0x177dc9eb0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430740>: [<AddmmBackward0 object at 0x177dc9ee0>, None], <BmmBackward0 object at 0x177dc9e20>: [<ReshapeAliasBackward0 object at 0x177dc9f10>, <ReshapeAliasBackward0 object at 0x177dc9f40>], <SliceBackward0 object at 0x177dc9e50>: [<SliceBackward0 object at 0x177dc9f70>], <SliceBackward0 object at 0x177dc9e80>: [<SelectBackward0 object at 0x177dc9fa0>], <SliceBackward0 object at 0x177dc9eb0>: [<SelectBackward0 object at 0x177dc9fd0>], <AddmmBackward0 object at 0x177dc9ee0>: [<AccumulateGrad object at 0x177dc0040>, <NativeLayerNormBackward0 object at 0x1775a2790>, <TBackward0 object at 0x177dc0070>], <ReshapeAliasBackward0 object at 0x177dc9f10>: [<ExpandBackward0 object at 0x177dc00a0>], <ReshapeAliasBackward0 object at 0x177dc9f40>: [<ExpandBackward0 object at 0x177dc00d0>], <SliceBackward0 object at 0x177dc9f70>: [<ViewBackward0 object at 0x177dc0100>], <SelectBackward0 object at 0x177dc9fa0>: [<SliceBackward0 object at 0x177dc0130>], <SelectBackward0 object at 0x177dc9fd0>: [<SliceBackward0 object at 0x177dc0160>], <AccumulateGrad object at 0x177dc0040>: [], <TBackward0 object at 0x177dc0070>: [<AccumulateGrad object at 0x177dc0190>], <ExpandBackward0 object at 0x177dc00a0>: [<PermuteBackward0 object at 0x177dc01c0>], <ExpandBackward0 object at 0x177dc00d0>: [<PermuteBackward0 object at 0x177dc01f0>], <ViewBackward0 object at 0x177dc0100>: [<ViewBackward0 object at 0x177dc0220>], <SliceBackward0 object at 0x177dc0130>: [<SliceBackward0 object at 0x177dc0250>], <SliceBackward0 object at 0x177dc0160>: [<SliceBackward0 object at 0x177dc0280>], <AccumulateGrad object at 0x177dc0190>: [], <PermuteBackward0 object at 0x177dc01c0>: [<SliceBackward0 object at 0x177dc02b0>], <PermuteBackward0 object at 0x177dc01f0>: [<SliceBackward0 object at 0x177dc02e0>], <ViewBackward0 object at 0x177dc0220>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430b40>], <SliceBackward0 object at 0x177dc0250>: [<ViewBackward0 object at 0x177dc9b50>], <SliceBackward0 object at 0x177dc0280>: [<ViewBackward0 object at 0x177dc9b50>], <SliceBackward0 object at 0x177dc02b0>: [<SliceBackward0 object at 0x177dc0310>], <SliceBackward0 object at 0x177dc02e0>: [<SliceBackward0 object at 0x177dc0340>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430b40>: [<AddmmBackward0 object at 0x177dc0370>, None], <SliceBackward0 object at 0x177dc0310>: [<SelectBackward0 object at 0x177dc03a0>], <SliceBackward0 object at 0x177dc0340>: [<SelectBackward0 object at 0x177dc03d0>], <AddmmBackward0 object at 0x177dc0370>: [<AccumulateGrad object at 0x177dc0400>, <torch.autograd.function.IndexFirstAxisBackward object at 0x1773b8e40>, <TBackward0 object at 0x177dc0430>], <SelectBackward0 object at 0x177dc03a0>: [<SliceBackward0 object at 0x177dc0460>], <SelectBackward0 object at 0x177dc03d0>: [<SliceBackward0 object at 0x177dc0490>], <AccumulateGrad object at 0x177dc0400>: [], <TBackward0 object at 0x177dc0430>: [<AccumulateGrad object at 0x177dc04c0>], <SliceBackward0 object at 0x177dc0460>: [<SliceBackward0 object at 0x177dc04f0>], <SliceBackward0 object at 0x177dc0490>: [<SliceBackward0 object at 0x177dc0520>], <AccumulateGrad object at 0x177dc04c0>: [], <SliceBackward0 object at 0x177dc04f0>: [<ViewBackward0 object at 0x177dc0100>], <SliceBackward0 object at 0x177dc0520>: [<ViewBackward0 object at 0x177dc0100>]}\n"
     ]
    }
   ],
   "source": [
    "for k, v in list(in_adj.items()):\n",
    "    if k == \"AddMmBackward0\" or \"AddMmBackward0\" in v:\n",
    "        print(k, v)\n",
    "print(out_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22ad4bb0-b096-4fa0-ab69-6fc7d0f5c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 768)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited[-137]._saved_self_sym_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b9840b0-c76e-406b-aae4-ac09696f1ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([768, 768]),\n",
       " torch.Size([2304, 768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([2304]),\n",
       " torch.Size([2304, 768]),\n",
       " torch.Size([2304]),\n",
       " torch.Size([2304, 768]),\n",
       " torch.Size([2304]),\n",
       " torch.Size([2304, 768])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ acc.variable.shape for acc in visited[-10:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8529ba4e-295a-42b7-b94f-839e0af7436d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_input_metadata',\n",
       " '_raw_saved_mat1',\n",
       " '_raw_saved_mat2',\n",
       " '_register_hook_dict',\n",
       " '_saved_alpha',\n",
       " '_saved_beta',\n",
       " '_saved_mat1',\n",
       " '_saved_mat1_sym_sizes',\n",
       " '_saved_mat1_sym_strides',\n",
       " '_saved_mat2',\n",
       " '_saved_mat2_sym_sizes',\n",
       " '_saved_mat2_sym_strides',\n",
       " '_sequence_nr',\n",
       " '_set_sequence_nr',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'next_functions',\n",
       " 'register_hook',\n",
       " 'register_prehook',\n",
       " 'requires_grad']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visited[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a8c0415-fe5d-4a32-a933-82cc69fed2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18446744073709551615"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8565c-7fca-43dc-b6be-015cf0bf1259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f620ab94-4522-4f70-802f-234f15583ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 3072 9223372036854775807\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "for fcn in visited:\n",
    "    if fcn.name() == \"SliceBackward0\" and not (fcn._saved_start == 0 and fcn._saved_end == 9223372036854775807):\n",
    "        print(fcn._saved_dim, fcn._saved_start, fcn._saved_end)\n",
    "print(len([ fcn for fcn in visited if fcn.name() == \"SliceBackward0\" ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "59e14e31-cfe9-40b5-a9ad-ac8380c606bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_input_metadata',\n",
       " '_register_hook_dict',\n",
       " '_saved_dim',\n",
       " '_saved_end',\n",
       " '_saved_self_sym_sizes',\n",
       " '_saved_start',\n",
       " '_saved_step',\n",
       " '_sequence_nr',\n",
       " '_set_sequence_nr',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'next_functions',\n",
       " 'register_hook',\n",
       " 'register_prehook',\n",
       " 'requires_grad']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visited[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4e7f0bb6-6b3b-492b-ba9b-0e9f94b00ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited[3]._saved_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b4122ca7-6985-429f-ab55-5ca4f2a31833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1706, 0.8294])\n",
      "((<AccumulateGrad object at 0x17a75efa0>, 0), (<AddBackward0 object at 0x130051940>, 0))\n",
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_input_metadata', '_register_hook_dict', '_saved_alpha', '_sequence_nr', '_set_sequence_nr', 'metadata', 'name', 'next_functions', 'register_hook', 'register_prehook', 'requires_grad']\n",
      "<AddBackward0 object at 0x13005a940>\n",
      "((<AddBackward0 object at 0x1300111f0>, 0), (None, 0))\n",
      "True\n",
      "((<AccumulateGrad object at 0x1300111f0>, 0), (<MulBackward0 object at 0x13005a940>, 0))\n",
      "None\n",
      "((<AccumulateGrad object at 0x1300111f0>, 0), (None, 0))\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, requires_grad=True)\n",
    "b = a*(a + a * 2 + 2)\n",
    "multa = b.grad_fn._saved_self\n",
    "multb = b.grad_fn._saved_other\n",
    "with torch.no_grad():\n",
    "    print(torch.concat((multa, multb)) / (multa + multb))\n",
    "print (b.grad_fn.next_functions)\n",
    "print(dir(b.grad_fn.next_functions[1][0]))\n",
    "print(b.grad_fn.next_functions[1][0])\n",
    "print (b.grad_fn.next_functions[1][0].next_functions)\n",
    "print (b.grad_fn.next_functions[0][0].variable is a)\n",
    "print(b.grad_fn.next_functions[1][0].next_functions[0][0].next_functions)\n",
    "print(b.grad_fn.next_functions[1][0].next_functions[0][0].next_functions[1][0]._saved_self)\n",
    "print(b.grad_fn.next_functions[1][0].next_functions[0][0].next_functions[1][0].next_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0d56d-0b51-4304-8145-5833989505d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
