@article{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  journal={International Conference on Machine Learning},
  year={2017},
  pages={3319--3328}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in Neural Information Processing Systems},
  year={2017},
  pages={4765--4774}
}

@article{bach2015pixel,
  title={Pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\"e}goire and others},
  journal={PLoS ONE},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015}
}

@article{achtibat2024attnlrp,
  title={AttnLRP: Attention-Aware Layer-wise Relevance Propagation for Transformers},
  author={Achtibat, Reduan and Hatefi, Sayed Mohammad Vakilzadeh and Dreyer, Maximilian and others},
  journal={arXiv preprint arXiv:2402.05602},
  year={2024}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{clark2019does,
  title={What does BERT look at? an analysis of BERT's attention},
  author={Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and Manning, Christopher D},
  journal={Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={276--286},
  year={2019}
}

@article{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and others},
  journal={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9650--9660},
  year={2021}
}

@article{wiegreffe2019attention,
  title={Attention is not explanation},
  author={Wiegreffe, Sarah and Pinter, Yuval},
  journal={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={11--20},
  year={2019}
}

@article{geva2021transformer,
  title={Transformer feed-forward layers are key-value memories},
  author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  journal={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={5484--5495},
  year={2021}
}

@article{dai2022knowledge,
  title={Knowledge neurons in pretrained transformers},
  author={Dai, Damai and Dong, Li and Hao, Yaru and others},
  journal={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8493--8502},
  year={2022}
}

@article{simonyan2014deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2014}
}

@article{ding2017saliency,
  title={Visualizing and understanding neural machine translation},
  author={Ding, Yanzhuo and Liu, Yang and Luan, Huanbo and Sun, Maosong},
  journal={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1150--1159},
  year={2017}
}

@article{voita2021analyzing,
  title={Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned},
  author={Voita, Elena and Talbot, David and Moiseev, Fedor and others},
  journal={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={5797--5808},
  year={2019}
}

@article{montavon2017explaining,
  title={Explaining nonlinear classification decisions with deep taylor decomposition},
  author={Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Binder, Alexander and others},
  journal={Pattern recognition},
  volume={65},
  pages={211--222},
  year={2017}
}

@article{machiraju2024prospector,
  title={Prospector Heads: Generalized Feature Attribution for Large Models \& Data},
  author={Machiraju, Gautam and Derry, Alexander and Desai, Arjun and others},
  journal={Proceedings of the 41st International Conference on Machine Learning},
  year={2024}
}