{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c295041-1116-4c05-b2f0-23d2e0746417",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d9b149-abf8-47ae-a1c9-96aac7413bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2808c6-a097-4f82-8caa-b3b5c0af5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91fc1cf7-88b0-44e0-bf7d-2f9847446536",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"deepset/roberta-large-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57aaaffe-d80b-4b71-92cd-021135a3be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrp_engine import LRPEngine, checkpoint_hook\n",
    "from lrp_engine.lrp_graph import make_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d42d521-92f7-4113-998f-b41e6cfc898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp = LRPEngine(topk=1, use_gamma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdbf46d9-20c6-4f12-b229-00bba0aea00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Welcome to the final examination for this term's offering of CS100. Please remove all headphones and earbuds, as well as hats and hoods. Place your bag under your desk so that it does not block the aisle. You are permitted writing instruments, a clear water bottle, and any aids listed on the front of your booklet. The exam will be 150 minutes in duration. You may now begin.\"\n",
    "question = \"What is this?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41963cf-22b1-484a-8fea-5ac704924cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(question, context, return_tensors=\"pt\")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d90c7e97-81ec-4f98-998f-e1470ff63d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62cc6912-b5ce-447d-b51a-8ef73bbedbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccumulateGrad',\n",
       " 'AddBackward0',\n",
       " 'CloneBackward0',\n",
       " 'CopySlices',\n",
       " 'EmbeddingBackward0',\n",
       " 'GeluBackward0',\n",
       " 'MmBackward0',\n",
       " 'NativeLayerNormBackward0',\n",
       " 'PermuteBackward0',\n",
       " 'ScaledDotProductEfficientAttentionBackward0',\n",
       " 'SplitBackward0',\n",
       " 'SqueezeBackward1',\n",
       " 'TBackward0',\n",
       " 'TransposeBackward0',\n",
       " 'ViewBackward0'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = make_graph(output.start_logits)\n",
    "g[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b7dd6c-ff13-43b3-9b2f-ff1c5ea60dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " final examination\n"
     ]
    }
   ],
   "source": [
    "start = torch.argmax(output.start_logits)\n",
    "end = torch.argmax(output.end_logits) + 1\n",
    "\n",
    "answer_tokens = input_ids[0][start:end]\n",
    "answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01621a0d-4570-4045-ba61-b2be11860e76",
   "metadata": {},
   "source": [
    "# Dummy Test (Don't run if you want to run the full SQuADv2 evaluation below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9075ce57-ffc4-47e4-b1e9-b5e007eedccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_vals, param_vals = lrp.run((output.start_logits, output.end_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c35bd78-e64e-4a89-82f9-0986d90602c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_vals1, param_vals1 = lrp.run((output.start_logits, output.end_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4a2b634-0587-4980-9ff5-c101348fd9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results diff between 1st pass and 2nd pass on same input (should be ~0)\n",
    "[\n",
    "    ((p1 - p0)**2).sum() for p1, p0 in zip(param_vals1, param_vals)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cb86fbe-d9af-4ec9-8d12-f3782ff7c78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " well under listed 150s\n"
     ]
    }
   ],
   "source": [
    "# Top 5 tokens from LRP\n",
    "lrp_answer_ids = input_ids[0][param_vals[1].flatten().topk(k=5).indices.cpu()]\n",
    "print(tokenizer.decode(lrp_answer_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1681f2-5dc4-4900-bf40-4e5f7ec4f5c9",
   "metadata": {},
   "source": [
    "# SQuADv2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d83cc306-6dc2-4fca-8ae3-4393690a6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp.starting_relevance=None\n",
    "lrp.topk=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2835809-0876-4a74-896a-6758035fb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03606f64-864d-4ecf-8274-18b82943144f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                            | 217/11873 [00:27<18:04, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 23 100\n",
      "tensor(0.5099, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                           | 429/11873 [00:52<20:07,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 28 200\n",
      "tensor(0.5025, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                         | 643/11873 [01:18<20:53,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253 41 300\n",
      "tensor(0.4810, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                        | 829/11873 [01:43<28:06,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 56 400\n",
      "tensor(0.5099, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▋                                                                      | 1022/11873 [02:09<26:42,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430 69 500\n",
      "tensor(0.5234, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▊                                                                     | 1214/11873 [02:35<27:11,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513 78 600\n",
      "tensor(0.5235, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▏                                                                   | 1419/11873 [03:01<17:34,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602 97 700\n",
      "tensor(0.5179, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▍                                                                  | 1614/11873 [03:28<35:09,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682 119 800\n",
      "tensor(0.5045, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▊                                                                 | 1812/11873 [03:56<18:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764 137 900\n",
      "tensor(0.4990, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████                                                                | 2016/11873 [04:23<23:05,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855 147 1000\n",
      "tensor(0.5067, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▍                                                              | 2227/11873 [04:49<16:45,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945 160 1100\n",
      "tensor(0.5122, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                             | 2390/11873 [05:16<20:50,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023 176 1200\n",
      "tensor(0.5084, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▋                                                            | 2570/11873 [05:43<23:16,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1101 189 1300\n",
      "tensor(0.5029, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████                                                           | 2790/11873 [06:09<18:28,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1189 201 1400\n",
      "tensor(0.4985, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                         | 2991/11873 [06:36<23:22,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 208 1500\n",
      "tensor(0.4958, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████                                                         | 3100/11873 [07:00<47:17,  3.09it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
      " 27%|████████████████████▌                                                        | 3177/11873 [07:08<16:06,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1361 213 1600\n",
      "tensor(0.4916, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████                                                       | 3411/11873 [07:39<23:24,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1447 223 1700\n",
      "tensor(0.4917, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████                                                      | 3555/11873 [08:05<18:38,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534 246 1800\n",
      "tensor(0.4913, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▏                                                    | 3728/11873 [08:33<27:19,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1608 262 1900\n",
      "tensor(0.4885, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████▌                                                   | 3933/11873 [09:01<25:02,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1691 286 2000\n",
      "tensor(0.4824, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▊                                                  | 4137/11873 [09:28<25:28,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1775 300 2100\n",
      "tensor(0.4851, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████▊                                                | 4438/11873 [09:57<05:42, 21.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1836 316 2200\n",
      "tensor(0.4679, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▌                                              | 4714/11873 [10:24<19:39,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1906 327 2300\n",
      "tensor(0.4564, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████▏                                            | 4958/11873 [10:51<07:04, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986 343 2400\n",
      "tensor(0.4557, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████                                           | 5245/11873 [11:17<14:35,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2071 362 2500\n",
      "tensor(0.4582, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████▎                                         | 5439/11873 [11:45<11:28,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149 369 2600\n",
      "tensor(0.4552, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████▏                                        | 5589/11873 [12:11<25:12,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2228 386 2700\n",
      "tensor(0.4535, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████▍                                       | 5776/11873 [12:40<09:02, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2301 392 2800\n",
      "tensor(0.4465, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████▉                                      | 6012/11873 [13:06<12:15,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2391 402 2900\n",
      "tensor(0.4496, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████▎                                    | 6223/11873 [13:41<26:33,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2483 422 3000\n",
      "tensor(0.4522, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████████▉                                   | 6458/11873 [14:27<13:16,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2566 444 3100\n",
      "tensor(0.4547, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████▏                                 | 6661/11873 [15:13<26:14,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2651 454 3200\n",
      "tensor(0.4558, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████▎                                | 6826/11873 [15:59<35:05,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2735 464 3300\n",
      "tensor(0.4576, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████████▍                               | 7000/11873 [16:48<17:50,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825 476 3400\n",
      "tensor(0.4592, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████▋                              | 7200/11873 [17:35<22:19,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910 478 3500\n",
      "tensor(0.4604, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████                             | 7403/11873 [18:21<21:22,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3002 491 3600\n",
      "tensor(0.4622, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████████▎                           | 7611/11873 [19:08<11:39,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3090 515 3700\n",
      "tensor(0.4632, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████▋                          | 7807/11873 [19:54<13:52,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3168 538 3800\n",
      "tensor(0.4643, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████▉                         | 8002/11873 [20:40<15:42,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3250 561 3900\n",
      "tensor(0.4638, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|█████████████████████████████████████████████████████▏                       | 8210/11873 [21:26<11:16,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3332 591 4000\n",
      "tensor(0.4650, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████▋                      | 8429/11873 [22:13<09:37,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3412 618 4100\n",
      "tensor(0.4664, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████                     | 8639/11873 [22:59<08:52,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3496 634 4200\n",
      "tensor(0.4661, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████▍                   | 8848/11873 [23:46<08:19,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3578 643 4300\n",
      "tensor(0.4661, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████▌                  | 9037/11873 [24:32<19:41,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3656 659 4400\n",
      "tensor(0.4660, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████▋                 | 9195/11873 [25:19<09:31,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3746 670 4500\n",
      "tensor(0.4673, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████▊                | 9379/11873 [26:05<07:41,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3832 699 4600\n",
      "tensor(0.4675, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████               | 9572/11873 [26:51<11:57,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3922 709 4700\n",
      "tensor(0.4670, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████▎             | 9765/11873 [27:38<11:55,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4006 716 4800\n",
      "tensor(0.4669, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████▌            | 9960/11873 [28:24<05:11,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4095 724 4900\n",
      "tensor(0.4669, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████▉           | 10149/11873 [29:10<08:53,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4182 732 5000\n",
      "tensor(0.4675, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████▎         | 10354/11873 [29:57<05:09,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4266 738 5100\n",
      "tensor(0.4674, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████▌        | 10550/11873 [30:43<04:46,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4348 750 5200\n",
      "tensor(0.4672, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████▊       | 10741/11873 [31:30<05:22,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4434 769 5300\n",
      "tensor(0.4681, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████      | 10947/11873 [32:16<03:21,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4517 783 5400\n",
      "tensor(0.4687, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████▍    | 11157/11873 [33:02<01:49,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4599 797 5500\n",
      "tensor(0.4692, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████▉   | 11394/11873 [33:48<01:32,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672 808 5600\n",
      "tensor(0.4667, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████▎ | 11603/11873 [34:35<01:18,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4753 821 5700\n",
      "tensor(0.4653, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████▌| 11798/11873 [35:21<00:13,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4843 831 5800\n",
      "tensor(0.4658, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11873/11873 [35:40<00:00,  5.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "top1_label_hits = 0\n",
    "top1_model_hits = 0\n",
    "total_examples = 0\n",
    "total_intersect = 0\n",
    "total_union = 0\n",
    "\n",
    "for example in tqdm(dataset[\"validation\"]):\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = example[\"answers\"][\"text\"]\n",
    "\n",
    "    if not answers:\n",
    "        continue\n",
    "\n",
    "    input_ids = tokenizer(context + \" \" + question, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    if input_ids.shape[-1] > 512:\n",
    "        continue\n",
    "\n",
    "    input_ids = tokenizer(question, context, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    output = model(input_ids.to(device))\n",
    "\n",
    "    start = torch.argmax(output.start_logits[:,1:]) + 1\n",
    "    end = torch.argmax(output.end_logits[:,1:]) + 2\n",
    "    if start > end:\n",
    "        continue\n",
    "    model_answer = tokenizer.decode(input_ids[0][start:end], skip_special_tokens=True)\n",
    "    if model_answer == \"\":\n",
    "        continue\n",
    "    # output = run_flan_encode_decode(input_ids)\n",
    "\n",
    "    lrp.topk = end - start\n",
    "    if (end - start) > output.start_logits.shape[-1]:\n",
    "        print(start, end)\n",
    "        print(output.start_logits.shape)\n",
    "        break\n",
    "\n",
    "    lrp_input1, lrp_input2 = output.start_logits, output.end_logits\n",
    "    lrp_input1[0][0] = 0\n",
    "    lrp_input2[0][0] = 0\n",
    "    checkpoint_vals, param_vals = lrp.run((lrp_input1, lrp_input2))\n",
    "\n",
    "    lrp_max = param_vals[1].flatten()[1:].argmax() + 1\n",
    "    lrp_top_token = tokenizer.convert_ids_to_tokens([input_ids[0][lrp_max]])[0].strip().replace(chr(9601), \"\")\n",
    "\n",
    "    # Do model answer-based accuracy, i.e. is the attribution aligned with the model prediction\n",
    "    if start <= lrp_max <= end:\n",
    "        top1_model_hits += 1\n",
    "\n",
    "    # Do IoU with the model prediction\n",
    "    intersect = 0\n",
    "    union = lrp.topk\n",
    "    for top_ind in param_vals[1].flatten()[1:].topk(lrp.topk).indices:\n",
    "        top_ind = top_ind + 1\n",
    "        if start <= top_ind <= end:\n",
    "            intersect += 1\n",
    "        else:\n",
    "            union += 1\n",
    "    total_intersect += intersect\n",
    "    total_union += union\n",
    "\n",
    "    # Do label-based accuracy\n",
    "    if any(lrp_top_token in ans for ans in answers):\n",
    "        # Is the attribution aligned with the ground truth label\n",
    "        top1_label_hits += 1\n",
    "    total_examples += 1\n",
    "    if not (total_examples % 100):\n",
    "        print(top1_model_hits, top1_label_hits, total_examples)\n",
    "        print(total_intersect / total_union)\n",
    "    # lrp_top5 = param_vals[2].flatten().topk(k=5)\n",
    "    # lrp_top5_tokens = tokenizer.decode(input_ids[0][lrp_top5.indices.cpu()])\n",
    "    # results.append({\n",
    "    #     \"example\": example,\n",
    "    #     \"lrp_top5_tokens\": lrp_top5_tokens,\n",
    "    #     \"lrp_top5_relevances\": lrp_top5.values.cpu(),\n",
    "    #     \"is_impossible\": len(answers) == 0\n",
    "    # })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c2a5f-9fdf-4d1f-9e0b-a4f132807eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "for example in tqdm(dataset[\"validation\"].select(range(100))):\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = example[\"answers\"][\"text\"]\n",
    "\n",
    "    input_ids = tokenizer(question, context, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    output = model(input_ids.to(device))\n",
    "\n",
    "    start = torch.argmax(output.start_logits)\n",
    "    end = torch.argmax(output.end_logits) + 1\n",
    "    model_answer = tokenizer.decode(input_ids[0][start:end], skip_special_tokens=True)\n",
    "\n",
    "    checkpoint_vals, param_vals = lrp.run((output.start_logits, output.end_logits))\n",
    "\n",
    "    lrp_top5 = param_vals[1].flatten().topk(k=5)\n",
    "    lrp_top5_tokens = tokenizer.decode(input_ids[0][lrp_top5.indices.cpu()], skip_special_tokens=True)\n",
    "    lrp_start_end = param_vals[1].flatten().topk(k=2).indices.cpu().sort()\n",
    "    lrp_start = lrp_start_end[0][0]\n",
    "    if lrp_start == 0:\n",
    "        lrp_start = lrp_start_end[0][1]\n",
    "    lrp_end = lrp_start_end[0][-1]\n",
    "    lrp_answer_ids = input_ids[0][lrp_start:lrp_end + 1]\n",
    "    lrp_answer = tokenizer.decode(lrp_answer_ids, skip_special_tokens=True)\n",
    "\n",
    "    results.append({\n",
    "        \"example\": example,\n",
    "        \"model_answer\": model_answer,\n",
    "        \"lrp_answer\": lrp_answer,\n",
    "        \"lrp_top5_tokens\": lrp_top5_tokens,\n",
    "        \"lrp_top5_relevances\": lrp_top5.values.cpu(),\n",
    "        \"is_impossible\": len(answers) == 0\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff2a32-b1dc-4e3f-ad4d-59537d2cde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    print(\"Q: \", res[\"example\"][\"question\"])\n",
    "    print(\"A (labels): \", res[\"example\"][\"answers\"][\"text\"])\n",
    "    print(\"Model: \", res[\"model_answer\"])\n",
    "    print(\"LRP: \", res[\"lrp_answer\"])\n",
    "    print(\"LRP top5: \", res[\"lrp_top5_tokens\"])\n",
    "    print(\"LRP top5 attributions: \", res[\"lrp_top5_relevances\"], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7701de-af2b-4743-9e4b-9c8e121530ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
