\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achtibat et~al.(2024)Achtibat, Hatefi, Dreyer,
  et~al.]{achtibat2024attnlrp}
Reduan Achtibat, Sayed Mohammad~Vakilzadeh Hatefi, Maximilian Dreyer, et~al.
\newblock Attnlrp: Attention-aware layer-wise relevance propagation for
  transformers.
\newblock \emph{arXiv preprint arXiv:2402.05602}, 2024.

\bibitem[Alber et~al.(2018)Alber, Lapuschkin, Seegerer, Hägele, Schütt,
  Montavon, Samek, Müller, Dähne, and Kindermans]{alber2018innvestigate}
Maximilian Alber, Sebastian Lapuschkin, Philipp Seegerer, Miriam Hägele,
  Kristof~T. Schütt, Grégoire Montavon, Wojciech Samek, Klaus-Robert Müller,
  Sven Dähne, and Pieter-Jan Kindermans.
\newblock innvestigate neural networks!, 2018.
\newblock URL \url{https://arxiv.org/abs/1808.04260}.

\bibitem[Ancona et~al.(2018)Ancona, Ceolini, {\"O}ztireli, and
  Gross]{ancona2018towards}
Marco Ancona, Enea Ceolini, Cengiz {\"O}ztireli, and Markus Gross.
\newblock Towards better understanding of gradient-based attribution methods
  for deep neural networks.
\newblock \emph{arXiv preprint arXiv:1711.06104}, 2018.

\bibitem[Anders et~al.(2021)Anders, Neumann, Samek, M{\"{u}}ller, and
  Sebastian]{anders2021zennit}
Christopher~J. Anders, David Neumann, Wojciech Samek, Klaus{-}Robert
  M{\"{u}}ller, and Lapuschkin Sebastian.
\newblock Software for dataset-wide {XAI:} from local explanations to
  globalinsights with zennit, corelay, and virelay.
\newblock \emph{CoRR}, abs/2106.13200, 2021.
\newblock URL \url{https://arxiv.org/abs/2106.13200}.

\bibitem[Babu et~al.(2021)Babu, Wang, Tjandra, Lakhotia, Xu, Goyal, Singh, von
  Platen, Saraf, Pino, Baevski, Conneau, and Auli]{babu2021xlsr}
Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman
  Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei
  Baevski, Alexis Conneau, and Michael Auli.
\newblock Xls-r: Self-supervised cross-lingual speech representation learning
  at scale, 2021.
\newblock URL \url{https://arxiv.org/abs/2111.09296}.

\bibitem[Bach et~al.(2015)Bach, Binder, Montavon, et~al.]{bach2015pixel}
Sebastian Bach, Alexander Binder, Gr{\"e}goire Montavon, et~al.
\newblock Pixel-wise explanations for non-linear classifier decisions by
  layer-wise relevance propagation.
\newblock \emph{PLoS ONE}, 10\penalty0 (7):\penalty0 e0130140, 2015.

\bibitem[Blücher et~al.(2024)Blücher, Vielhaben, and
  Strodthoff]{blucher2024pixelflipping}
Stefan Blücher, Johanna Vielhaben, and Nils Strodthoff.
\newblock Decoupling pixel flipping and occlusion strategy for consistent xai
  benchmarks, 2024.
\newblock URL \url{https://arxiv.org/abs/2401.06654}.

\bibitem[Böhle et~al.(2019)Böhle, Eitel, Weygandt, and
  Ritter]{bohle2019alzheimers}
Moritz Böhle, Fabian Eitel, Martin Weygandt, and Kerstin Ritter.
\newblock Layer-wise relevance propagation for explaining deep neural network
  decisions in mri-based alzheimer's disease classification.
\newblock \emph{Frontiers in Aging Neuroscience}, Volume 11 - 2019, 2019.
\newblock ISSN 1663-4365.
\newblock \doi{10.3389/fnagi.2019.00194}.
\newblock URL
  \url{https://www.frontiersin.org/journals/aging-neuroscience/articles/10.3389/fnagi.2019.00194}.

\bibitem[Chan et~al.(2021)Chan, Möller, Pietsch, and
  Soni]{chan2021robertasquadv2}
Branden Chan, Timo Möller, Malte Pietsch, and Tanay Soni.
\newblock roberta-large for extractive qa, 2021.
\newblock URL \url{https://huggingface.co/deepset/roberta-large-squad2}.
\newblock Accessed: 2025-12-06.

\bibitem[Chung et~al.(2022)Chung, Hou, Longpre, Zoph, Tay, Fedus, Li, Wang,
  Dehghani, Brahma, Webson, Gu, Dai, Suzgun, Chen, Chowdhery, Narang, Mishra,
  Yu, Zhao, Huang, Dai, Yu, Petrov, Chi, Dean, Devlin, Roberts, Zhou, Le, and
  Wei]{chung2022flant5}
Hyung~Won Chung, Le~Hou, Shayne Longpre, Barret Zoph, Yi~Tay, William Fedus,
  Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson,
  Shixiang~Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha
  Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping
  Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed~H. Chi, Jeff Dean, Jacob
  Devlin, Adam Roberts, Denny Zhou, Quoc~V. Le, and Jason Wei.
\newblock Scaling instruction-finetuned language models, 2022.
\newblock URL \url{https://arxiv.org/abs/2210.11416}.

\bibitem[Covert et~al.(2020)Covert, Lundberg, and Lee]{covert2020understanding}
Ian Covert, Scott~M Lundberg, and Su-In Lee.
\newblock Understanding global feature contributions with additive importance
  measures.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 17212--17223, 2020.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiy2021vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale, 2021.
\newblock URL \url{https://arxiv.org/abs/2010.11929}.

\bibitem[Dubey \& et~al.(2024)Dubey and et~al.]{dubey2024llama3}
Abhimanyu Dubey and et~al.
\newblock The llama 3 herd of models, 2024.
\newblock URL \url{https://arxiv.org/abs/2407.21783}.

\bibitem[Gu \& Dao(2024)Gu and Dao]{gu2024mamba}
Albert Gu and Tri Dao.
\newblock Mamba: Linear-time sequence modeling with selective state spaces,
  2024.
\newblock URL \url{https://arxiv.org/abs/2312.00752}.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{he2015resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition, 2015.
\newblock URL \url{https://arxiv.org/abs/1512.03385}.

\bibitem[Howard(2019)]{howard2019imagenette}
Jeremy Howard.
\newblock Imagenette: A smaller subset of 10 easily classified classes from
  imagenet, March 2019.
\newblock URL \url{https://github.com/fastai/imagenette}.

\bibitem[Iwana et~al.(2019)Iwana, Kuroki, and
  Uchida]{iwana2019lrpexplainingcnns}
Brian~K. Iwana, Ryohei Kuroki, and Seiichi Uchida.
\newblock Explaining convolutional neural networks using softmax gradient
  layer-wise relevance propagation, 2019.
\newblock URL \url{https://arxiv.org/abs/1908.04351}.

\bibitem[Kokhlikyan et~al.(2020)Kokhlikyan, Miglani, Martin, Wang, Alsallakh,
  Reynolds, Melnikov, Kliushkina, Araya, Yan, and
  Reblitz-Richardson]{kokhlikyan2020captum}
Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Bilal Alsallakh,
  Jonathan Reynolds, Alexander Melnikov, Natalia Kliushkina, Carlos Araya, Siqi
  Yan, and Orion Reblitz-Richardson.
\newblock Captum: A unified and generic model interpretability library for
  pytorch, 2020.
\newblock URL \url{https://arxiv.org/abs/2009.07896}.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and
  Hinton]{krizhevsky2009learning}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical Report~0, University of Toronto, Toronto, Ontario, 2009.
\newblock URL
  \url{https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}.

\bibitem[Lee(2023)]{lee2023flant5squadv2}
Sebastian~Husch Lee.
\newblock flan-t5-large for extractive qa, 2023.
\newblock URL \url{https://huggingface.co/sjrhuschlee/flan-t5-large-squad2}.
\newblock Accessed: 2025-12-06.

\bibitem[Liu et~al.(2022)Liu, Eisenschlos, Piccinno, Krichene, Pang, Lee,
  Joshi, Chen, Collier, and Altun]{liu2022deplot}
Fangyu Liu, Julian~Martin Eisenschlos, Francesco Piccinno, Syrine Krichene,
  Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, and Yasemin
  Altun.
\newblock Deplot: One-shot visual language reasoning by plot-to-table
  translation, 2022.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
  Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: {A} robustly optimized {BERT} pretraining approach, 2019.
\newblock URL \url{http://arxiv.org/abs/1907.11692}.

\bibitem[Lundberg \& Lee(2017)Lundberg and Lee]{lundberg2017unified}
Scott~M Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock \emph{Advances in Neural Information Processing Systems}, pp.\
  4765--4774, 2017.

\bibitem[Machiraju et~al.(2024)Machiraju, Derry, Desai,
  et~al.]{machiraju2024prospector}
Gautam Machiraju, Alexander Derry, Arjun Desai, et~al.
\newblock Prospector heads: Generalized feature attribution for large models \&
  data.
\newblock \emph{Proceedings of the 41st International Conference on Machine
  Learning}, 2024.

\bibitem[Montavon et~al.(2017)Montavon, Lapuschkin, Binder,
  et~al.]{montavon2017explaining}
Gr{\'e}goire Montavon, Sebastian Lapuschkin, Alexander Binder, et~al.
\newblock Explaining nonlinear classification decisions with deep taylor
  decomposition.
\newblock \emph{Pattern recognition}, 65:\penalty0 211--222, 2017.

\bibitem[Montavon et~al.(2019)Montavon, Binder, Lapuschkin, Samek, and
  M{\"u}ller]{montavon2019lrp}
Gr{\'e}goire Montavon, Alexander Binder, Sebastian Lapuschkin, Wojciech Samek,
  and Klaus-Robert M{\"u}ller.
\newblock Layer-wise relevance propagation: An overview, 2019.

\bibitem[Otsuki et~al.(2024)Otsuki, Iida, Doublet, Hirakawa, Yamashita,
  Fujiyoshi, and Sugiura]{otsuki2024lrpresidualconnections}
Seitaro Otsuki, Tsumugi Iida, Félix Doublet, Tsubasa Hirakawa, Takayoshi
  Yamashita, Hironobu Fujiyoshi, and Komei Sugiura.
\newblock Layer-wise relevance propagation with conservation property for
  resnet, 2024.
\newblock URL \url{https://arxiv.org/abs/2407.09115}.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{radford2019gpt2}
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI}, 2019.

\bibitem[Radford et~al.(2022)Radford, Kim, Xu, Brockman, McLeavey, and
  Sutskever]{radford2022whisper}
Alec Radford, Jong~Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and
  Ilya Sutskever.
\newblock Robust speech recognition via large-scale weak supervision, 2022.
\newblock URL \url{https://arxiv.org/abs/2212.04356}.

\bibitem[Rajpurkar et~al.(2018)Rajpurkar, Jia, and Liang]{rajpurkar2018squadv2}
Pranav Rajpurkar, Robin Jia, and Percy Liang.
\newblock Know what you don't know: Unanswerable questions for squad, 2018.
\newblock URL \url{https://arxiv.org/abs/1806.03822}.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{ribeiro2016should}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock Why should i trust you?: Explaining the predictions of any
  classifier.
\newblock \emph{Proceedings of the 22nd ACM SIGKDD international conference on
  knowledge discovery and data mining}, pp.\  1135--1144, 2016.

\bibitem[Samek et~al.(2021)Samek, Montavon, Lapuschkin, Anders, and
  Muller]{samek2021xaireview}
Wojciech Samek, Gregoire Montavon, Sebastian Lapuschkin, Christopher~J. Anders,
  and Klaus-Robert Muller.
\newblock Explaining deep neural networks and beyond: A review of methods and
  applications.
\newblock \emph{Proceedings of the IEEE}, 109\penalty0 (3), 2021.
\newblock ISSN 1558-2256.
\newblock \doi{10.1109/jproc.2021.3060483}.
\newblock URL \url{http://dx.doi.org/10.1109/JPROC.2021.3060483}.

\bibitem[Schulz et~al.(2020)Schulz, Sixt, Tombari, and
  Landgraf]{schulz2020abpc}
Karl Schulz, Leon Sixt, Federico Tombari, and Tim Landgraf.
\newblock Restricting the flow: Information bottlenecks for attribution.
\newblock \emph{International Conference on Learning Representations}, pp.\
  12685--12703, 2020.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and
  Batra]{selvaraju2017grad}
Ramprasaath~R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
  Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  618--626, 2017.

\bibitem[Simonyan \& Zisserman(2015)Simonyan and Zisserman]{simonyan2015vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition,
  2015.
\newblock URL \url{https://arxiv.org/abs/1409.1556}.

\bibitem[Simonyan et~al.(2014)Simonyan, Vedaldi, and
  Zisserman]{simonyan2014deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock \emph{arXiv preprint arXiv:1312.6034}, 2014.

\bibitem[Smilkov et~al.(2017)Smilkov, Thorat, Kim, Vi{\'e}gas, and
  Wattenberg]{smilkov2017smoothgrad}
Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi{\'e}gas, and Martin
  Wattenberg.
\newblock Smoothgrad: removing noise by adding noise.
\newblock \emph{arXiv preprint arXiv:1706.03825}, 2017.

\bibitem[Sun et~al.(2021)Sun, Lapuschkin, Samek, and
  Binder]{sun2021lrpfinetuning}
Jiamei Sun, Sebastian Lapuschkin, Wojciech Samek, and Alexander Binder.
\newblock Explain and improve: Lrp-inference fine-tuning for image captioning
  models, 2021.
\newblock URL \url{https://arxiv.org/abs/2001.01037}.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{sundararajan2017axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock \emph{International Conference on Machine Learning}, pp.\
  3319--3328, 2017.

\bibitem[Tan \& Le(2021)Tan and Le]{tan2021efficientnetv2}
Mingxing Tan and Quoc~V. Le.
\newblock Efficientnetv2: Smaller models and faster training, 2021.
\newblock URL \url{https://arxiv.org/abs/2104.00298}.

\bibitem[Team(2025{\natexlab{a}})]{gemmateam2025gemma3}
Gemma Team.
\newblock Gemma 3 technical report, 2025{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2503.19786}.

\bibitem[Team(2025{\natexlab{b}})]{yang2025qwen3}
Qwen Team.
\newblock Qwen3 technical report, 2025{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2505.09388}.

\bibitem[Tschannen et~al.(2025)Tschannen, Gritsenko, Wang, Naeem,
  Alabdulmohsin, Parthasarathy, Evans, Beyer, Xia, Mustafa, Hénaff, Harmsen,
  Steiner, and Zhai]{tschannen2025siglip2}
Michael Tschannen, Alexey Gritsenko, Xiao Wang, Muhammad~Ferjad Naeem, Ibrahim
  Alabdulmohsin, Nikhil Parthasarathy, Talfan Evans, Lucas Beyer, Ye~Xia, Basil
  Mustafa, Olivier Hénaff, Jeremiah Harmsen, Andreas Steiner, and Xiaohua
  Zhai.
\newblock Siglip 2: Multilingual vision-language encoders with improved
  semantic understanding, localization, and dense features, 2025.
\newblock URL \url{https://arxiv.org/abs/2502.14786}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar,
  et~al.]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, et~al.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Zhou et~al.(2016)Zhou, Khosla, Lapedriza, Oliva, and
  Torralba]{zhou2016learning}
Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba.
\newblock Learning deep features for discriminative localization.
\newblock \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2921--2929, 2016.

\end{thebibliography}
