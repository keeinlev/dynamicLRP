{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2e5bca-5fb2-4c76-afcc-a2ab615c94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3674a9c3-644b-4adc-a9ed-34e2d94e463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinlee-talka/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-2-117M/7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"zhihan1996/DNABERT-2-117M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "955778f8-7778-45cf-aa06-dee75285b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class LRPCheckpoint(torch.autograd.Function):\n",
    "    \"\"\"Identity autograd fcn for marking where to capture relevance.\"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, input: torch.Tensor) -> torch.Tensor:\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.Tensor) -> Tuple[torch.Tensor, None, None]:\n",
    "        return grad_output, None, None\n",
    "\n",
    "create_checkpoint = LRPCheckpoint.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2462a393-1877-4f94-b66c-be0b1f69c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_hook(module, input, output):\n",
    "    return create_checkpoint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f01096bb-97a3-47cf-916c-5f38a899ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_module in model.encoder.layer:\n",
    "    layer_module.attention.self.register_forward_hook(checkpoint_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0cba7c-db59-4cc8-acb9-0cb41f9ccbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = \"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\"\n",
    "inputs = tokenizer(dna, return_tensors = 'pt')[\"input_ids\"]\n",
    "hidden_states : torch.Tensor = model(inputs, requires_grad=True)[0] # [1, sequence_length, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4a4b85e0-9f4d-4bcd-b5b5-81157205841a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 768])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a288ca1c-ad72-4943-85b7-2ddb78b735ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    m = hidden_states.max(-1)\n",
    "    # print(m)\n",
    "    b = torch.zeros_like(a)\n",
    "    for i, inds in enumerate(m.indices):\n",
    "        b[i,list(range(hidden_states.shape[1])),inds] = torch.ones_like(m.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432acd9e-5070-4f44-8a29-f75ac41ea750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "fcns = [ [hidden_states.grad_fn] ]\n",
    "visited = set()\n",
    "names = set()\n",
    "\n",
    "count = 0\n",
    "while fcns:\n",
    "    count += 1\n",
    "    # print(len(fcns))\n",
    "    new_fcns = []\n",
    "    for fcn_list in fcns:\n",
    "        for fcn in fcn_list:\n",
    "            if fcn is None or fcn in visited:\n",
    "                continue\n",
    "            if type(fcn).__name__ not in names:\n",
    "                names.add(type(fcn).__name__)\n",
    "            visited.add(fcn)\n",
    "            new_fcns.append([ fcn_tup[0] for fcn_tup in fcn.next_functions ])\n",
    "        # new_fcns += [ [ fcn_tup[0] for fcn_tup in curr.next_functions ] for curr in fcn_list if (curr is not None) ]\n",
    "    fcns = new_fcns\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "703f399d-f29f-40d5-9dae-e131fe3e7f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccumulateGrad',\n",
       " 'AddBackward0',\n",
       " 'AddmmBackward0',\n",
       " 'BmmBackward0',\n",
       " 'DivBackward0',\n",
       " 'EmbeddingBackward0',\n",
       " 'ExpandBackward0',\n",
       " 'GeluBackward0',\n",
       " 'IndexFirstAxisBackward',\n",
       " 'IndexPutFirstAxisBackward',\n",
       " 'LRPCheckpointBackward',\n",
       " 'MmBackward0',\n",
       " 'MulBackward0',\n",
       " 'NativeLayerNormBackward0',\n",
       " 'PermuteBackward0',\n",
       " 'ReshapeAliasBackward0',\n",
       " 'SelectBackward0',\n",
       " 'SliceBackward0',\n",
       " 'SoftmaxBackward0',\n",
       " 'TBackward0',\n",
       " 'UnsafeViewBackward0',\n",
       " 'ViewBackward0'}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb40f3c5-406a-40e5-8586-8befdadb8e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = list(visited)\n",
    "visited = sorted(visited, key=lambda fcn: fcn._sequence_nr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d57aada-f2bd-43c3-af00-839a878fb75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, <EmbeddingBackward0 at 0x29145a6a0>),\n",
       " (1, <EmbeddingBackward0 at 0x29145a6d0>),\n",
       " (2, <AddBackward0 at 0x29145a3d0>),\n",
       " (3, <NativeLayerNormBackward0 at 0x29145a130>),\n",
       " (4, <ViewBackward0 at 0x291463e80>),\n",
       " (5, <torch.autograd.function.IndexFirstAxisBackward at 0x291185e40>),\n",
       " (6, <TBackward0 at 0x29146ebb0>),\n",
       " (7, <AddmmBackward0 at 0x29146eaf0>),\n",
       " (8, <torch.autograd.function.IndexPutFirstAxisBackward at 0x2911fdb40>),\n",
       " (9, <ViewBackward0 at 0x29146e9a0>),\n",
       " (10, <ViewBackward0 at 0x29146e880>),\n",
       " (11, <SliceBackward0 at 0x29146ec70>),\n",
       " (12, <SliceBackward0 at 0x29146ebe0>),\n",
       " (13, <SelectBackward0 at 0x29146eb20>),\n",
       " (14, <SliceBackward0 at 0x29146ea90>),\n",
       " (15, <SliceBackward0 at 0x29146ea30>),\n",
       " (16, <PermuteBackward0 at 0x29146e940>),\n",
       " (17, <SliceBackward0 at 0x29146eca0>),\n",
       " (18, <SliceBackward0 at 0x29146ec10>),\n",
       " (19, <SelectBackward0 at 0x29146eb50>),\n",
       " (20, <SliceBackward0 at 0x29146eac0>),\n",
       " (21, <SliceBackward0 at 0x29146ea60>),\n",
       " (22, <PermuteBackward0 at 0x29146e970>),\n",
       " (23, <SliceBackward0 at 0x29146e730>),\n",
       " (24, <SliceBackward0 at 0x29146e610>),\n",
       " (25, <SelectBackward0 at 0x29146e4f0>),\n",
       " (26, <SliceBackward0 at 0x29146e370>),\n",
       " (27, <SliceBackward0 at 0x29146e1c0>),\n",
       " (28, <PermuteBackward0 at 0x29146e040>),\n",
       " (29, <ExpandBackward0 at 0x29146e820>),\n",
       " (30, <ReshapeAliasBackward0 at 0x29146e6d0>),\n",
       " (31, <ExpandBackward0 at 0x29146e850>),\n",
       " (32, <ReshapeAliasBackward0 at 0x29146e700>),\n",
       " (33, <BmmBackward0 at 0x29146e5e0>),\n",
       " (34, <UnsafeViewBackward0 at 0x29146e4c0>),\n",
       " (35, <DivBackward0 at 0x29146e340>),\n",
       " (36, <AddBackward0 at 0x29146e190>),\n",
       " (37, <SoftmaxBackward0 at 0x29145afd0>),\n",
       " (38, <ExpandBackward0 at 0x29145ae50>),\n",
       " (39, <ViewBackward0 at 0x29145ac70>),\n",
       " (40, <ExpandBackward0 at 0x29145ae80>),\n",
       " (41, <ReshapeAliasBackward0 at 0x29145aca0>),\n",
       " (42, <BmmBackward0 at 0x29145aa90>),\n",
       " (43, <UnsafeViewBackward0 at 0x29145a880>),\n",
       " (44, <PermuteBackward0 at 0x29145a670>),\n",
       " (45, <ReshapeAliasBackward0 at 0x29145a3a0>),\n",
       " (46, <torch.autograd.function.IndexFirstAxisBackward at 0x2911fd040>),\n",
       " (47, <ViewBackward0 at 0x291463e20>),\n",
       " (48, <TBackward0 at 0x291463e50>),\n",
       " (49, <AddmmBackward0 at 0x291463bb0>),\n",
       " (50, <AddBackward0 at 0x291463850>),\n",
       " (51, <NativeLayerNormBackward0 at 0x291463520>),\n",
       " (52, <TBackward0 at 0x29145a370>),\n",
       " (53, <MmBackward0 at 0x29145a0d0>),\n",
       " (54, <SliceBackward0 at 0x29145a0a0>),\n",
       " (55, <SliceBackward0 at 0x291463d90>),\n",
       " (56, <SliceBackward0 at 0x291463dc0>),\n",
       " (57, <SliceBackward0 at 0x291463b50>),\n",
       " (58, <GeluBackward0 at 0x291463b20>),\n",
       " (59, <MulBackward0 at 0x2914637f0>),\n",
       " (60, <TBackward0 at 0x291463820>),\n",
       " (61, <AddmmBackward0 at 0x2914634f0>),\n",
       " (62, <AddBackward0 at 0x291463220>),\n",
       " (63, <NativeLayerNormBackward0 at 0x291461f10>),\n",
       " (64, <TBackward0 at 0x29146e7f0>),\n",
       " (65, <AddmmBackward0 at 0x29146e6a0>),\n",
       " (66, <torch.autograd.function.IndexPutFirstAxisBackward at 0x2911fd740>),\n",
       " (67, <ViewBackward0 at 0x29146e490>),\n",
       " (68, <ViewBackward0 at 0x29146e310>),\n",
       " (69, <SliceBackward0 at 0x29146e9d0>),\n",
       " (70, <SliceBackward0 at 0x29146e8b0>),\n",
       " (71, <SelectBackward0 at 0x29146e760>),\n",
       " (72, <SliceBackward0 at 0x29146e640>),\n",
       " (73, <SliceBackward0 at 0x29146e580>),\n",
       " (74, <PermuteBackward0 at 0x29146e430>),\n",
       " (75, <SliceBackward0 at 0x29146ea00>),\n",
       " (76, <SliceBackward0 at 0x29146e8e0>),\n",
       " (77, <SelectBackward0 at 0x29146e790>),\n",
       " (78, <SliceBackward0 at 0x29146e670>),\n",
       " (79, <SliceBackward0 at 0x29146e5b0>),\n",
       " (80, <PermuteBackward0 at 0x29146e460>),\n",
       " (81, <SliceBackward0 at 0x29146e160>),\n",
       " (82, <SliceBackward0 at 0x29145afa0>),\n",
       " (83, <SelectBackward0 at 0x29145ae20>),\n",
       " (84, <SliceBackward0 at 0x29145ac40>),\n",
       " (85, <SliceBackward0 at 0x29145aa60>),\n",
       " (86, <PermuteBackward0 at 0x29145a850>),\n",
       " (87, <ExpandBackward0 at 0x29146e2b0>),\n",
       " (88, <ReshapeAliasBackward0 at 0x29146e100>),\n",
       " (89, <ExpandBackward0 at 0x29146e2e0>),\n",
       " (90, <ReshapeAliasBackward0 at 0x29146e130>),\n",
       " (91, <BmmBackward0 at 0x29145af70>),\n",
       " (92, <UnsafeViewBackward0 at 0x29145adf0>),\n",
       " (93, <DivBackward0 at 0x29145ac10>),\n",
       " (94, <AddBackward0 at 0x29145aa30>),\n",
       " (95, <SoftmaxBackward0 at 0x29145a820>),\n",
       " (96, <ExpandBackward0 at 0x29145a5e0>),\n",
       " (97, <ViewBackward0 at 0x29145a310>),\n",
       " (98, <ExpandBackward0 at 0x29145a610>),\n",
       " (99, <ReshapeAliasBackward0 at 0x29145a340>),\n",
       " (100, <BmmBackward0 at 0x29145a070>),\n",
       " (101, <UnsafeViewBackward0 at 0x291463d60>),\n",
       " (102, <PermuteBackward0 at 0x291463af0>),\n",
       " (103, <ReshapeAliasBackward0 at 0x291463790>),\n",
       " (104, <torch.autograd.function.IndexFirstAxisBackward at 0x2911fd840>),\n",
       " (105, <ViewBackward0 at 0x2914631c0>),\n",
       " (106, <TBackward0 at 0x2914631f0>),\n",
       " (107, <AddmmBackward0 at 0x291461ee0>),\n",
       " (108, <AddBackward0 at 0x291461b80>),\n",
       " (109, <NativeLayerNormBackward0 at 0x291461850>),\n",
       " (110, <TBackward0 at 0x291463760>),\n",
       " (111, <MmBackward0 at 0x291463490>),\n",
       " (112, <SliceBackward0 at 0x291463460>),\n",
       " (113, <SliceBackward0 at 0x291463130>),\n",
       " (114, <SliceBackward0 at 0x291463160>),\n",
       " (115, <SliceBackward0 at 0x291461e80>),\n",
       " (116, <GeluBackward0 at 0x291461e50>),\n",
       " (117, <MulBackward0 at 0x291461b20>),\n",
       " (118, <TBackward0 at 0x291461b50>),\n",
       " (119, <AddmmBackward0 at 0x291461820>),\n",
       " (120, <AddBackward0 at 0x291461550>),\n",
       " (121, <NativeLayerNormBackward0 at 0x291461280>),\n",
       " (122, <TBackward0 at 0x29146e280>),\n",
       " (123, <AddmmBackward0 at 0x29146e0d0>),\n",
       " (124, <torch.autograd.function.IndexPutFirstAxisBackward at 0x2911fd940>),\n",
       " (125, <ViewBackward0 at 0x29145adc0>),\n",
       " (126, <ViewBackward0 at 0x29145abe0>),\n",
       " (127, <SliceBackward0 at 0x29146e520>),\n",
       " (128, <SliceBackward0 at 0x29146e3a0>),\n",
       " (129, <SelectBackward0 at 0x29146e1f0>),\n",
       " (130, <SliceBackward0 at 0x29146e070>),\n",
       " (131, <SliceBackward0 at 0x29145af10>),\n",
       " (132, <PermuteBackward0 at 0x29145ad60>),\n",
       " (133, <SliceBackward0 at 0x29146e550>),\n",
       " (134, <SliceBackward0 at 0x29146e3d0>),\n",
       " (135, <SelectBackward0 at 0x29146e220>),\n",
       " (136, <SliceBackward0 at 0x29146e0a0>),\n",
       " (137, <SliceBackward0 at 0x29145af40>),\n",
       " (138, <PermuteBackward0 at 0x29145ad90>),\n",
       " (139, <SliceBackward0 at 0x29145aa00>),\n",
       " (140, <SliceBackward0 at 0x29145a7f0>),\n",
       " (141, <SelectBackward0 at 0x29145a5b0>),\n",
       " (142, <SliceBackward0 at 0x29145a2e0>),\n",
       " (143, <SliceBackward0 at 0x29145a040>),\n",
       " (144, <PermuteBackward0 at 0x291463d30>),\n",
       " (145, <ExpandBackward0 at 0x29145ab80>),\n",
       " (146, <ReshapeAliasBackward0 at 0x29145a9a0>),\n",
       " (147, <ExpandBackward0 at 0x29145abb0>),\n",
       " (148, <ReshapeAliasBackward0 at 0x29145a9d0>),\n",
       " (149, <BmmBackward0 at 0x29145a7c0>),\n",
       " (150, <UnsafeViewBackward0 at 0x29145a580>),\n",
       " (151, <DivBackward0 at 0x29145a2b0>),\n",
       " (152, <AddBackward0 at 0x291463fd0>),\n",
       " (153, <SoftmaxBackward0 at 0x291463d00>),\n",
       " (154, <ExpandBackward0 at 0x291463a60>),\n",
       " (155, <ViewBackward0 at 0x291463700>),\n",
       " (156, <ExpandBackward0 at 0x291463a90>),\n",
       " (157, <ReshapeAliasBackward0 at 0x291463730>),\n",
       " (158, <BmmBackward0 at 0x291463430>),\n",
       " (159, <UnsafeViewBackward0 at 0x291463100>),\n",
       " (160, <PermuteBackward0 at 0x291461e20>),\n",
       " (161, <ReshapeAliasBackward0 at 0x291461ac0>),\n",
       " (162, <torch.autograd.function.IndexFirstAxisBackward at 0x2911fda40>),\n",
       " (163, <ViewBackward0 at 0x2914614f0>),\n",
       " (164, <TBackward0 at 0x291461520>),\n",
       " (165, <AddmmBackward0 at 0x291461250>),\n",
       " (166, <AddBackward0 at 0x291460eb0>),\n",
       " (167, <NativeLayerNormBackward0 at 0x291460b80>),\n",
       " (168, <TBackward0 at 0x291461a90>),\n",
       " (169, <MmBackward0 at 0x2914617c0>),\n",
       " (170, <SliceBackward0 at 0x291461790>),\n",
       " (171, <SliceBackward0 at 0x291461460>),\n",
       " (172, <SliceBackward0 at 0x291461490>),\n",
       " (173, <SliceBackward0 at 0x2914611f0>),\n",
       " (174, <GeluBackward0 at 0x2914611c0>),\n",
       " (175, <MulBackward0 at 0x291460e50>),\n",
       " (176, <TBackward0 at 0x291460e80>),\n",
       " (177, <AddmmBackward0 at 0x291460b50>),\n",
       " (178, <AddBackward0 at 0x291460880>),\n",
       " (179, <NativeLayerNormBackward0 at 0x2914605b0>),\n",
       " (180, <TBackward0 at 0x29145ab50>),\n",
       " (181, <AddmmBackward0 at 0x29145a970>),\n",
       " (182, <torch.autograd.function.IndexPutFirstAxisBackward at 0x2911fdc40>),\n",
       " (183, <ViewBackward0 at 0x29145a550>),\n",
       " (184, <ViewBackward0 at 0x29145a280>),\n",
       " (185, <SliceBackward0 at 0x29145aeb0>),\n",
       " (186, <SliceBackward0 at 0x29145acd0>),\n",
       " (187, <SelectBackward0 at 0x29145aac0>),\n",
       " (188, <SliceBackward0 at 0x29145a910>),\n",
       " (189, <SliceBackward0 at 0x29145a760>),\n",
       " (190, <PermuteBackward0 at 0x29145a4f0>),\n",
       " (191, <SliceBackward0 at 0x29145aee0>),\n",
       " (192, <SliceBackward0 at 0x29145ad00>),\n",
       " (193, <SelectBackward0 at 0x29145aaf0>),\n",
       " (194, <SliceBackward0 at 0x29145a940>),\n",
       " (195, <SliceBackward0 at 0x29145a790>),\n",
       " (196, <PermuteBackward0 at 0x29145a520>),\n",
       " (197, <SliceBackward0 at 0x291463fa0>),\n",
       " (198, <SliceBackward0 at 0x291463cd0>),\n",
       " (199, <SelectBackward0 at 0x291463a30>),\n",
       " (200, <SliceBackward0 at 0x2914636d0>),\n",
       " (201, <SliceBackward0 at 0x291463400>),\n",
       " (202, <PermuteBackward0 at 0x2914630d0>),\n",
       " (203, <ExpandBackward0 at 0x29145a220>),\n",
       " (204, <ReshapeAliasBackward0 at 0x291463f40>),\n",
       " (205, <ExpandBackward0 at 0x29145a250>),\n",
       " (206, <ReshapeAliasBackward0 at 0x291463f70>),\n",
       " (207, <BmmBackward0 at 0x291463ca0>),\n",
       " (208, <UnsafeViewBackward0 at 0x291463a00>),\n",
       " (209, <DivBackward0 at 0x2914636a0>),\n",
       " (210, <AddBackward0 at 0x2914633d0>),\n",
       " (211, <SoftmaxBackward0 at 0x2914630a0>),\n",
       " (212, <ExpandBackward0 at 0x291461d90>),\n",
       " (213, <ViewBackward0 at 0x291461a30>),\n",
       " (214, <ExpandBackward0 at 0x291461dc0>),\n",
       " (215, <ReshapeAliasBackward0 at 0x291461a60>),\n",
       " (216, <BmmBackward0 at 0x291461760>),\n",
       " (217, <UnsafeViewBackward0 at 0x291461430>),\n",
       " (218, <PermuteBackward0 at 0x291461190>),\n",
       " (219, <ReshapeAliasBackward0 at 0x291460df0>),\n",
       " (220, <torch.autograd.function.IndexFirstAxisBackward at 0x2911fdd40>),\n",
       " (221, <ViewBackward0 at 0x291460820>),\n",
       " (222, <TBackward0 at 0x291460850>),\n",
       " (223, <AddmmBackward0 at 0x291460580>),\n",
       " (224, <AddBackward0 at 0x291460220>),\n",
       " (225, <NativeLayerNormBackward0 at 0x29145feb0>),\n",
       " (226, <TBackward0 at 0x291460dc0>),\n",
       " (227, <MmBackward0 at 0x291460af0>),\n",
       " (228, <SliceBackward0 at 0x291460ac0>),\n",
       " (229, <SliceBackward0 at 0x291460790>),\n",
       " (230, <SliceBackward0 at 0x2914607c0>),\n",
       " (231, <SliceBackward0 at 0x291460520>),\n",
       " (232, <GeluBackward0 at 0x2914604f0>),\n",
       " (233, <MulBackward0 at 0x2914601c0>),\n",
       " (234, <TBackward0 at 0x2914601f0>),\n",
       " (235, <AddmmBackward0 at 0x29145fe80>),\n",
       " (236, <AddBackward0 at 0x29145fbb0>),\n",
       " (237, <NativeLayerNormBackward0 at 0x29145f8e0>),\n",
       " (238, <TBackward0 at 0x29145a1f0>),\n",
       " (239, <AddmmBackward0 at 0x291463f10>),\n",
       " (240, <torch.autograd.function.IndexPutFirstAxisBackward at 0x2911fde40>),\n",
       " (241, <ViewBackward0 at 0x2914639d0>),\n",
       " (242, <ViewBackward0 at 0x291463670>),\n",
       " (243, <SliceBackward0 at 0x29145a700>),\n",
       " (244, <SliceBackward0 at 0x29145a460>),\n",
       " (245, <SelectBackward0 at 0x29145a160>),\n",
       " (246, <SliceBackward0 at 0x291463eb0>),\n",
       " (247, <SliceBackward0 at 0x291463c40>),\n",
       " (248, <PermuteBackward0 at 0x291463970>),\n",
       " (249, <SliceBackward0 at 0x29145a730>),\n",
       " (250, <SliceBackward0 at 0x29145a490>),\n",
       " (251, <SelectBackward0 at 0x29145a190>),\n",
       " (252, <SliceBackward0 at 0x291463ee0>),\n",
       " (253, <SliceBackward0 at 0x291463c70>),\n",
       " (254, <PermuteBackward0 at 0x2914639a0>),\n",
       " (255, <SliceBackward0 at 0x2914633a0>),\n",
       " (256, <SliceBackward0 at 0x291463070>),\n",
       " (257, <SelectBackward0 at 0x291461d60>),\n",
       " (258, <SliceBackward0 at 0x291461a00>),\n",
       " (259, <SliceBackward0 at 0x291461730>),\n",
       " (260, <PermuteBackward0 at 0x291461400>),\n",
       " (261, <ExpandBackward0 at 0x291463610>),\n",
       " (262, <ReshapeAliasBackward0 at 0x291463340>),\n",
       " (263, <ExpandBackward0 at 0x291463640>),\n",
       " (264, <ReshapeAliasBackward0 at 0x291463370>),\n",
       " (265, <BmmBackward0 at 0x291463040>),\n",
       " (266, <UnsafeViewBackward0 at 0x291461d30>),\n",
       " (267, <DivBackward0 at 0x2914619d0>),\n",
       " (268, <AddBackward0 at 0x291461700>),\n",
       " (269, <SoftmaxBackward0 at 0x2914613d0>),\n",
       " (270, <ExpandBackward0 at 0x291461100>),\n",
       " (271, <ViewBackward0 at 0x291460d60>),\n",
       " (272, <ExpandBackward0 at 0x291461130>),\n",
       " (273, <ReshapeAliasBackward0 at 0x291460d90>),\n",
       " (274, <BmmBackward0 at 0x291460a90>),\n",
       " (275, <UnsafeViewBackward0 at 0x291460760>),\n",
       " (276, <PermuteBackward0 at 0x2914604c0>),\n",
       " (277, <ReshapeAliasBackward0 at 0x291460160>),\n",
       " (278, <torch.autograd.function.IndexFirstAxisBackward at 0x29145d040>),\n",
       " (279, <ViewBackward0 at 0x29145fb50>),\n",
       " (280, <TBackward0 at 0x29145fb80>),\n",
       " (281, <AddmmBackward0 at 0x29145f8b0>),\n",
       " (282, <AddBackward0 at 0x29145f550>),\n",
       " (283, <NativeLayerNormBackward0 at 0x29145f220>),\n",
       " (284, <TBackward0 at 0x291460130>),\n",
       " (285, <MmBackward0 at 0x29145fe20>),\n",
       " (286, <SliceBackward0 at 0x29145fdf0>),\n",
       " (287, <SliceBackward0 at 0x29145fac0>),\n",
       " (288, <SliceBackward0 at 0x29145faf0>),\n",
       " (289, <SliceBackward0 at 0x29145f850>),\n",
       " (290, <GeluBackward0 at 0x29145f820>),\n",
       " (291, <MulBackward0 at 0x29145f4f0>),\n",
       " (292, <TBackward0 at 0x29145f520>),\n",
       " (293, <AddmmBackward0 at 0x29145f1f0>),\n",
       " (294, <AddBackward0 at 0x291453400>),\n",
       " (295, <NativeLayerNormBackward0 at 0x291453dc0>),\n",
       " (296, <TBackward0 at 0x2914635e0>),\n",
       " (297, <AddmmBackward0 at 0x291463310>),\n",
       " (298, <torch.autograd.function.IndexPutFirstAxisBackward at 0x29145d140>),\n",
       " (299, <ViewBackward0 at 0x291461d00>),\n",
       " (300, <ViewBackward0 at 0x2914619a0>),\n",
       " (301, <SliceBackward0 at 0x291463be0>),\n",
       " (302, <SliceBackward0 at 0x2914638e0>),\n",
       " (303, <SelectBackward0 at 0x291463550>),\n",
       " (304, <SliceBackward0 at 0x2914632b0>),\n",
       " (305, <SliceBackward0 at 0x291461fa0>),\n",
       " (306, <PermuteBackward0 at 0x291461ca0>),\n",
       " (307, <SliceBackward0 at 0x291463c10>),\n",
       " (308, <SliceBackward0 at 0x291463910>),\n",
       " (309, <SelectBackward0 at 0x291463580>),\n",
       " (310, <SliceBackward0 at 0x2914632e0>),\n",
       " (311, <SliceBackward0 at 0x291461fd0>),\n",
       " (312, <PermuteBackward0 at 0x291461cd0>),\n",
       " (313, <SliceBackward0 at 0x2914616d0>),\n",
       " (314, <SliceBackward0 at 0x2914613a0>),\n",
       " (315, <SelectBackward0 at 0x2914610d0>),\n",
       " (316, <SliceBackward0 at 0x291460d30>),\n",
       " (317, <SliceBackward0 at 0x291460a60>),\n",
       " (318, <PermuteBackward0 at 0x291460730>),\n",
       " (319, <ExpandBackward0 at 0x291461940>),\n",
       " (320, <ReshapeAliasBackward0 at 0x291461670>),\n",
       " (321, <ExpandBackward0 at 0x291461970>),\n",
       " (322, <ReshapeAliasBackward0 at 0x2914616a0>),\n",
       " (323, <BmmBackward0 at 0x291461370>),\n",
       " (324, <UnsafeViewBackward0 at 0x2914610a0>),\n",
       " (325, <DivBackward0 at 0x291460d00>),\n",
       " (326, <AddBackward0 at 0x291460a30>),\n",
       " (327, <SoftmaxBackward0 at 0x291460700>),\n",
       " (328, <ExpandBackward0 at 0x291460430>),\n",
       " (329, <ViewBackward0 at 0x2914600d0>),\n",
       " (330, <ExpandBackward0 at 0x291460460>),\n",
       " (331, <ReshapeAliasBackward0 at 0x291460100>),\n",
       " (332, <BmmBackward0 at 0x29145fdc0>),\n",
       " (333, <UnsafeViewBackward0 at 0x29145fa90>),\n",
       " (334, <PermuteBackward0 at 0x29145f7f0>),\n",
       " (335, <ReshapeAliasBackward0 at 0x29145f490>),\n",
       " (336, <torch.autograd.function.IndexFirstAxisBackward at 0x29145d240>),\n",
       " (337, <ViewBackward0 at 0x291453190>),\n",
       " (338, <TBackward0 at 0x291453370>),\n",
       " (339, <AddmmBackward0 at 0x291453fa0>),\n",
       " (340, <AddBackward0 at 0x2911deb50>),\n",
       " (341, <NativeLayerNormBackward0 at 0x2911de7c0>),\n",
       " (342, <TBackward0 at 0x29145f460>),\n",
       " (343, <MmBackward0 at 0x29145f190>),\n",
       " (344, <SliceBackward0 at 0x29145f160>),\n",
       " (345, <SliceBackward0 at 0x291453490>),\n",
       " (346, <SliceBackward0 at 0x2914534c0>),\n",
       " (347, <SliceBackward0 at 0x2911deee0>),\n",
       " (348, <GeluBackward0 at 0x2911de1f0>),\n",
       " (349, <MulBackward0 at 0x2911deaf0>),\n",
       " (350, <TBackward0 at 0x2911deb20>),\n",
       " (351, <AddmmBackward0 at 0x2911de790>),\n",
       " (352, <AddBackward0 at 0x2911de490>),\n",
       " (353, <NativeLayerNormBackward0 at 0x2911de580>),\n",
       " (354, <TBackward0 at 0x291461910>),\n",
       " (355, <AddmmBackward0 at 0x291461640>),\n",
       " (356, <torch.autograd.function.IndexPutFirstAxisBackward at 0x29145d340>),\n",
       " (357, <ViewBackward0 at 0x291461070>),\n",
       " (358, <ViewBackward0 at 0x291460cd0>),\n",
       " (359, <SliceBackward0 at 0x291461f40>),\n",
       " (360, <SliceBackward0 at 0x291461c10>),\n",
       " (361, <SelectBackward0 at 0x291461880>),\n",
       " (362, <SliceBackward0 at 0x2914615e0>),\n",
       " (363, <SliceBackward0 at 0x291461310>),\n",
       " (364, <PermuteBackward0 at 0x291460fd0>),\n",
       " (365, <SliceBackward0 at 0x291461f70>),\n",
       " (366, <SliceBackward0 at 0x291461c40>),\n",
       " (367, <SelectBackward0 at 0x2914618b0>),\n",
       " (368, <SliceBackward0 at 0x291461610>),\n",
       " (369, <SliceBackward0 at 0x291461340>),\n",
       " (370, <PermuteBackward0 at 0x291461040>),\n",
       " (371, <SliceBackward0 at 0x291460a00>),\n",
       " (372, <SliceBackward0 at 0x2914606d0>),\n",
       " (373, <SelectBackward0 at 0x291460400>),\n",
       " (374, <SliceBackward0 at 0x2914600a0>),\n",
       " (375, <SliceBackward0 at 0x29145fd90>),\n",
       " (376, <PermuteBackward0 at 0x29145fa60>),\n",
       " (377, <ExpandBackward0 at 0x291460c70>),\n",
       " (378, <ReshapeAliasBackward0 at 0x2914609a0>),\n",
       " (379, <ExpandBackward0 at 0x291460ca0>),\n",
       " (380, <ReshapeAliasBackward0 at 0x2914609d0>),\n",
       " (381, <BmmBackward0 at 0x2914606a0>),\n",
       " (382, <UnsafeViewBackward0 at 0x2914603d0>),\n",
       " (383, <DivBackward0 at 0x291460070>),\n",
       " (384, <AddBackward0 at 0x29145fd60>),\n",
       " (385, <SoftmaxBackward0 at 0x29145fa30>),\n",
       " (386, <ExpandBackward0 at 0x29145f760>),\n",
       " (387, <ViewBackward0 at 0x29145f400>),\n",
       " (388, <ExpandBackward0 at 0x29145f790>),\n",
       " (389, <ReshapeAliasBackward0 at 0x29145f430>),\n",
       " (390, <BmmBackward0 at 0x29145f130>),\n",
       " (391, <UnsafeViewBackward0 at 0x291453670>),\n",
       " (392, <PermuteBackward0 at 0x2911de280>),\n",
       " (393, <ReshapeAliasBackward0 at 0x2911dea90>),\n",
       " (394, <torch.autograd.function.IndexFirstAxisBackward at 0x29145d440>),\n",
       " (395, <ViewBackward0 at 0x2911de430>),\n",
       " (396, <TBackward0 at 0x2911de460>),\n",
       " (397, <AddmmBackward0 at 0x2911de310>),\n",
       " (398, <AddBackward0 at 0x291201e20>),\n",
       " (399, <NativeLayerNormBackward0 at 0x291201970>),\n",
       " (400, <TBackward0 at 0x2911dea60>),\n",
       " (401, <MmBackward0 at 0x2911de730>),\n",
       " (402, <SliceBackward0 at 0x2911de850>),\n",
       " (403, <SliceBackward0 at 0x2911de700>),\n",
       " (404, <SliceBackward0 at 0x2911de2b0>),\n",
       " (405, <SliceBackward0 at 0x2911de220>),\n",
       " (406, <GeluBackward0 at 0x291201280>),\n",
       " (407, <MulBackward0 at 0x291201070>),\n",
       " (408, <TBackward0 at 0x291201040>),\n",
       " (409, <AddmmBackward0 at 0x2912019a0>),\n",
       " (410, <AddBackward0 at 0x29142d880>),\n",
       " (411, <NativeLayerNormBackward0 at 0x291413850>),\n",
       " (412, <TBackward0 at 0x291460c40>),\n",
       " (413, <AddmmBackward0 at 0x291460970>),\n",
       " (414, <torch.autograd.function.IndexPutFirstAxisBackward at 0x29145d540>),\n",
       " (415, <ViewBackward0 at 0x2914603a0>),\n",
       " (416, <ViewBackward0 at 0x291460040>),\n",
       " (417, <SliceBackward0 at 0x2914612b0>),\n",
       " (418, <SliceBackward0 at 0x291460f40>),\n",
       " (419, <SelectBackward0 at 0x291460bb0>),\n",
       " (420, <SliceBackward0 at 0x291460910>),\n",
       " (421, <SliceBackward0 at 0x291460640>),\n",
       " (422, <PermuteBackward0 at 0x291460340>),\n",
       " (423, <SliceBackward0 at 0x2914612e0>),\n",
       " (424, <SliceBackward0 at 0x291460f70>),\n",
       " (425, <SelectBackward0 at 0x291460be0>),\n",
       " (426, <SliceBackward0 at 0x291460940>),\n",
       " (427, <SliceBackward0 at 0x291460670>),\n",
       " (428, <PermuteBackward0 at 0x291460370>),\n",
       " (429, <SliceBackward0 at 0x29145fd30>),\n",
       " (430, <SliceBackward0 at 0x29145fa00>),\n",
       " (431, <SelectBackward0 at 0x29145f730>),\n",
       " (432, <SliceBackward0 at 0x29145f3d0>),\n",
       " (433, <SliceBackward0 at 0x29145f100>),\n",
       " (434, <PermuteBackward0 at 0x291453640>),\n",
       " (435, <ExpandBackward0 at 0x29145ffa0>),\n",
       " (436, <ReshapeAliasBackward0 at 0x29145fcd0>),\n",
       " (437, <ExpandBackward0 at 0x29145ffd0>),\n",
       " (438, <ReshapeAliasBackward0 at 0x29145fd00>),\n",
       " (439, <BmmBackward0 at 0x29145f9d0>),\n",
       " (440, <UnsafeViewBackward0 at 0x29145f700>),\n",
       " (441, <DivBackward0 at 0x29145f3a0>),\n",
       " (442, <AddBackward0 at 0x29145f0d0>),\n",
       " (443, <SoftmaxBackward0 at 0x291453850>),\n",
       " (444, <ExpandBackward0 at 0x2911dedc0>),\n",
       " (445, <ViewBackward0 at 0x2911dea00>),\n",
       " (446, <ExpandBackward0 at 0x2911dedf0>),\n",
       " (447, <ReshapeAliasBackward0 at 0x2911dea30>),\n",
       " (448, <BmmBackward0 at 0x2911de820>),\n",
       " (449, <UnsafeViewBackward0 at 0x2911de6d0>),\n",
       " (450, <PermuteBackward0 at 0x291201250>),\n",
       " (451, <ReshapeAliasBackward0 at 0x291201130>),\n",
       " (452, <torch.autograd.function.IndexFirstAxisBackward at 0x29145d640>),\n",
       " (453, <ViewBackward0 at 0x29142d910>),\n",
       " (454, <TBackward0 at 0x29142ddc0>),\n",
       " (455, <AddmmBackward0 at 0x16b9935b0>),\n",
       " (456, <AddBackward0 at 0x1060ba760>),\n",
       " (457, <NativeLayerNormBackward0 at 0x291222580>),\n",
       " (458, <TBackward0 at 0x291201310>),\n",
       " (459, <MmBackward0 at 0x291201b50>),\n",
       " (460, <SliceBackward0 at 0x291201760>),\n",
       " (461, <SliceBackward0 at 0x29142d8b0>),\n",
       " (462, <SliceBackward0 at 0x29142d940>),\n",
       " (463, <SliceBackward0 at 0x16b993610>),\n",
       " (464, <GeluBackward0 at 0x16b993a00>),\n",
       " (465, <MulBackward0 at 0x1060ba4f0>),\n",
       " (466, <TBackward0 at 0x1060ba670>),\n",
       " (467, <AddmmBackward0 at 0x2912225b0>),\n",
       " (468, <AddBackward0 at 0x291218400>),\n",
       " (469, <NativeLayerNormBackward0 at 0x291445c70>),\n",
       " (470, <TBackward0 at 0x29145ff70>),\n",
       " (471, <AddmmBackward0 at 0x29145fca0>),\n",
       " (472, <torch.autograd.function.IndexPutFirstAxisBackward at 0x29145d740>),\n",
       " (473, <ViewBackward0 at 0x29145f6d0>),\n",
       " (474, <ViewBackward0 at 0x29145f370>),\n",
       " (475, <SliceBackward0 at 0x2914605e0>),\n",
       " (476, <SliceBackward0 at 0x2914602b0>),\n",
       " (477, <SelectBackward0 at 0x29145fee0>),\n",
       " (478, <SliceBackward0 at 0x29145fc40>),\n",
       " (479, <SliceBackward0 at 0x29145f970>),\n",
       " (480, <PermuteBackward0 at 0x29145f670>),\n",
       " (481, <SliceBackward0 at 0x291460610>),\n",
       " (482, <SliceBackward0 at 0x2914602e0>),\n",
       " (483, <SelectBackward0 at 0x29145ff10>),\n",
       " (484, <SliceBackward0 at 0x29145fc70>),\n",
       " (485, <SliceBackward0 at 0x29145f9a0>),\n",
       " (486, <PermuteBackward0 at 0x29145f6a0>),\n",
       " (487, <SliceBackward0 at 0x29145f0a0>),\n",
       " (488, <SliceBackward0 at 0x291453820>),\n",
       " (489, <SelectBackward0 at 0x2911ded90>),\n",
       " (490, <SliceBackward0 at 0x2911de9d0>),\n",
       " (491, <SliceBackward0 at 0x2911de6a0>),\n",
       " (492, <PermuteBackward0 at 0x2911de8e0>),\n",
       " (493, <ExpandBackward0 at 0x29145f310>),\n",
       " (494, <ReshapeAliasBackward0 at 0x29145f040>),\n",
       " (495, <ExpandBackward0 at 0x29145f340>),\n",
       " (496, <ReshapeAliasBackward0 at 0x29145f070>),\n",
       " (497, <BmmBackward0 at 0x291453a30>),\n",
       " (498, <UnsafeViewBackward0 at 0x2911ded00>),\n",
       " (499, <DivBackward0 at 0x2911de9a0>),\n",
       " (500, <AddBackward0 at 0x2911de670>),\n",
       " (501, <SoftmaxBackward0 at 0x2911dee50>),\n",
       " (502, <ExpandBackward0 at 0x2912011c0>),\n",
       " (503, <ViewBackward0 at 0x291201370>),\n",
       " (504, <ExpandBackward0 at 0x2912011f0>),\n",
       " (505, <ReshapeAliasBackward0 at 0x291201340>),\n",
       " (506, <BmmBackward0 at 0x291201940>),\n",
       " (507, <UnsafeViewBackward0 at 0x29142de20>),\n",
       " (508, <PermuteBackward0 at 0x16b993910>),\n",
       " (509, <ReshapeAliasBackward0 at 0x10608c880>),\n",
       " (510, <torch.autograd.function.IndexFirstAxisBackward at 0x29145d840>),\n",
       " (511, <ViewBackward0 at 0x291218460>),\n",
       " (512, <TBackward0 at 0x2912183d0>),\n",
       " (513, <AddmmBackward0 at 0x291445610>),\n",
       " (514, <AddBackward0 at 0x291445e50>),\n",
       " (515, <NativeLayerNormBackward0 at 0x29144b6d0>),\n",
       " (516, <TBackward0 at 0x10608cf40>),\n",
       " (517, <MmBackward0 at 0x291222760>),\n",
       " (518, <SliceBackward0 at 0x291222670>),\n",
       " (519, <SliceBackward0 at 0x291218100>),\n",
       " (520, <SliceBackward0 at 0x291218070>),\n",
       " (521, <SliceBackward0 at 0x291445640>),\n",
       " (522, <GeluBackward0 at 0x291445400>),\n",
       " (523, <MulBackward0 at 0x291445d90>),\n",
       " (524, <TBackward0 at 0x291445df0>),\n",
       " (525, <AddmmBackward0 at 0x29144b520>),\n",
       " (526, <AddBackward0 at 0x29144bd60>),\n",
       " (527, <NativeLayerNormBackward0 at 0x29122e3a0>),\n",
       " (528, <TBackward0 at 0x29145f2e0>),\n",
       " (529, <AddmmBackward0 at 0x291453fd0>),\n",
       " (530, <torch.autograd.function.IndexPutFirstAxisBackward at 0x29145d940>),\n",
       " (531, <ViewBackward0 at 0x2911decd0>),\n",
       " (532, <ViewBackward0 at 0x2911de970>),\n",
       " (533, <SliceBackward0 at 0x29145f910>),\n",
       " (534, <SliceBackward0 at 0x29145f5e0>),\n",
       " (535, <SelectBackward0 at 0x29145f250>),\n",
       " (536, <SliceBackward0 at 0x2914533d0>),\n",
       " (537, <SliceBackward0 at 0x291453c10>),\n",
       " (538, <PermuteBackward0 at 0x2911dec70>),\n",
       " (539, <SliceBackward0 at 0x29145f940>),\n",
       " (540, <SliceBackward0 at 0x29145f610>),\n",
       " (541, <SelectBackward0 at 0x29145f280>),\n",
       " (542, <SliceBackward0 at 0x291453460>),\n",
       " (543, <SliceBackward0 at 0x291453a00>),\n",
       " (544, <PermuteBackward0 at 0x2911deca0>),\n",
       " (545, <SliceBackward0 at 0x2911de640>),\n",
       " (546, <SliceBackward0 at 0x2911de8b0>),\n",
       " (547, <SelectBackward0 at 0x291201190>),\n",
       " (548, <SliceBackward0 at 0x2912013a0>),\n",
       " (549, <SliceBackward0 at 0x291201790>),\n",
       " (550, <PermuteBackward0 at 0x29142d970>),\n",
       " (551, <ExpandBackward0 at 0x2911de910>),\n",
       " (552, <ReshapeAliasBackward0 at 0x2911de5e0>),\n",
       " (553, <ExpandBackward0 at 0x2911de940>),\n",
       " (554, <ReshapeAliasBackward0 at 0x2911de610>),\n",
       " (555, <BmmBackward0 at 0x2911de3d0>),\n",
       " (556, <UnsafeViewBackward0 at 0x291201160>),\n",
       " (557, <DivBackward0 at 0x291201460>),\n",
       " (558, <AddBackward0 at 0x291201730>),\n",
       " (559, <SoftmaxBackward0 at 0x29142d9a0>),\n",
       " (560, <ExpandBackward0 at 0x16b9935e0>),\n",
       " (561, <ViewBackward0 at 0x291222700>),\n",
       " (562, <ExpandBackward0 at 0x16b9939d0>),\n",
       " (563, <ReshapeAliasBackward0 at 0x10608ce50>),\n",
       " (564, <BmmBackward0 at 0x2912220a0>),\n",
       " (565, <UnsafeViewBackward0 at 0x291218820>),\n",
       " (566, <PermuteBackward0 at 0x291445820>),\n",
       " (567, <ReshapeAliasBackward0 at 0x29144bf70>),\n",
       " (568, <torch.autograd.function.IndexFirstAxisBackward at 0x29145da40>),\n",
       " (569, <ViewBackward0 at 0x29144b130>),\n",
       " (570, <TBackward0 at 0x29144b160>),\n",
       " (571, <AddmmBackward0 at 0x29122e4c0>),\n",
       " (572, <AddBackward0 at 0x29126f1c0>),\n",
       " (573, <NativeLayerNormBackward0 at 0x29126f5e0>),\n",
       " (574, <TBackward0 at 0x29144bac0>),\n",
       " (575, <MmBackward0 at 0x29144b370>),\n",
       " (576, <SliceBackward0 at 0x29144b340>),\n",
       " (577, <SliceBackward0 at 0x29144b0a0>),\n",
       " (578, <SliceBackward0 at 0x29144b0d0>),\n",
       " (579, <SliceBackward0 at 0x29122e070>),\n",
       " (580, <GeluBackward0 at 0x29122e4f0>),\n",
       " (581, <MulBackward0 at 0x29126f040>),\n",
       " (582, <TBackward0 at 0x29126f400>),\n",
       " (583, <AddmmBackward0 at 0x29126f5b0>),\n",
       " (584, <AddBackward0 at 0x291205d60>),\n",
       " (585, <NativeLayerNormBackward0 at 0x291205520>),\n",
       " (586, <TBackward0 at 0x2911de880>),\n",
       " (587, <AddmmBackward0 at 0x2911de5b0>),\n",
       " (588, <torch.autograd.function.IndexPutFirstAxisBackward at 0x29145db40>),\n",
       " (589, <ViewBackward0 at 0x2912012e0>),\n",
       " (590, <ViewBackward0 at 0x291201be0>),\n",
       " (591, <SliceBackward0 at 0x291453df0>),\n",
       " (592, <SliceBackward0 at 0x2911debe0>),\n",
       " (593, <SelectBackward0 at 0x2911de7f0>),\n",
       " (594, <SliceBackward0 at 0x2911de520>),\n",
       " (595, <SliceBackward0 at 0x2911de100>),\n",
       " (596, <PermuteBackward0 at 0x2912010d0>),\n",
       " (597, <SliceBackward0 at 0x291453be0>),\n",
       " (598, <SliceBackward0 at 0x2911dec10>),\n",
       " (599, <SelectBackward0 at 0x2911deb80>),\n",
       " (600, <SliceBackward0 at 0x2911de550>),\n",
       " (601, <SliceBackward0 at 0x2911defa0>),\n",
       " (602, <PermuteBackward0 at 0x2912012b0>),\n",
       " (603, <SliceBackward0 at 0x291201880>),\n",
       " (604, <SliceBackward0 at 0x29142d8e0>),\n",
       " (605, <SelectBackward0 at 0x1060ba880>),\n",
       " (606, <SliceBackward0 at 0x2912225e0>),\n",
       " (607, <SliceBackward0 at 0x291222250>),\n",
       " (608, <PermuteBackward0 at 0x291218190>),\n",
       " (609, <ExpandBackward0 at 0x291201a30>),\n",
       " (610, <ReshapeAliasBackward0 at 0x291201cd0>),\n",
       " (611, <ExpandBackward0 at 0x291201a00>),\n",
       " (612, <ReshapeAliasBackward0 at 0x291201850>),\n",
       " (613, <BmmBackward0 at 0x29142d9d0>),\n",
       " (614, <UnsafeViewBackward0 at 0x1060ba640>),\n",
       " (615, <DivBackward0 at 0x291222130>),\n",
       " (616, <AddBackward0 at 0x2912222e0>),\n",
       " (617, <SoftmaxBackward0 at 0x291218730>),\n",
       " (618, <ExpandBackward0 at 0x291445ca0>),\n",
       " (619, <ViewBackward0 at 0x29144b8e0>),\n",
       " (620, <ExpandBackward0 at 0x291445cd0>),\n",
       " (621, <ReshapeAliasBackward0 at 0x29144ba90>),\n",
       " (622, <BmmBackward0 at 0x29144b1f0>),\n",
       " (623, <UnsafeViewBackward0 at 0x29144b070>),\n",
       " (624, <PermuteBackward0 at 0x29122e0d0>),\n",
       " (625, <ReshapeAliasBackward0 at 0x29126f550>),\n",
       " (626, <torch.autograd.function.IndexFirstAxisBackward at 0x29145dc40>),\n",
       " (627, <ViewBackward0 at 0x2912056d0>),\n",
       " (628, <TBackward0 at 0x291205af0>),\n",
       " (629, <AddmmBackward0 at 0x291205070>),\n",
       " (630, <AddBackward0 at 0x291205280>),\n",
       " (631, <NativeLayerNormBackward0 at 0x2912051c0>),\n",
       " (632, <TBackward0 at 0x29126f1f0>),\n",
       " (633, <MmBackward0 at 0x291205fa0>),\n",
       " (634, <SliceBackward0 at 0x291205fd0>),\n",
       " (635, <SliceBackward0 at 0x291205610>),\n",
       " (636, <SliceBackward0 at 0x291205220>),\n",
       " (637, <SliceBackward0 at 0x291205460>),\n",
       " (638, <GeluBackward0 at 0x291205400>),\n",
       " (639, <MulBackward0 at 0x2912053d0>),\n",
       " (640, <TBackward0 at 0x2912052e0>),\n",
       " (641, <AddmmBackward0 at 0x291205ca0>),\n",
       " (642, <AddBackward0 at 0x291205a90>),\n",
       " (643, <NativeLayerNormBackward0 at 0x291205e50>),\n",
       " (644, <TBackward0 at 0x291201a60>),\n",
       " (645, <AddmmBackward0 at 0x291201d60>),\n",
       " (646, <torch.autograd.function.IndexPutFirstAxisBackward at 0x29145dd40>),\n",
       " (647, <ViewBackward0 at 0x1060bae80>),\n",
       " (648, <ViewBackward0 at 0x291222280>),\n",
       " (649, <SliceBackward0 at 0x2911def70>),\n",
       " (650, <SliceBackward0 at 0x291201bb0>),\n",
       " (651, <SelectBackward0 at 0x291201af0>),\n",
       " (652, <SliceBackward0 at 0x291201c40>),\n",
       " (653, <SliceBackward0 at 0x2914139d0>),\n",
       " (654, <PermuteBackward0 at 0x1060ba430>),\n",
       " (655, <SliceBackward0 at 0x2911deeb0>),\n",
       " (656, <SliceBackward0 at 0x291201c70>),\n",
       " (657, <SelectBackward0 at 0x291201ac0>),\n",
       " (658, <SliceBackward0 at 0x291201c10>),\n",
       " (659, <SliceBackward0 at 0x29142de50>),\n",
       " (660, <PermuteBackward0 at 0x1060ba580>),\n",
       " (661, <SliceBackward0 at 0x291222850>),\n",
       " (662, <SliceBackward0 at 0x291218ac0>),\n",
       " (663, <SelectBackward0 at 0x291445d00>),\n",
       " (664, <SliceBackward0 at 0x29144b8b0>),\n",
       " (665, <SliceBackward0 at 0x29144b1c0>),\n",
       " (666, <PermuteBackward0 at 0x29144b040>),\n",
       " (667, <ExpandBackward0 at 0x291222610>),\n",
       " (668, <ReshapeAliasBackward0 at 0x2912226d0>),\n",
       " (669, <ExpandBackward0 at 0x2912226a0>),\n",
       " (670, <ReshapeAliasBackward0 at 0x2912220d0>),\n",
       " (671, <BmmBackward0 at 0x291218790>),\n",
       " (672, <UnsafeViewBackward0 at 0x291445ee0>),\n",
       " (673, <DivBackward0 at 0x29144b700>),\n",
       " (674, <AddBackward0 at 0x29144b190>),\n",
       " (675, <SoftmaxBackward0 at 0x29144be20>),\n",
       " (676, <ExpandBackward0 at 0x29122e580>),\n",
       " (677, <ViewBackward0 at 0x29126f640>),\n",
       " (678, <ExpandBackward0 at 0x29122e370>),\n",
       " (679, <ReshapeAliasBackward0 at 0x29126f580>),\n",
       " (680, <BmmBackward0 at 0x291205f10>),\n",
       " (681, <UnsafeViewBackward0 at 0x291205370>),\n",
       " (682, <PermuteBackward0 at 0x2912054c0>),\n",
       " (683, <ReshapeAliasBackward0 at 0x291205640>),\n",
       " (684, <torch.autograd.function.IndexFirstAxisBackward at 0x29145de40>),\n",
       " (685, <ViewBackward0 at 0x291205d00>),\n",
       " (686, <TBackward0 at 0x291205c10>),\n",
       " (687, <AddmmBackward0 at 0x291205d30>),\n",
       " (688, <AddBackward0 at 0x2912055b0>),\n",
       " (689, <NativeLayerNormBackward0 at 0x291205d90>),\n",
       " (690, <TBackward0 at 0x291205130>),\n",
       " (691, <MmBackward0 at 0x291205c40>),\n",
       " (692, <SliceBackward0 at 0x291205100>),\n",
       " (693, <SliceBackward0 at 0x291205cd0>),\n",
       " (694, <SliceBackward0 at 0x291205df0>),\n",
       " (695, <SliceBackward0 at 0x291205e20>),\n",
       " (696, <GeluBackward0 at 0x291205550>),\n",
       " (697, <MulBackward0 at 0x291205040>),\n",
       " (698, <TBackward0 at 0x291205970>),\n",
       " (699, <AddmmBackward0 at 0x2912059d0>),\n",
       " (700, <AddBackward0 at 0x2912059a0>),\n",
       " (701, <NativeLayerNormBackward0 at 0x291205a00>),\n",
       " (702, <torch.autograd.function.IndexPutFirstAxisBackward at 0x29145e040>),\n",
       " (703, <ViewBackward0 at 0x2912052b0>),\n",
       " (704, <AccumulateGrad at 0x291218160>),\n",
       " (705, <AccumulateGrad at 0x291460190>),\n",
       " (706, <AccumulateGrad at 0x291460250>),\n",
       " (707, <AccumulateGrad at 0x291460280>),\n",
       " (708, <AccumulateGrad at 0x291460310>),\n",
       " (709, <AccumulateGrad at 0x291460490>),\n",
       " (710, <AccumulateGrad at 0x291460550>),\n",
       " (711, <AccumulateGrad at 0x2914607f0>),\n",
       " (712, <AccumulateGrad at 0x2914608b0>),\n",
       " (713, <AccumulateGrad at 0x2914608e0>),\n",
       " (714, <AccumulateGrad at 0x291218b20>),\n",
       " (715, <AccumulateGrad at 0x291460b20>),\n",
       " (716, <AccumulateGrad at 0x291218bb0>),\n",
       " (717, <AccumulateGrad at 0x291460c10>),\n",
       " (718, <AccumulateGrad at 0x291460e20>),\n",
       " (719, <AccumulateGrad at 0x291460ee0>),\n",
       " (720, <AccumulateGrad at 0x291460f10>),\n",
       " (721, <AccumulateGrad at 0x291460fa0>),\n",
       " (722, <AccumulateGrad at 0x2912010a0>),\n",
       " (723, <AccumulateGrad at 0x291201100>),\n",
       " (724, <AccumulateGrad at 0x291461160>),\n",
       " (725, <AccumulateGrad at 0x291201220>),\n",
       " (726, <AccumulateGrad at 0x291461220>),\n",
       " (727, <AccumulateGrad at 0x291201400>),\n",
       " (728, <AccumulateGrad at 0x2914614c0>),\n",
       " (729, <AccumulateGrad at 0x291461580>),\n",
       " (730, <AccumulateGrad at 0x2914615b0>),\n",
       " (731, <AccumulateGrad at 0x2914617f0>),\n",
       " (732, <AccumulateGrad at 0x2914618e0>),\n",
       " (733, <AccumulateGrad at 0x291201a90>),\n",
       " (734, <AccumulateGrad at 0x291461af0>),\n",
       " (735, <AccumulateGrad at 0x291201b20>),\n",
       " (736, <AccumulateGrad at 0x291461bb0>),\n",
       " (737, <AccumulateGrad at 0x291461be0>),\n",
       " (738, <AccumulateGrad at 0x291461c70>),\n",
       " (739, <AccumulateGrad at 0x291461df0>),\n",
       " (740, <AccumulateGrad at 0x291461eb0>),\n",
       " (741, <AccumulateGrad at 0x291201fa0>),\n",
       " (742, <AccumulateGrad at 0x29145a100>),\n",
       " (743, <AccumulateGrad at 0x29145a1c0>),\n",
       " (744, <AccumulateGrad at 0x29145a400>),\n",
       " (745, <AccumulateGrad at 0x29145a430>),\n",
       " (746, <AccumulateGrad at 0x1060ba460>),\n",
       " (747, <AccumulateGrad at 0x29145a4c0>),\n",
       " (748, <AccumulateGrad at 0x291222640>),\n",
       " (749, <AccumulateGrad at 0x29145a640>),\n",
       " (750, <AccumulateGrad at 0x1060ba700>),\n",
       " (751, <AccumulateGrad at 0x29145a8b0>),\n",
       " (752, <AccumulateGrad at 0x29145a8e0>),\n",
       " (753, <AccumulateGrad at 0x29145ab20>),\n",
       " (754, <AccumulateGrad at 0x29145ad30>),\n",
       " (755, <AccumulateGrad at 0x29144b100>),\n",
       " (756, <AccumulateGrad at 0x291453160>),\n",
       " (757, <AccumulateGrad at 0x291463190>),\n",
       " (758, <AccumulateGrad at 0x291463250>),\n",
       " (759, <AccumulateGrad at 0x291463280>),\n",
       " (760, <AccumulateGrad at 0x291453340>),\n",
       " (761, <AccumulateGrad at 0x2914533a0>),\n",
       " (762, <AccumulateGrad at 0x2914634c0>),\n",
       " (763, <AccumulateGrad at 0x29144b4f0>),\n",
       " (764, <AccumulateGrad at 0x2914635b0>),\n",
       " (765, <AccumulateGrad at 0x2914637c0>),\n",
       " (766, <AccumulateGrad at 0x16b993820>),\n",
       " (767, <AccumulateGrad at 0x291463880>),\n",
       " (768, <AccumulateGrad at 0x2914638b0>),\n",
       " (769, <AccumulateGrad at 0x291463940>),\n",
       " (770, <AccumulateGrad at 0x16b993ac0>),\n",
       " (771, <AccumulateGrad at 0x291463ac0>),\n",
       " (772, <AccumulateGrad at 0x291463b80>),\n",
       " (773, <AccumulateGrad at 0x29144bc70>),\n",
       " (774, <AccumulateGrad at 0x291463df0>),\n",
       " (775, <AccumulateGrad at 0x29144bf40>),\n",
       " (776, <AccumulateGrad at 0x291453f70>),\n",
       " (777, <AccumulateGrad at 0x10608ce80>),\n",
       " (778, <AccumulateGrad at 0x2912050a0>),\n",
       " (779, <AccumulateGrad at 0x2912050d0>),\n",
       " (780, <AccumulateGrad at 0x2912051f0>),\n",
       " (781, <AccumulateGrad at 0x291205250>),\n",
       " (782, <AccumulateGrad at 0x29142d2b0>),\n",
       " (783, <AccumulateGrad at 0x29142d2e0>),\n",
       " (784, <AccumulateGrad at 0x2912053a0>),\n",
       " (785, <AccumulateGrad at 0x2912056a0>),\n",
       " (786, <AccumulateGrad at 0x2912057f0>),\n",
       " (787, <AccumulateGrad at 0x291205850>),\n",
       " (788, <AccumulateGrad at 0x291205880>),\n",
       " (789, <AccumulateGrad at 0x291205940>),\n",
       " (790, <AccumulateGrad at 0x291205a60>),\n",
       " (791, <AccumulateGrad at 0x291445a90>),\n",
       " (792, <AccumulateGrad at 0x291205be0>),\n",
       " (793, <AccumulateGrad at 0x291445c40>),\n",
       " (794, <AccumulateGrad at 0x291205c70>),\n",
       " (795, <AccumulateGrad at 0x291445d60>),\n",
       " (796, <AccumulateGrad at 0x29142dd90>),\n",
       " (797, <AccumulateGrad at 0x291205dc0>),\n",
       " (798, <AccumulateGrad at 0x291445e20>),\n",
       " (799, <AccumulateGrad at 0x291205e80>),\n",
       " (800, <AccumulateGrad at 0x291445e80>),\n",
       " (801, <AccumulateGrad at 0x291205ee0>),\n",
       " (802, <AccumulateGrad at 0x291205f40>),\n",
       " (803, <AccumulateGrad at 0x291205f70>),\n",
       " (804, <AccumulateGrad at 0x29122e160>),\n",
       " (805, <AccumulateGrad at 0x29122e1c0>),\n",
       " (806, <AccumulateGrad at 0x2911de250>),\n",
       " (807, <AccumulateGrad at 0x29146e250>),\n",
       " (808, <AccumulateGrad at 0x29122e2b0>),\n",
       " (809, <AccumulateGrad at 0x2911de400>),\n",
       " (810, <AccumulateGrad at 0x29146e400>),\n",
       " (811, <AccumulateGrad at 0x2911de4c0>),\n",
       " (812, <AccumulateGrad at 0x2911de4f0>),\n",
       " (813, <AccumulateGrad at 0x29122e610>),\n",
       " (814, <AccumulateGrad at 0x2911de760>),\n",
       " (815, <AccumulateGrad at 0x29146e7c0>),\n",
       " (816, <AccumulateGrad at 0x29146e910>),\n",
       " (817, <AccumulateGrad at 0x2911deac0>),\n",
       " (818, <AccumulateGrad at 0x29146eb80>),\n",
       " (819, <AccumulateGrad at 0x2911debb0>),\n",
       " (820, <AccumulateGrad at 0x2911dec40>),\n",
       " (821, <AccumulateGrad at 0x29146ec40>),\n",
       " (822, <AccumulateGrad at 0x2911ded30>),\n",
       " (823, <AccumulateGrad at 0x2911ded60>),\n",
       " (824, <AccumulateGrad at 0x2911dee20>),\n",
       " (825, <AccumulateGrad at 0x29145f1c0>),\n",
       " (826, <AccumulateGrad at 0x29145f2b0>),\n",
       " (827, <AccumulateGrad at 0x29145f4c0>),\n",
       " (828, <AccumulateGrad at 0x29145f580>),\n",
       " (829, <AccumulateGrad at 0x29145f5b0>),\n",
       " (830, <AccumulateGrad at 0x29126f610>),\n",
       " (831, <AccumulateGrad at 0x29145f640>),\n",
       " (832, <AccumulateGrad at 0x29126f6a0>),\n",
       " (833, <AccumulateGrad at 0x29145f7c0>),\n",
       " (834, <AccumulateGrad at 0x29145f880>),\n",
       " (835, <AccumulateGrad at 0x29145fb20>),\n",
       " (836, <AccumulateGrad at 0x29145fbe0>),\n",
       " (837, <AccumulateGrad at 0x29145fc10>),\n",
       " (838, <AccumulateGrad at 0x29145fe50>),\n",
       " (839, <AccumulateGrad at 0x29145ff40>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(visited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca910056-cec9-4f95-85b0-f606f23f954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_input_metadata',\n",
       " '_raw_saved_bias',\n",
       " '_raw_saved_input',\n",
       " '_raw_saved_result1',\n",
       " '_raw_saved_result2',\n",
       " '_raw_saved_weight',\n",
       " '_register_hook_dict',\n",
       " '_saved_bias',\n",
       " '_saved_input',\n",
       " '_saved_normalized_shape',\n",
       " '_saved_result1',\n",
       " '_saved_result2',\n",
       " '_saved_weight',\n",
       " '_sequence_nr',\n",
       " '_set_sequence_nr',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'next_functions',\n",
       " 'register_hook',\n",
       " 'register_prehook',\n",
       " 'requires_grad']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visited[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9851049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For denominator stability in relevance distribution\n",
    "epsilon = 10e-6\n",
    "\n",
    "def renormalize_epsilon(rz, rx, ry):\n",
    "    # Renormalizes output relevances after dividing by a denominator with epsilon added to preserve conservation\n",
    "    scale = rz / (rx + ry)\n",
    "    return rx * scale, ry * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "51abf176-b5df-4314-a419-2579a6594290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddBackwardPromise:\n",
    "    def __init__(self, promise, idx):\n",
    "        # promise: shared data between the promise origin and both branches.\n",
    "        # idx: specifies which argument/operand the branch is looking for.\n",
    "        # fwd: applies all operations to the operand found from a branch to the origin of the promise.\n",
    "        # bwd: applies all operations to the relevance of the operand from the origin of the promise\n",
    "        #   to the end of the branch, possibly in steps if one or more Checkpoints were on the branch.\n",
    "        #   Structure: [ (checkpoint1, fcn_to_get_from_origin_to_checkpoint1),\n",
    "        #                (checkpoint2, fcn_to_get_from_checkpoint1_to_checkpoint2),\n",
    "        #                ...\n",
    "        #                (None, fcn_to_get_from_last_checkpoint_to_curnode) ]\n",
    "        #   So you should apply from left to right, but the inner functions themselves nest right to left.\n",
    "        # fwd_shape: used as target shape for shape-modifying operations in fwd\n",
    "        self.promise = promise\n",
    "        self.parent = promise[\"parent\"]\n",
    "        self.children = None # Will be set to list[AddBackwardPromise] if further nested AddBackward Nodes are found.\n",
    "        self.idx = idx\n",
    "        self.fwd = lambda x: x\n",
    "        self.bwd = [ (None, lambda x: x) ] # This will chain in case we come across a Checkpoint partway through\n",
    "        self.fwd_shape = promise[\"rout\"].shape # This will update after a shape-modifying operation is added to fwd\n",
    "        self.other_branch = None\n",
    "\n",
    "    def nest_fwd(self, next_f):\n",
    "        # Nests a new operation for recovering the operand for the promise origin\n",
    "        self.fwd = lambda x: self.fwd(next_f(x))\n",
    "\n",
    "    def checkpoint(self, new_checkpoint):\n",
    "        # Marks a checkpoint in the backwards op chain and opens a new chain after the checkpoint\n",
    "        self.bwd[-1] = (new_checkpoint, self.bwd[-1][1])\n",
    "        self.bwd.append((None, lambda x: x))\n",
    "\n",
    "    def nest_bwd(self, next_f):\n",
    "        # Stacks on a new operation for transforming the promised relevance back down the branch\n",
    "        last_checkpoint, most_recent_f = self.bwd[-1] # last_checkpoint is actually always None here\n",
    "        self.bwd[-1] = (last_checkpoint, lambda x: next_f(most_recent_f(x)))\n",
    "\n",
    "    @property\n",
    "    def ready(self):\n",
    "        return self.promise[\"ready\"]\n",
    "\n",
    "    @property\n",
    "    def complete(self):\n",
    "        # Flags if the promise is done all forward and backward execution\n",
    "        # If the promise is complete and has children, it will have set its children's rout value to its bwd(rin)\n",
    "        # result. So the children need only check if parent.complete is True to begin their own exec_bwd().\n",
    "        return self.promise[\"complete\"]\n",
    "\n",
    "    @property\n",
    "    def arg1(self):\n",
    "        return self.promise[\"args\"][0] # TODO: see if we really need both of these or just the arg for the branch\n",
    "\n",
    "    @property\n",
    "    def arg2(self):\n",
    "        return self.promise[\"args\"][1]\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.fwd_shape\n",
    "\n",
    "    @property\n",
    "    def rin(self):\n",
    "        return self.promise[\"rins\"][self.idx]\n",
    "\n",
    "    @property\n",
    "    def rout(self):\n",
    "        return self.promise[\"rout\"]\n",
    "\n",
    "    def set_rout(self, new_rout):\n",
    "        self.promise[\"rout\"] = new_rout\n",
    "\n",
    "    def exec_bwd(self):\n",
    "        # Perform each saved backward execution chain to propagate relevance back down the branch.\n",
    "        # Save values for any checkpoints marked along the path and return them with their respective checkpoints.\n",
    "        assert(self.ready and (self.parent is None or self.parent.complete),\n",
    "               \"Promise backward execution was triggered before promise was ready or before parent promise was complete.\")\n",
    "        res = self.rin\n",
    "        checkpoints = []\n",
    "        for checkpoint, fcn in self.bwd:\n",
    "            res = fcn(res)\n",
    "            if checkpoint is not None:\n",
    "                checkpoints.append((checkpoint, res))\n",
    "        return checkpoints, res\n",
    "\n",
    "    def compute_rins(self):\n",
    "        # Compute base branch relevances based on sum of squares ratios.\n",
    "        assert(self.ready and (self.parent is None or self.parent.complete))\n",
    "        arg1, arg2 = self.promise[\"args\"]\n",
    "        r = self.promise[\"rout\"]\n",
    "        denom = arg1 ** 2 + arg2 ** 2 + epsilon\n",
    "        r1 = (arg1 ** 2 / denom) * r\n",
    "        r2 = (arg2 ** 2 / denom) * r\n",
    "        self.promise[\"rins\"][0], self.promise[\"rins\"][1] = renormalize_epsilon(r, r1, r2)\n",
    "\n",
    "    def trigger_promise_completion(self):\n",
    "        # This is only called once a promise receives its second argument.\n",
    "        assert(self.ready, \"Promise completion was triggered before promise was ready.\")\n",
    "        if self.parent is None or self.parent.complete:\n",
    "            # Either reached root of a promise tree, or we are in the exec_bwd call of a child of a completed promise.\n",
    "            self.compute_rins()\n",
    "            checkpoints1, res1 = self.exec_bwd()\n",
    "            checkpoints2, res2 = self.other_branch.exec_bwd()\n",
    "            # Save checkpoint relevances to their grad_fn metadatas to collect later.\n",
    "            for checkpoint, val in checkpoints1 + checkpoints2:\n",
    "                checkpoint.metadata[\"checkpoint_relevance\"] = val\n",
    "            self.complete = True\n",
    "\n",
    "            if self.children is not None:\n",
    "                # Now that we have calculated the end relevance_in of this branch, we can feed it to the children promises.\n",
    "                for child_promise in self.children:\n",
    "                    child_promise.set_rout(res1)\n",
    "                    child_promise.trigger_promise_completion()\n",
    "\n",
    "            if self.other_branch.children is not None:\n",
    "                # Do the same for the other branch in this promise. (I should really make Promise and Branch two different classes...)\n",
    "                for child_promise in self.other_branch.children:\n",
    "                    child_promise.set_rout(res2)\n",
    "                    child_promise.trigger_promise_completion()\n",
    "\n",
    "        else:\n",
    "            # If there is a parent promise, but it is not complete yet, we can now set its arg with this promise's result.\n",
    "            # This is what triggers the propagation of the arguments back to the root of the promise tree.\n",
    "            self.promise[\"parent\"].setarg(self.arg1 + self.arg2)\n",
    "\n",
    "    def setarg(self, value):\n",
    "        # Set the corresponding arg for this branch and check if the promise is ready\n",
    "        self.promise[\"args\"][self.idx] = self.fwd(value)\n",
    "        self.promise[\"ready\"] = all([ x is not None for x in self.promise[\"args\"] ])\n",
    "        if self.promise[\"ready\"]:\n",
    "            self.trigger_promise_completion()\n",
    "\n",
    "def AddBackwardProp(grad_fn, r):\n",
    "    # IMPORTANT: AddBackward0 does not actually store any operands of the addition, so we have\n",
    "    # to get a bit tricky.\n",
    "    # The idea is to return a \"promise\", a dict wrapped in a class which contains the outgoing relevance, and\n",
    "    # placeholders for the operands and their respective relevances.\n",
    "    # From what I know right now, AddBackward0 is the only math-op grad_fn that does this, so the hope is\n",
    "    # that we pass this promise down the graph, and we encounter one of:\n",
    "    #   1. AccumulateGrad or another math-op that we can get the result from\n",
    "    #   2. A function that follows the identity or uniform rule like GeluBackward0 or LayerNormBackward0\n",
    "    #   3. A mutation function like SliceBackward0 or ReshapeBackward0\n",
    "    #   4. (worst case) Another AddBackward0\n",
    "    # For case 2 and 3, we would have to keep an arbitrarily composable function which progressively\n",
    "    # nests the operations that must be done on the result, once it is found, to make it equivalent\n",
    "    # to the downstream addition operand. When we find a node with the result, we simply apply f(result)\n",
    "    # to get the actual operand for the original addition.\n",
    "    # However, we will also need to keep a similar function but for going backwards from the addition\n",
    "    # back to the result node, but this time for the relevance.\n",
    "    # If at this time, both operands have been found, compute and store the relevances for both in the\n",
    "    # promise. If not, move this node to the \n",
    "    # For case 4, we would simply have to nest a promise within the existing promise.\n",
    "    # So the only time this algorithm will branch is if there are multiple additions with no result-\n",
    "    # yielding grad_fn's in between.\n",
    "\n",
    "    promise = {\n",
    "        \"rout\": r,\n",
    "        \"args\": [None, None],\n",
    "        \"rins\": [None, None],\n",
    "        \"ready\": False,\n",
    "        \"complete\": False,\n",
    "        \"parent\": None,\n",
    "    }\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        promise[\"parent\"] = r\n",
    "        promise[\"rout\"] = torch.zeros(r.fwd_shape) # Placeholder for shape\n",
    "\n",
    "    promise1 = AddBackwardPromise(promise, 0)\n",
    "    promise2 = AddBackwardPromise(promise, 1)\n",
    "\n",
    "    promise1.other_branch = promise2\n",
    "    promise2.other_branch = promise1\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.children = [promise1, promise2]\n",
    "\n",
    "    grad_fn.metadata[\"promise\"] = promise\n",
    "\n",
    "    return promise1, promise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f53d6-6b27-4cd2-9052-8e7fbc3c84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling AddMmBackward0 is not the exact same as just AddBackward0. The calculation of the in-relevances\n",
    "# is slightly different because you need to consider the matmul after the addition is propagated.\n",
    "# AddMmBackward0 also has 3 inputs, rather than 2 as in AddBackward0, so they will not be easily\n",
    "# compatible with the current promise tree structure.\n",
    "# I created the promise and promise tree structure with the aim to not have to re-visit the promise\n",
    "# origin nodes after sending out the promises (we re-visit the promise tree nodes, but not the grad_fn\n",
    "# nodes themselves). AddMmBackward0 would add a good amount of extra work if we were to handle it with\n",
    "# promises, it would require a completely different promise completion handling sequence.\n",
    "# It would be much easier to simply decompose an AddMmBackward0 into an AddBackward0 and a MmBackward0\n",
    "# in our graph, then traverse using the normal AddBackward0 promises, where we can fill in the Mm side first.\n",
    "\n",
    "# Since the autograd Nodes are code-generated and not exposed to the torch API, we just redefine shell\n",
    "# classes for the ones we need to instantiate, with the fields we need according to the dir() of the\n",
    "# original classes.\n",
    "class AddBackward0:\n",
    "    def __init__(self, next_functions):\n",
    "        self.name = \"AddBackward0\"\n",
    "        self.next_functions = next_functions\n",
    "        self.metadata = {}\n",
    "\n",
    "class MmBackward0:\n",
    "    def __init__(self, next_functions, mat1, mat2):\n",
    "        self.name = \"MmBackward0\"\n",
    "        self.next_functions = next_functions\n",
    "        self._saved_self = mat1\n",
    "        self._saved_self_sym_sizes = mat1.shape\n",
    "        self._saved_mat2 = mat2\n",
    "        self._saved_mat2_sym_sizes = mat2.shape\n",
    "\n",
    "def decompose_addmmbackward(grad_fn):\n",
    "    # Assuming grad_fn is an instance of AddMmBackward, returns an AddBackward0 instance that is the parent\n",
    "    # of an MmBackward0 instance and the first function in grad_fn.next_functions.\n",
    "    # The MmBackward0 is then the parent of the last two functions in grad_fn.next_functions.\n",
    "    mm_fn = MmBackward0(grad_fn.next_functions[1:], grad_fn._saved_mat1, grad_fn._saved_mat2)\n",
    "    add_fn = AddBackward0((grad_fn.next_functions[0], (mm_fn, 0)))\n",
    "\n",
    "    return add_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a3ebc-d27e-4b2b-8a98-98f4dc8bfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "For all these functions, grad_fn is the autograd Node returned from traversing the autograd graph.\n",
    "r is the relevance tensor of the output of the given Node.\n",
    "\"\"\"\n",
    "\n",
    "def ViewBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        target_shape = r.fwd_shape\n",
    "        r.nest_fwd(lambda x: torch.view(x, target_shape))\n",
    "        r.nest_bwd(lambda x: torch.view(x, upstream_shape))\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return torch.view(r, upstream_shape)\n",
    "\n",
    "def UnsafeViewBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        target_shape = r.fwd_shape\n",
    "        r.nest_fwd(lambda x: torch.view(x, target_shape))\n",
    "        r.nest_bwd(lambda x: torch.view(x, upstream_shape))\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return torch.view(r, upstream_shape)\n",
    "\n",
    "def ReshapeBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        target_shape = r.fwd_shape\n",
    "        r.nest_fwd(lambda x: torch.reshape(x, target_shape))\n",
    "        r.nest_bwd(lambda x: torch.reshape(x, upstream_shape))\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return torch.reshape(r, grad_fn._saved_self_sym_sizes)\n",
    "\n",
    "def SliceBackwardProp(grad_fn, r):\n",
    "    # Assumes the index corresponding to _saved_start in the forward pass is non-negative.\n",
    "    # If it was negative-indexed, i.e. x[-i:] autograd saves the index as INT_MAX - i.\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    sliced_dim = grad_fn._saved_dim\n",
    "    start = grad_fn._saved_start # TODO: Come back to take care of the negative index case.\n",
    "    full_size = upstream_shape[sliced_dim]\n",
    "    end = start + r.shape[sliced_dim]\n",
    "\n",
    "    # We wish to pad r so that it becomes the correct size along the sliced dimension\n",
    "    pad = []\n",
    "    to_pad = [start, full_size - end]\n",
    "\n",
    "    # Iterate in reverse order, since F.pad() takes in dims from last to first,\n",
    "    # see https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.pad.html\n",
    "    # All dims other than sliced_dim should be 0, 0\n",
    "    for dim in range(len(upstream_shape) - 1, -1, -1):\n",
    "        pad += [0, 0] if dim != sliced_dim else to_pad\n",
    "    pad = tuple(pad)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(lambda x: torch.ops.aten.slice(x, sliced_dim, start, end))\n",
    "        r.nest_bwd(lambda x: F.pad(x, pad))\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return F.pad(r, pad)\n",
    "\n",
    "def IndexBackwardProp(grad_fn, r):\n",
    "    # An Index can be compound, unlike Slice, i.e. a[[0,1], [1,2]] is ONE Index op, whereas a[:,1:] is TWO Slice ops.\n",
    "    # This is because (in this case) the second Slice depends on the first. It's saying that from the result of\n",
    "    # the first slice, for each element, select index 1 from the first, and index 2 from the second (assuming of\n",
    "    # course that 1 and 2 are in bounds for each element returned by the first slice).\n",
    "    # Therefore, the length of the first Slice acts as an upper bound for the length of the Slices that succeed it.\n",
    "    # If you wanted it to select indices 1 and 2 for each resulting element, you would just use a Slice for the last\n",
    "    # dim instead of an Index.\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    \n",
    "    idxs = [ torch.tensor(x) if x is not None else None for x in grad_fn._saved_indices ]\n",
    "\n",
    "    def undoIndex(x):\n",
    "        out = torch.zeros(upstream_shape, dtype=x.dtype, device=x.device)\n",
    "        return torch.ops.aten.index_put(out, idxs, x)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(lambda x: torch.ops.aten.index(x, idxs))\n",
    "        r.nest_bwd(undoIndex)\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "    return undoIndex(r)\n",
    "            \n",
    "\n",
    "def SelectBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    dim = grad_fn._saved_dim\n",
    "    idx = grad_fn._saved_index\n",
    "\n",
    "    def undoSelect(x):\n",
    "        out = torch.zeros(upstream_shape, dtype=x.dtype, device=x.device)\n",
    "        x_expanded = torch.unsqueeze(x, dim)\n",
    "        out.select(dim, idx).copy_(x_expanded)\n",
    "        return out\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(lambda x: torch.select(x, dim, idx))\n",
    "        r.nest_bwd(undoSelect)\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "\n",
    "    return undoSelect(r)\n",
    "\n",
    "def TBackwardProp(grad_fn, r):\n",
    "    # Not sure why TBackward is different from TransposeBackward, but it seems like this is only\n",
    "    # in Linear layer matmuls on W for xW^T before Mm and Addmm operations.\n",
    "    assert(len(r.shape) == 2, \"Assumption was that matrix would be 2d Linear weights.\") # For now assume that it is only 2d matmuls for Linear layers.\n",
    "\n",
    "    transpose = lambda x: x.T\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(transpose)\n",
    "        r.nest_bwd(transpose)\n",
    "        new_shape = list(r.fwd_shape)\n",
    "        new_shape[0], new_shape[1] = new_shape[1], new_shape[0]\n",
    "        r.fwd_shape = tuple(new_shape)\n",
    "        return r\n",
    "\n",
    "    return transpose(r)\n",
    "\n",
    "def TransposeBackwardProp(grad_fn, r):\n",
    "    dim1 = grad_fn._saved_dim0\n",
    "    dim2 = grad_fn._saved_dim1\n",
    "\n",
    "    if dim1 == 2**32 - 2:\n",
    "        dim1 = -2\n",
    "    if dim2 == 2**32 - 1:\n",
    "        dim2 = -1\n",
    "\n",
    "    swapaxes = lambda x: torch.swapaxes(x, dim1, dim2)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(swapaxes)\n",
    "        r.nest_bwd(swapaxes)\n",
    "        new_shape = list(r.fwd_shape)\n",
    "        new_shape[dim1], new_shape[dim2] = new_shape[dim2], new_shape[dim1]\n",
    "        r.fwd_shape = tuple(new_shape)\n",
    "        return r\n",
    "    \n",
    "    return swapaxes(r)\n",
    "\n",
    "def PermuteBackwardProp(grad_fn, r):\n",
    "    dims = grad_fn._saved_dims\n",
    "    permute = lambda x: torch.permute(x, dims)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(permute)\n",
    "        r.nest_bwd(permute)\n",
    "        new_shape = list(r.fwd_shape)\n",
    "        for old_dim, new_dim in enumerate(dims):\n",
    "            new_shape[old_dim] = r.fwd_shape[new_dim]\n",
    "        r.fwd_shape = tuple(new_shape)\n",
    "        return r\n",
    "    return permute(r)\n",
    "\n",
    "def ExpandBackwardProp(grad_fn, r):\n",
    "    upstream_shape = grad_fn._saved_self_sym_sizes\n",
    "    downstream_shape = r.shape\n",
    "    assert(len(upstream_shape) == len(downstream_shape), \"Expand should not increase number of dimensions.\")\n",
    "\n",
    "    expand_input = [ dim2 if dim1 != dim2 else -1 for dim1, dim2 in zip(upstream_shape, downstream_shape) ]\n",
    "\n",
    "    def undoExpand(x):\n",
    "        for i, expand_dim in enumerate(expand_input):\n",
    "            if expand_dim != -1:\n",
    "                x = x.select(i, 0).unsqueeze(i)\n",
    "        return x\n",
    "\n",
    "    expand = lambda x: x.expand(*expand_input)\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.nest_fwd(expand)\n",
    "        r.nest_bwd(undoExpand)\n",
    "        r.fwd_shape = upstream_shape\n",
    "        return r\n",
    "\n",
    "    return undoExpand(r)\n",
    "\n",
    "def MulBackwardProp(grad_fn, r):\n",
    "    arg1 = grad_fn._saved_self\n",
    "    arg2 = grad_fn._saved_other\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        if arg1 is None:\n",
    "            r.nest_fwd(lambda x: x * arg2)\n",
    "        else:\n",
    "            r.setarg(arg1 * arg2)\n",
    "            if r.complete:\n",
    "                r = r.rin\n",
    "            else:\n",
    "                return None # Trigger requeue\n",
    "\n",
    "    if arg1 is None:\n",
    "        # Tensor-scalar product, disregard scalar\n",
    "        return r, 0.0\n",
    "\n",
    "    denom = arg1.abs() + arg2.abs() + epsilon\n",
    "    r1 = (arg1.abs() / denom) * r\n",
    "    r2 = (arg2.abs() / denom) * r\n",
    "\n",
    "    return renormalize_epsilon(r, r1, r2)\n",
    "\n",
    "def DivBackwardProp(grad_fn, r):\n",
    "    arg1 = grad_fn._saved_self\n",
    "    arg2 = grad_fn._saved_other\n",
    "\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        if arg1 is None:\n",
    "            r.nest_fwd(lambda x: x / arg2)\n",
    "        else:\n",
    "            r.setarg(arg1 / arg2)\n",
    "            if r.complete:\n",
    "                r = r.rin\n",
    "            else:\n",
    "                return None # Trigger requeue\n",
    "\n",
    "    if arg1 is None:\n",
    "        # Tensor-scalar product, disregard scalar\n",
    "        return r, 0.0\n",
    "\n",
    "    denom = arg1.abs() + (1 / arg2).abs() + epsilon\n",
    "    r1 = (arg1.abs() / denom) * r\n",
    "    r2 = ((1 / arg2).abs() / denom) * r\n",
    "\n",
    "    return renormalize_epsilon(r, r1, r2)\n",
    "\n",
    "def MmBackwardProp(grad_fn, r):\n",
    "    x = grad_fn._saved_mat1 # i j\n",
    "    weights = grad_fn._saved_mat2 # j k\n",
    "    z = torch.matmul(x, weights)\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.setarg(z)\n",
    "        if r.complete:\n",
    "            r = r.rin\n",
    "        else:\n",
    "            # If this is the first branch of the promise\n",
    "            return None # Make this trigger a requeue\n",
    "\n",
    "    i, j = x.shape\n",
    "    k = weights.shape[1]\n",
    "    intermediates = torch.einsum(\"ij, jk -> ijk\", x, weights)\n",
    "\n",
    "    z = z.unsqueeze(1).broadcast_to((i,j,k))\n",
    "\n",
    "    ratios = intermediates / z\n",
    "\n",
    "    # return relevance for input and relevance for weight\n",
    "    return ratios.sum(dim=2, keepdims=True) * r, ratios.sum(dim=0, keepdims=True) * r.T\n",
    "\n",
    "def BmmBackwardProp(grad_fn, r):\n",
    "    mat1 = grad_fn.saved_self\n",
    "    mat2 = grad_fn.saved_mat2\n",
    "    z = torch.matmul(mat1, mat2)\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.setarg(z)\n",
    "        if r.complete:\n",
    "            r = r.rin\n",
    "        else:\n",
    "            # If this is the first branch of the promise\n",
    "            return None # Make this trigger a requeue\n",
    "\n",
    "    b, i, j = mat1.shape\n",
    "    k = mat2.shape[-1]\n",
    "    intermediates = torch.einsum(\"bij, bjk -> bijk\", mat1, mat2)\n",
    "\n",
    "    z = z.unsqueeze(2).broadcast_to((b,i,j,k))\n",
    "\n",
    "    ratios = intermediates / z\n",
    "\n",
    "    # return relevance for mat1 and relevance for mat2\n",
    "    return ratios.sum(dim=2, keepdims=True) * r, ratios.sum(dim=1, keepdims=True) * r.T\n",
    "\n",
    "def NativeLayerNormBackwardProp(grad_fn, r):\n",
    "    mean = grad_fn._saved_result1\n",
    "    gamma = grad_fn._saved_weight\n",
    "    beta = grad_fn._saved_bias\n",
    "    rec_stddev = grad_fn._saved_result2\n",
    "    def layerNorm(x):\n",
    "        normalized = (x - mean) * rec_stddev\n",
    "        return normalized * gamma + beta\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        # Identity for relevance going backwards, no need for bwd\n",
    "        r.nest_fwd(layerNorm)\n",
    "\n",
    "    # next_functions will correspond to input, weights, bias\n",
    "    # We only care about propagating through the input for LayerNorm.\n",
    "    return r, 0.0, 0.0\n",
    "\n",
    "def GeluBackwardProp(grad_fn, r):\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        # Identity for relevance going backwards, no need for bwd\n",
    "        r.nest_fwd(torch.nn.GELU(approximate=\"none\"))\n",
    "    return r\n",
    "\n",
    "def SoftmaxBackwardProp(grad_fn, r):\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        # Identity for relevance going backwards, no need for bwd\n",
    "        r.nest_fwd(lambda x: x.softmax(dim=-1))\n",
    "    return r\n",
    "\n",
    "def IdentityProp(grad_fn, r):\n",
    "    \"\"\"Placeholder for any missed operations, or general use for identity-rule operations.\"\"\"\n",
    "    return r\n",
    "    \n",
    "def AccumulateGradProp(grad_fn, r):\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.setarg(grad_fn.variable)\n",
    "    return 0.0\n",
    "\n",
    "def LRPCheckpointBackwardProp(grad_fn, r):\n",
    "    if isinstance(r, AddBackwardPromise):\n",
    "        r.checkpoint(grad_fn)\n",
    "    else:\n",
    "        grad_fn.metadata[\"checkpoint_relevance\"] = r\n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "dd381d58-e580-4699-8f3c-2a03604c4442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 3072, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "start = 3072\n",
    "end = 6144\n",
    "to_pad = [start, 6144 - end]\n",
    "sliced_dim = 2\n",
    "pad = tuple(sum([ [0,0] if i != sliced_dim else to_pad for i in range(3, -1, -1) ], []))\n",
    "print(pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e4f1ff55-aee6-4e32-a0dd-68c669381033",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((1,17,3072,3))\n",
    "a.shape\n",
    "b = F.pad(a, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "004d4d1d-17bc-4699-9e63-9396f0d4ac99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited[:10].index(visited[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "64a23e69-3718-4da7-82c7-29e7d0964c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "out_adj = {}\n",
    "in_adj = {}\n",
    "\n",
    "root = hidden_states.grad_fn\n",
    "visited = set()\n",
    "fcns = [ [root] ]\n",
    "# idea: dynamically init relevance variables when branching occurs, assign them to the corresponding\n",
    "# downstream nodes they should belong to using next_functions and visited table. Requires 2 passes.\n",
    "# Perhaps need a last_saved_relevance for each node, in the case when a node is traversed more than once to accumulate relevance.\n",
    "# Need all incoming branches to land before we continue, else we need to compute the same downstream paths multiple times for\n",
    "# each incoming branch.\n",
    "# Modified DFS? Traverse down a path, creating all necessary relevance branches until a node with multiple in-edges is reached.\n",
    "# We will need a modified graph as well with in_children for each node to determine the above condition.\n",
    "\n",
    "# First pass will:\n",
    "# 1. Create in and out adjacency lists.\n",
    "# 2. Decompose AddMmBackward0's with AddBackward0 leading back to MmBackward0.\n",
    "while fcns:\n",
    "    new_fcns = []\n",
    "    for fcn_list in fcns:\n",
    "        for fcn in fcn_list:\n",
    "\n",
    "            if fcn is None or fcn in visited:\n",
    "                continue\n",
    "\n",
    "            if type(fcn).__name__ == \"AddMmBackward0\":\n",
    "                # Decompose the function into an Add + Mm, then re-assign its adjacencies.\n",
    "                decomposed_add = decompose_addmmbackward(fcn)\n",
    "                # Assign new Add's in-neighbours to the AddMm's in-neighbours.\n",
    "                in_adj[decomposed_add] = in_adj[fcn]\n",
    "                for in_neighbour in in_adj[fcn]:\n",
    "                    # Replace all out-edges going to the AddMm to point to the new Add.\n",
    "                    old_fcn_idx = out_adj[in_neighbour].index(fcn)\n",
    "                    out_adj[in_neighbour][old_fcn_idx] = decomposed_add\n",
    "                del in_adj[fcn]\n",
    "                fcn = decomposed_add\n",
    "\n",
    "            # Assign adjacencies\n",
    "            if fcn not in out_adj:\n",
    "                out_adj[fcn] = []\n",
    "            for (child, _) in fcn.next_functions:\n",
    "                out_adj[fcn].append(child)\n",
    "                if child not in in_adj:\n",
    "                    in_adj[child] = []\n",
    "                in_adj[child].append(fcn)\n",
    "\n",
    "            visited.add(fcn)\n",
    "\n",
    "            new_fcns.append([ fcn_tup[0] for fcn_tup in fcn.next_functions ])\n",
    "\n",
    "    # Iterate\n",
    "    fcns = new_fcns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1f317cab-d7e8-435f-8ed1-b95674160345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<ViewBackward0 object at 0x17757e100>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758c040>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758c040>: [<NativeLayerNormBackward0 object at 0x177461370>, None], <NativeLayerNormBackward0 object at 0x177461370>: [<AddBackward0 object at 0x177582f70>, <AccumulateGrad object at 0x177582be0>, <AccumulateGrad object at 0x1775827f0>], <AddBackward0 object at 0x177582f70>: [<AddmmBackward0 object at 0x177582a00>, <NativeLayerNormBackward0 object at 0x177582610>], <AccumulateGrad object at 0x177582be0>: [], <AccumulateGrad object at 0x1775827f0>: [], <AddmmBackward0 object at 0x177582a00>: [<AccumulateGrad object at 0x177582820>, <MulBackward0 object at 0x177582430>, <TBackward0 object at 0x177582640>], <NativeLayerNormBackward0 object at 0x177582610>: [<AddBackward0 object at 0x1775822b0>, <AccumulateGrad object at 0x177582460>, <AccumulateGrad object at 0x177582130>], <AccumulateGrad object at 0x177582820>: [], <MulBackward0 object at 0x177582430>: [<GeluBackward0 object at 0x177582250>, <SliceBackward0 object at 0x177582040>], <TBackward0 object at 0x177582640>: [<AccumulateGrad object at 0x1774a0670>], <AddBackward0 object at 0x1775822b0>: [<AddmmBackward0 object at 0x15b042f40>, <NativeLayerNormBackward0 object at 0x15b042ac0>], <AccumulateGrad object at 0x177582460>: [], <AccumulateGrad object at 0x177582130>: [], <GeluBackward0 object at 0x177582250>: [<SliceBackward0 object at 0x177414be0>], <SliceBackward0 object at 0x177582040>: [<SliceBackward0 object at 0x177414700>], <AccumulateGrad object at 0x1774a0670>: [], <AddmmBackward0 object at 0x15b042f40>: [<AccumulateGrad object at 0x1774147c0>, <ViewBackward0 object at 0x177414fa0>, <TBackward0 object at 0x177414820>], <NativeLayerNormBackward0 object at 0x15b042ac0>: [<AddBackward0 object at 0x177414040>, <AccumulateGrad object at 0x1774146d0>, <AccumulateGrad object at 0x1774142e0>], <SliceBackward0 object at 0x177414be0>: [<SliceBackward0 object at 0x1774146a0>], <SliceBackward0 object at 0x177414700>: [<MmBackward0 object at 0x1774142b0>], <AccumulateGrad object at 0x1774147c0>: [], <ViewBackward0 object at 0x177414fa0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758be40>], <TBackward0 object at 0x177414820>: [<AccumulateGrad object at 0x1041ba790>], <AddBackward0 object at 0x177414040>: [<AddmmBackward0 object at 0x1041ba850>, <NativeLayerNormBackward0 object at 0x1041ba430>], <AccumulateGrad object at 0x1774146d0>: [], <AccumulateGrad object at 0x1774142e0>: [], <SliceBackward0 object at 0x1774146a0>: [<MmBackward0 object at 0x1774142b0>], <MmBackward0 object at 0x1774142b0>: [<NativeLayerNormBackward0 object at 0x177582610>, <TBackward0 object at 0x1041ba880>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758be40>: [<ReshapeAliasBackward0 object at 0x1041ba640>, None], <AccumulateGrad object at 0x1041ba790>: [], <AddmmBackward0 object at 0x1041ba850>: [<AccumulateGrad object at 0x1041ba7c0>, <MulBackward0 object at 0x1041badf0>, <TBackward0 object at 0x1041ba520>], <NativeLayerNormBackward0 object at 0x1041ba430>: [<AddBackward0 object at 0x1041ba550>, <AccumulateGrad object at 0x1041ba940>, <AccumulateGrad object at 0x15a76b730>], <TBackward0 object at 0x1041ba880>: [<AccumulateGrad object at 0x15a211940>], <ReshapeAliasBackward0 object at 0x1041ba640>: [<PermuteBackward0 object at 0x15a211550>], <AccumulateGrad object at 0x1041ba7c0>: [], <MulBackward0 object at 0x1041badf0>: [<GeluBackward0 object at 0x15a211520>, <SliceBackward0 object at 0x15a2113d0>], <TBackward0 object at 0x1041ba520>: [<AccumulateGrad object at 0x15a211820>], <AddBackward0 object at 0x1041ba550>: [<AddmmBackward0 object at 0x15a2116d0>, <NativeLayerNormBackward0 object at 0x177438130>], <AccumulateGrad object at 0x1041ba940>: [], <AccumulateGrad object at 0x15a76b730>: [], <AccumulateGrad object at 0x15a211940>: [], <PermuteBackward0 object at 0x15a211550>: [<UnsafeViewBackward0 object at 0x1774388b0>], <GeluBackward0 object at 0x15a211520>: [<SliceBackward0 object at 0x177438190>], <SliceBackward0 object at 0x15a2113d0>: [<SliceBackward0 object at 0x177438220>], <AccumulateGrad object at 0x15a211820>: [], <AddmmBackward0 object at 0x15a2116d0>: [<AccumulateGrad object at 0x177438610>, <ViewBackward0 object at 0x177438f10>, <TBackward0 object at 0x177438670>], <NativeLayerNormBackward0 object at 0x177438130>: [<AddBackward0 object at 0x177438fa0>, <AccumulateGrad object at 0x177438fd0>, <AccumulateGrad object at 0x177438a60>], <UnsafeViewBackward0 object at 0x1774388b0>: [<BmmBackward0 object at 0x177438f70>], <SliceBackward0 object at 0x177438190>: [<SliceBackward0 object at 0x1774381c0>], <SliceBackward0 object at 0x177438220>: [<MmBackward0 object at 0x1774381f0>], <AccumulateGrad object at 0x177438610>: [], <ViewBackward0 object at 0x177438f10>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758bc40>], <TBackward0 object at 0x177438670>: [<AccumulateGrad object at 0x177438d60>], <AddBackward0 object at 0x177438fa0>: [<AddmmBackward0 object at 0x1774386a0>, <NativeLayerNormBackward0 object at 0x177438af0>], <AccumulateGrad object at 0x177438fd0>: [], <AccumulateGrad object at 0x177438a60>: [], <BmmBackward0 object at 0x177438f70>: [<ViewBackward0 object at 0x1774385e0>, <ReshapeAliasBackward0 object at 0x177438f40>], <SliceBackward0 object at 0x1774381c0>: [<MmBackward0 object at 0x1774381f0>], <MmBackward0 object at 0x1774381f0>: [<NativeLayerNormBackward0 object at 0x1041ba430>, <TBackward0 object at 0x1774386d0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758bc40>: [<ReshapeAliasBackward0 object at 0x177438ca0>, None], <AccumulateGrad object at 0x177438d60>: [], <AddmmBackward0 object at 0x1774386a0>: [<AccumulateGrad object at 0x177438c70>, <MulBackward0 object at 0x177438d00>, <TBackward0 object at 0x1774387c0>], <NativeLayerNormBackward0 object at 0x177438af0>: [<AddBackward0 object at 0x177438280>, <AccumulateGrad object at 0x177438250>, <AccumulateGrad object at 0x1774382e0>], <ViewBackward0 object at 0x1774385e0>: [<ExpandBackward0 object at 0x177438b50>], <ReshapeAliasBackward0 object at 0x177438f40>: [<ExpandBackward0 object at 0x177438910>], <TBackward0 object at 0x1774386d0>: [<AccumulateGrad object at 0x177438a30>], <ReshapeAliasBackward0 object at 0x177438ca0>: [<PermuteBackward0 object at 0x177438d90>], <AccumulateGrad object at 0x177438c70>: [], <MulBackward0 object at 0x177438d00>: [<GeluBackward0 object at 0x1774389d0>, <SliceBackward0 object at 0x177438550>], <TBackward0 object at 0x1774387c0>: [<AccumulateGrad object at 0x177438a00>], <AddBackward0 object at 0x177438280>: [<AddmmBackward0 object at 0x177438850>, <NativeLayerNormBackward0 object at 0x177438e20>], <AccumulateGrad object at 0x177438250>: [], <AccumulateGrad object at 0x1774382e0>: [], <ExpandBackward0 object at 0x177438b50>: [<SoftmaxBackward0 object at 0x177438e50>], <ExpandBackward0 object at 0x177438910>: [<PermuteBackward0 object at 0x177438d30>], <AccumulateGrad object at 0x177438a30>: [], <PermuteBackward0 object at 0x177438d90>: [<UnsafeViewBackward0 object at 0x177438df0>], <GeluBackward0 object at 0x1774389d0>: [<SliceBackward0 object at 0x177438ee0>], <SliceBackward0 object at 0x177438550>: [<SliceBackward0 object at 0x177438cd0>], <AccumulateGrad object at 0x177438a00>: [], <AddmmBackward0 object at 0x177438850>: [<AccumulateGrad object at 0x177438160>, <ViewBackward0 object at 0x1774380d0>, <TBackward0 object at 0x177438100>], <NativeLayerNormBackward0 object at 0x177438e20>: [<AddBackward0 object at 0x177438040>, <AccumulateGrad object at 0x1774380a0>, <AccumulateGrad object at 0x1774385b0>], <SoftmaxBackward0 object at 0x177438e50>: [<AddBackward0 object at 0x177438070>], <PermuteBackward0 object at 0x177438d30>: [<SliceBackward0 object at 0x177438640>], <UnsafeViewBackward0 object at 0x177438df0>: [<BmmBackward0 object at 0x1774382b0>], <SliceBackward0 object at 0x177438ee0>: [<SliceBackward0 object at 0x177438340>], <SliceBackward0 object at 0x177438cd0>: [<MmBackward0 object at 0x177438310>], <AccumulateGrad object at 0x177438160>: [], <ViewBackward0 object at 0x1774380d0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758ba40>], <TBackward0 object at 0x177438100>: [<AccumulateGrad object at 0x1774383a0>], <AddBackward0 object at 0x177438040>: [<AddmmBackward0 object at 0x177438370>, <NativeLayerNormBackward0 object at 0x177438430>], <AccumulateGrad object at 0x1774380a0>: [], <AccumulateGrad object at 0x1774385b0>: [], <AddBackward0 object at 0x177438070>: [<DivBackward0 object at 0x1774383d0>, None], <SliceBackward0 object at 0x177438640>: [<SliceBackward0 object at 0x177438490>], <BmmBackward0 object at 0x1774382b0>: [<ViewBackward0 object at 0x177438460>, <ReshapeAliasBackward0 object at 0x1774384f0>], <SliceBackward0 object at 0x177438340>: [<MmBackward0 object at 0x177438310>], <MmBackward0 object at 0x177438310>: [<NativeLayerNormBackward0 object at 0x177438af0>, <TBackward0 object at 0x1774384c0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758ba40>: [<ReshapeAliasBackward0 object at 0x177438400>, None], <AccumulateGrad object at 0x1774383a0>: [], <AddmmBackward0 object at 0x177438370>: [<AccumulateGrad object at 0x177438700>, <MulBackward0 object at 0x177438970>, <TBackward0 object at 0x177438730>], <NativeLayerNormBackward0 object at 0x177438430>: [<AddBackward0 object at 0x177438be0>, <AccumulateGrad object at 0x177438c10>, <AccumulateGrad object at 0x177438580>], <DivBackward0 object at 0x1774383d0>: [<UnsafeViewBackward0 object at 0x177438760>, None], <SliceBackward0 object at 0x177438490>: [<SelectBackward0 object at 0x177438820>], <ViewBackward0 object at 0x177438460>: [<ExpandBackward0 object at 0x177438a90>], <ReshapeAliasBackward0 object at 0x1774384f0>: [<ExpandBackward0 object at 0x1774387f0>], <TBackward0 object at 0x1774384c0>: [<AccumulateGrad object at 0x177438880>], <ReshapeAliasBackward0 object at 0x177438400>: [<PermuteBackward0 object at 0x177438bb0>], <AccumulateGrad object at 0x177438700>: [], <MulBackward0 object at 0x177438970>: [<GeluBackward0 object at 0x177438b80>, <SliceBackward0 object at 0x1774388e0>], <TBackward0 object at 0x177438730>: [<AccumulateGrad object at 0x177438790>], <AddBackward0 object at 0x177438be0>: [<AddmmBackward0 object at 0x177438520>, <NativeLayerNormBackward0 object at 0x177449790>], <AccumulateGrad object at 0x177438c10>: [], <AccumulateGrad object at 0x177438580>: [], <UnsafeViewBackward0 object at 0x177438760>: [<BmmBackward0 object at 0x177449af0>], <SelectBackward0 object at 0x177438820>: [<SliceBackward0 object at 0x177449820>], <ExpandBackward0 object at 0x177438a90>: [<SoftmaxBackward0 object at 0x177449a60>], <ExpandBackward0 object at 0x1774387f0>: [<PermuteBackward0 object at 0x1774498b0>], <AccumulateGrad object at 0x177438880>: [], <PermuteBackward0 object at 0x177438bb0>: [<UnsafeViewBackward0 object at 0x177449e80>], <GeluBackward0 object at 0x177438b80>: [<SliceBackward0 object at 0x177449760>], <SliceBackward0 object at 0x1774388e0>: [<SliceBackward0 object at 0x1774497c0>], <AccumulateGrad object at 0x177438790>: [], <AddmmBackward0 object at 0x177438520>: [<AccumulateGrad object at 0x177449190>, <ViewBackward0 object at 0x1774497f0>, <TBackward0 object at 0x177449040>], <NativeLayerNormBackward0 object at 0x177449790>: [<AddBackward0 object at 0x1774491c0>, <AccumulateGrad object at 0x1774490a0>, <AccumulateGrad object at 0x177449070>], <BmmBackward0 object at 0x177449af0>: [<ReshapeAliasBackward0 object at 0x177449100>, <ReshapeAliasBackward0 object at 0x1774490d0>], <SliceBackward0 object at 0x177449820>: [<SliceBackward0 object at 0x177449160>], <SoftmaxBackward0 object at 0x177449a60>: [<AddBackward0 object at 0x177449130>], <PermuteBackward0 object at 0x1774498b0>: [<SliceBackward0 object at 0x177449220>], <UnsafeViewBackward0 object at 0x177449e80>: [<BmmBackward0 object at 0x1774491f0>], <SliceBackward0 object at 0x177449760>: [<SliceBackward0 object at 0x177449280>], <SliceBackward0 object at 0x1774497c0>: [<MmBackward0 object at 0x177449250>], <AccumulateGrad object at 0x177449190>: [], <ViewBackward0 object at 0x1774497f0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b840>], <TBackward0 object at 0x177449040>: [<AccumulateGrad object at 0x1774492e0>], <AddBackward0 object at 0x1774491c0>: [<AddmmBackward0 object at 0x1774492b0>, <NativeLayerNormBackward0 object at 0x177449340>], <AccumulateGrad object at 0x1774490a0>: [], <AccumulateGrad object at 0x177449070>: [], <ReshapeAliasBackward0 object at 0x177449100>: [<ExpandBackward0 object at 0x177449310>], <ReshapeAliasBackward0 object at 0x1774490d0>: [<ExpandBackward0 object at 0x177449700>], <SliceBackward0 object at 0x177449160>: [<ViewBackward0 object at 0x177449370>], <AddBackward0 object at 0x177449130>: [<DivBackward0 object at 0x1774493a0>, None], <SliceBackward0 object at 0x177449220>: [<SliceBackward0 object at 0x177449730>], <BmmBackward0 object at 0x1774491f0>: [<ViewBackward0 object at 0x177449400>, <ReshapeAliasBackward0 object at 0x1774493d0>], <SliceBackward0 object at 0x177449280>: [<MmBackward0 object at 0x177449250>], <MmBackward0 object at 0x177449250>: [<NativeLayerNormBackward0 object at 0x177438430>, <TBackward0 object at 0x177449460>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b840>: [<ReshapeAliasBackward0 object at 0x177449430>, None], <AccumulateGrad object at 0x1774492e0>: [], <AddmmBackward0 object at 0x1774492b0>: [<AccumulateGrad object at 0x1774494c0>, <MulBackward0 object at 0x177449490>, <TBackward0 object at 0x177449520>], <NativeLayerNormBackward0 object at 0x177449340>: [<AddBackward0 object at 0x1774494f0>, <AccumulateGrad object at 0x177449580>, <AccumulateGrad object at 0x177449550>], <ExpandBackward0 object at 0x177449310>: [<PermuteBackward0 object at 0x1774495e0>], <ExpandBackward0 object at 0x177449700>: [<PermuteBackward0 object at 0x1774495b0>], <ViewBackward0 object at 0x177449370>: [<ViewBackward0 object at 0x177449640>], <DivBackward0 object at 0x1774493a0>: [<UnsafeViewBackward0 object at 0x177449610>, None], <SliceBackward0 object at 0x177449730>: [<SelectBackward0 object at 0x1774496d0>], <ViewBackward0 object at 0x177449400>: [<ExpandBackward0 object at 0x177449670>], <ReshapeAliasBackward0 object at 0x1774493d0>: [<ExpandBackward0 object at 0x1774496a0>], <TBackward0 object at 0x177449460>: [<AccumulateGrad object at 0x1774333d0>], <ReshapeAliasBackward0 object at 0x177449430>: [<PermuteBackward0 object at 0x1774338e0>], <AccumulateGrad object at 0x1774494c0>: [], <MulBackward0 object at 0x177449490>: [<GeluBackward0 object at 0x177433df0>, <SliceBackward0 object at 0x1774333a0>], <TBackward0 object at 0x177449520>: [<AccumulateGrad object at 0x177433f70>], <AddBackward0 object at 0x1774494f0>: [<AddmmBackward0 object at 0x177433b50>, <NativeLayerNormBackward0 object at 0x177433c70>], <AccumulateGrad object at 0x177449580>: [], <AccumulateGrad object at 0x177449550>: [], <PermuteBackward0 object at 0x1774495e0>: [<SliceBackward0 object at 0x177433d00>], <PermuteBackward0 object at 0x1774495b0>: [<SliceBackward0 object at 0x177433bb0>], <ViewBackward0 object at 0x177449640>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758bd40>], <UnsafeViewBackward0 object at 0x177449610>: [<BmmBackward0 object at 0x177433be0>], <SelectBackward0 object at 0x1774496d0>: [<SliceBackward0 object at 0x177433b80>], <ExpandBackward0 object at 0x177449670>: [<SoftmaxBackward0 object at 0x177433c10>], <ExpandBackward0 object at 0x1774496a0>: [<PermuteBackward0 object at 0x1774337f0>], <AccumulateGrad object at 0x1774333d0>: [], <PermuteBackward0 object at 0x1774338e0>: [<UnsafeViewBackward0 object at 0x177433880>], <GeluBackward0 object at 0x177433df0>: [<SliceBackward0 object at 0x177433700>], <SliceBackward0 object at 0x1774333a0>: [<SliceBackward0 object at 0x177433730>], <AccumulateGrad object at 0x177433f70>: [], <AddmmBackward0 object at 0x177433b50>: [<AccumulateGrad object at 0x177433ac0>, <ViewBackward0 object at 0x177433af0>, <TBackward0 object at 0x177433910>], <NativeLayerNormBackward0 object at 0x177433c70>: [<AddBackward0 object at 0x177433940>, <AccumulateGrad object at 0x177433a60>, <AccumulateGrad object at 0x177433a90>], <SliceBackward0 object at 0x177433d00>: [<SliceBackward0 object at 0x177433a00>], <SliceBackward0 object at 0x177433bb0>: [<SliceBackward0 object at 0x177433a30>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758bd40>: [<AddmmBackward0 object at 0x1774339a0>, None], <BmmBackward0 object at 0x177433be0>: [<ReshapeAliasBackward0 object at 0x1774339d0>, <ReshapeAliasBackward0 object at 0x177433430>], <SliceBackward0 object at 0x177433b80>: [<SliceBackward0 object at 0x177433d60>], <SoftmaxBackward0 object at 0x177433c10>: [<AddBackward0 object at 0x177433340>], <PermuteBackward0 object at 0x1774337f0>: [<SliceBackward0 object at 0x177433370>], <UnsafeViewBackward0 object at 0x177433880>: [<BmmBackward0 object at 0x1774332e0>], <SliceBackward0 object at 0x177433700>: [<SliceBackward0 object at 0x177433310>], <SliceBackward0 object at 0x177433730>: [<MmBackward0 object at 0x1774330d0>], <AccumulateGrad object at 0x177433ac0>: [], <ViewBackward0 object at 0x177433af0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b640>], <TBackward0 object at 0x177433910>: [<AccumulateGrad object at 0x177433100>], <AddBackward0 object at 0x177433940>: [<AddmmBackward0 object at 0x177433040>, <NativeLayerNormBackward0 object at 0x177433070>], <AccumulateGrad object at 0x177433a60>: [], <AccumulateGrad object at 0x177433a90>: [], <SliceBackward0 object at 0x177433a00>: [<SelectBackward0 object at 0x1774330a0>], <SliceBackward0 object at 0x177433a30>: [<SelectBackward0 object at 0x177433280>], <AddmmBackward0 object at 0x1774339a0>: [<AccumulateGrad object at 0x1774332b0>, <NativeLayerNormBackward0 object at 0x15b042ac0>, <TBackward0 object at 0x177433130>], <ReshapeAliasBackward0 object at 0x1774339d0>: [<ExpandBackward0 object at 0x177433160>], <ReshapeAliasBackward0 object at 0x177433430>: [<ExpandBackward0 object at 0x177433190>], <SliceBackward0 object at 0x177433d60>: [<ViewBackward0 object at 0x1774331c0>], <AddBackward0 object at 0x177433340>: [<DivBackward0 object at 0x1774331f0>, None], <SliceBackward0 object at 0x177433370>: [<SliceBackward0 object at 0x177433220>], <BmmBackward0 object at 0x1774332e0>: [<ViewBackward0 object at 0x177433250>, <ReshapeAliasBackward0 object at 0x17740d1f0>], <SliceBackward0 object at 0x177433310>: [<MmBackward0 object at 0x1774330d0>], <MmBackward0 object at 0x1774330d0>: [<NativeLayerNormBackward0 object at 0x177449340>, <TBackward0 object at 0x17740d220>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b640>: [<ReshapeAliasBackward0 object at 0x17740d2e0>, None], <AccumulateGrad object at 0x177433100>: [], <AddmmBackward0 object at 0x177433040>: [<AccumulateGrad object at 0x17740d550>, <MulBackward0 object at 0x17740df40>, <TBackward0 object at 0x17740deb0>], <NativeLayerNormBackward0 object at 0x177433070>: [<AddBackward0 object at 0x17740d0d0>, <AccumulateGrad object at 0x17740df70>, <AccumulateGrad object at 0x17740d3a0>], <SelectBackward0 object at 0x1774330a0>: [<SliceBackward0 object at 0x17740d880>], <SelectBackward0 object at 0x177433280>: [<SliceBackward0 object at 0x17740de50>], <AccumulateGrad object at 0x1774332b0>: [], <TBackward0 object at 0x177433130>: [<AccumulateGrad object at 0x17740d8b0>], <ExpandBackward0 object at 0x177433160>: [<PermuteBackward0 object at 0x17740d6a0>], <ExpandBackward0 object at 0x177433190>: [<PermuteBackward0 object at 0x17740d6d0>], <ViewBackward0 object at 0x1774331c0>: [<ViewBackward0 object at 0x17740d280>], <DivBackward0 object at 0x1774331f0>: [<UnsafeViewBackward0 object at 0x17740d3d0>, None], <SliceBackward0 object at 0x177433220>: [<SelectBackward0 object at 0x17740d400>], <ViewBackward0 object at 0x177433250>: [<ExpandBackward0 object at 0x17740d430>], <ReshapeAliasBackward0 object at 0x17740d1f0>: [<ExpandBackward0 object at 0x17740d460>], <TBackward0 object at 0x17740d220>: [<AccumulateGrad object at 0x17740d490>], <ReshapeAliasBackward0 object at 0x17740d2e0>: [<PermuteBackward0 object at 0x17740d4c0>], <AccumulateGrad object at 0x17740d550>: [], <MulBackward0 object at 0x17740df40>: [<GeluBackward0 object at 0x17740d4f0>, <SliceBackward0 object at 0x17740d520>], <TBackward0 object at 0x17740deb0>: [<AccumulateGrad object at 0x17740d580>], <AddBackward0 object at 0x17740d0d0>: [<AddmmBackward0 object at 0x17740d5b0>, <NativeLayerNormBackward0 object at 0x17740d5e0>], <AccumulateGrad object at 0x17740df70>: [], <AccumulateGrad object at 0x17740d3a0>: [], <SliceBackward0 object at 0x17740d880>: [<SliceBackward0 object at 0x17740d610>], <SliceBackward0 object at 0x17740de50>: [<SliceBackward0 object at 0x17740d640>], <AccumulateGrad object at 0x17740d8b0>: [], <PermuteBackward0 object at 0x17740d6a0>: [<SliceBackward0 object at 0x17740d670>], <PermuteBackward0 object at 0x17740d6d0>: [<SliceBackward0 object at 0x17740d7f0>], <ViewBackward0 object at 0x17740d280>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758bb40>], <UnsafeViewBackward0 object at 0x17740d3d0>: [<BmmBackward0 object at 0x17740d820>], <SelectBackward0 object at 0x17740d400>: [<SliceBackward0 object at 0x17740d700>], <ExpandBackward0 object at 0x17740d430>: [<SoftmaxBackward0 object at 0x17740d730>], <ExpandBackward0 object at 0x17740d460>: [<PermuteBackward0 object at 0x17740d760>], <AccumulateGrad object at 0x17740d490>: [], <PermuteBackward0 object at 0x17740d4c0>: [<UnsafeViewBackward0 object at 0x17740d790>], <GeluBackward0 object at 0x17740d4f0>: [<SliceBackward0 object at 0x17740d7c0>], <SliceBackward0 object at 0x17740d520>: [<SliceBackward0 object at 0x17740db50>], <AccumulateGrad object at 0x17740d580>: [], <AddmmBackward0 object at 0x17740d5b0>: [<AccumulateGrad object at 0x17740db80>, <ViewBackward0 object at 0x17740d850>, <TBackward0 object at 0x17740d8e0>], <NativeLayerNormBackward0 object at 0x17740d5e0>: [<AddBackward0 object at 0x17740d910>, <AccumulateGrad object at 0x17740d940>, <AccumulateGrad object at 0x17740d970>], <SliceBackward0 object at 0x17740d610>: [<ViewBackward0 object at 0x177449370>], <SliceBackward0 object at 0x17740d640>: [<ViewBackward0 object at 0x177449370>], <SliceBackward0 object at 0x17740d670>: [<SliceBackward0 object at 0x17740d9a0>], <SliceBackward0 object at 0x17740d7f0>: [<SliceBackward0 object at 0x17740d9d0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758bb40>: [<AddmmBackward0 object at 0x17740da00>, None], <BmmBackward0 object at 0x17740d820>: [<ReshapeAliasBackward0 object at 0x17740da30>, <ReshapeAliasBackward0 object at 0x17740da60>], <SliceBackward0 object at 0x17740d700>: [<SliceBackward0 object at 0x17740da90>], <SoftmaxBackward0 object at 0x17740d730>: [<AddBackward0 object at 0x17740dac0>], <PermuteBackward0 object at 0x17740d760>: [<SliceBackward0 object at 0x17740daf0>], <UnsafeViewBackward0 object at 0x17740d790>: [<BmmBackward0 object at 0x17740db20>], <SliceBackward0 object at 0x17740d7c0>: [<SliceBackward0 object at 0x17740dd00>], <SliceBackward0 object at 0x17740db50>: [<MmBackward0 object at 0x17740dd30>], <AccumulateGrad object at 0x17740db80>: [], <ViewBackward0 object at 0x17740d850>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b440>], <TBackward0 object at 0x17740d8e0>: [<AccumulateGrad object at 0x17740dbb0>], <AddBackward0 object at 0x17740d910>: [<AddmmBackward0 object at 0x17740dbe0>, <NativeLayerNormBackward0 object at 0x17740dc10>], <AccumulateGrad object at 0x17740d940>: [], <AccumulateGrad object at 0x17740d970>: [], <SliceBackward0 object at 0x17740d9a0>: [<SelectBackward0 object at 0x17740dc40>], <SliceBackward0 object at 0x17740d9d0>: [<SelectBackward0 object at 0x17740dc70>], <AddmmBackward0 object at 0x17740da00>: [<AccumulateGrad object at 0x17740dca0>, <NativeLayerNormBackward0 object at 0x177438130>, <TBackward0 object at 0x17740dcd0>], <ReshapeAliasBackward0 object at 0x17740da30>: [<ExpandBackward0 object at 0x17740dd60>], <ReshapeAliasBackward0 object at 0x17740da60>: [<ExpandBackward0 object at 0x17740dd90>], <SliceBackward0 object at 0x17740da90>: [<ViewBackward0 object at 0x17740ddc0>], <AddBackward0 object at 0x17740dac0>: [<DivBackward0 object at 0x17740ddf0>, None], <SliceBackward0 object at 0x17740daf0>: [<SliceBackward0 object at 0x17740de20>], <BmmBackward0 object at 0x17740db20>: [<ViewBackward0 object at 0x17740d250>, <ReshapeAliasBackward0 object at 0x17740d1c0>], <SliceBackward0 object at 0x17740dd00>: [<MmBackward0 object at 0x17740dd30>], <MmBackward0 object at 0x17740dd30>: [<NativeLayerNormBackward0 object at 0x177433070>, <TBackward0 object at 0x17740dfd0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b440>: [<ReshapeAliasBackward0 object at 0x17759e040>, None], <AccumulateGrad object at 0x17740dbb0>: [], <AddmmBackward0 object at 0x17740dbe0>: [<AccumulateGrad object at 0x17759e070>, <MulBackward0 object at 0x17759e0a0>, <TBackward0 object at 0x17759e0d0>], <NativeLayerNormBackward0 object at 0x17740dc10>: [<AddBackward0 object at 0x17759e100>, <AccumulateGrad object at 0x17759e130>, <AccumulateGrad object at 0x17759e160>], <SelectBackward0 object at 0x17740dc40>: [<SliceBackward0 object at 0x17759e190>], <SelectBackward0 object at 0x17740dc70>: [<SliceBackward0 object at 0x17759e1c0>], <AccumulateGrad object at 0x17740dca0>: [], <TBackward0 object at 0x17740dcd0>: [<AccumulateGrad object at 0x17759e1f0>], <ExpandBackward0 object at 0x17740dd60>: [<PermuteBackward0 object at 0x17759e220>], <ExpandBackward0 object at 0x17740dd90>: [<PermuteBackward0 object at 0x17759e250>], <ViewBackward0 object at 0x17740ddc0>: [<ViewBackward0 object at 0x17759e280>], <DivBackward0 object at 0x17740ddf0>: [<UnsafeViewBackward0 object at 0x17759e2b0>, None], <SliceBackward0 object at 0x17740de20>: [<SelectBackward0 object at 0x17759e2e0>], <ViewBackward0 object at 0x17740d250>: [<ExpandBackward0 object at 0x17759e310>], <ReshapeAliasBackward0 object at 0x17740d1c0>: [<ExpandBackward0 object at 0x17759e340>], <TBackward0 object at 0x17740dfd0>: [<AccumulateGrad object at 0x17759e370>], <ReshapeAliasBackward0 object at 0x17759e040>: [<PermuteBackward0 object at 0x17759e3a0>], <AccumulateGrad object at 0x17759e070>: [], <MulBackward0 object at 0x17759e0a0>: [<GeluBackward0 object at 0x17759e3d0>, <SliceBackward0 object at 0x17759e400>], <TBackward0 object at 0x17759e0d0>: [<AccumulateGrad object at 0x17759e430>], <AddBackward0 object at 0x17759e100>: [<AddmmBackward0 object at 0x17759e460>, <NativeLayerNormBackward0 object at 0x17759e490>], <AccumulateGrad object at 0x17759e130>: [], <AccumulateGrad object at 0x17759e160>: [], <SliceBackward0 object at 0x17759e190>: [<SliceBackward0 object at 0x17759e4c0>], <SliceBackward0 object at 0x17759e1c0>: [<SliceBackward0 object at 0x17759e4f0>], <AccumulateGrad object at 0x17759e1f0>: [], <PermuteBackward0 object at 0x17759e220>: [<SliceBackward0 object at 0x17759e520>], <PermuteBackward0 object at 0x17759e250>: [<SliceBackward0 object at 0x17759e550>], <ViewBackward0 object at 0x17759e280>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b940>], <UnsafeViewBackward0 object at 0x17759e2b0>: [<BmmBackward0 object at 0x17759e580>], <SelectBackward0 object at 0x17759e2e0>: [<SliceBackward0 object at 0x17759e5b0>], <ExpandBackward0 object at 0x17759e310>: [<SoftmaxBackward0 object at 0x17759e5e0>], <ExpandBackward0 object at 0x17759e340>: [<PermuteBackward0 object at 0x17759e610>], <AccumulateGrad object at 0x17759e370>: [], <PermuteBackward0 object at 0x17759e3a0>: [<UnsafeViewBackward0 object at 0x17759e640>], <GeluBackward0 object at 0x17759e3d0>: [<SliceBackward0 object at 0x17759e670>], <SliceBackward0 object at 0x17759e400>: [<SliceBackward0 object at 0x17759e6a0>], <AccumulateGrad object at 0x17759e430>: [], <AddmmBackward0 object at 0x17759e460>: [<AccumulateGrad object at 0x17759e6d0>, <ViewBackward0 object at 0x17759e700>, <TBackward0 object at 0x17759e730>], <NativeLayerNormBackward0 object at 0x17759e490>: [<AddBackward0 object at 0x17759e760>, <AccumulateGrad object at 0x17759e790>, <AccumulateGrad object at 0x17759e7c0>], <SliceBackward0 object at 0x17759e4c0>: [<ViewBackward0 object at 0x1774331c0>], <SliceBackward0 object at 0x17759e4f0>: [<ViewBackward0 object at 0x1774331c0>], <SliceBackward0 object at 0x17759e520>: [<SliceBackward0 object at 0x17759e7f0>], <SliceBackward0 object at 0x17759e550>: [<SliceBackward0 object at 0x17759e820>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b940>: [<AddmmBackward0 object at 0x17759e850>, None], <BmmBackward0 object at 0x17759e580>: [<ReshapeAliasBackward0 object at 0x17759e880>, <ReshapeAliasBackward0 object at 0x17759e8b0>], <SliceBackward0 object at 0x17759e5b0>: [<SliceBackward0 object at 0x17759e8e0>], <SoftmaxBackward0 object at 0x17759e5e0>: [<AddBackward0 object at 0x17759e910>], <PermuteBackward0 object at 0x17759e610>: [<SliceBackward0 object at 0x17759e940>], <UnsafeViewBackward0 object at 0x17759e640>: [<BmmBackward0 object at 0x17759e970>], <SliceBackward0 object at 0x17759e670>: [<SliceBackward0 object at 0x17759e9a0>], <SliceBackward0 object at 0x17759e6a0>: [<MmBackward0 object at 0x17759e9d0>], <AccumulateGrad object at 0x17759e6d0>: [], <ViewBackward0 object at 0x17759e700>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b240>], <TBackward0 object at 0x17759e730>: [<AccumulateGrad object at 0x17759ea00>], <AddBackward0 object at 0x17759e760>: [<AddmmBackward0 object at 0x17759ea30>, <NativeLayerNormBackward0 object at 0x17759ea60>], <AccumulateGrad object at 0x17759e790>: [], <AccumulateGrad object at 0x17759e7c0>: [], <SliceBackward0 object at 0x17759e7f0>: [<SelectBackward0 object at 0x17759ea90>], <SliceBackward0 object at 0x17759e820>: [<SelectBackward0 object at 0x17759eac0>], <AddmmBackward0 object at 0x17759e850>: [<AccumulateGrad object at 0x17759eaf0>, <NativeLayerNormBackward0 object at 0x177438e20>, <TBackward0 object at 0x17759eb20>], <ReshapeAliasBackward0 object at 0x17759e880>: [<ExpandBackward0 object at 0x17759eb50>], <ReshapeAliasBackward0 object at 0x17759e8b0>: [<ExpandBackward0 object at 0x17759eb80>], <SliceBackward0 object at 0x17759e8e0>: [<ViewBackward0 object at 0x17759ebb0>], <AddBackward0 object at 0x17759e910>: [<DivBackward0 object at 0x17759ebe0>, None], <SliceBackward0 object at 0x17759e940>: [<SliceBackward0 object at 0x17759ec10>], <BmmBackward0 object at 0x17759e970>: [<ViewBackward0 object at 0x17759ec40>, <ReshapeAliasBackward0 object at 0x17759ec70>], <SliceBackward0 object at 0x17759e9a0>: [<MmBackward0 object at 0x17759e9d0>], <MmBackward0 object at 0x17759e9d0>: [<NativeLayerNormBackward0 object at 0x17740dc10>, <TBackward0 object at 0x17759eca0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b240>: [<ReshapeAliasBackward0 object at 0x17759ecd0>, None], <AccumulateGrad object at 0x17759ea00>: [], <AddmmBackward0 object at 0x17759ea30>: [<AccumulateGrad object at 0x17759ed00>, <MulBackward0 object at 0x17759ed30>, <TBackward0 object at 0x17759ed60>], <NativeLayerNormBackward0 object at 0x17759ea60>: [<AddBackward0 object at 0x17759ed90>, <AccumulateGrad object at 0x17759edc0>, <AccumulateGrad object at 0x17759edf0>], <SelectBackward0 object at 0x17759ea90>: [<SliceBackward0 object at 0x17759ee20>], <SelectBackward0 object at 0x17759eac0>: [<SliceBackward0 object at 0x17759ee50>], <AccumulateGrad object at 0x17759eaf0>: [], <TBackward0 object at 0x17759eb20>: [<AccumulateGrad object at 0x17759ee80>], <ExpandBackward0 object at 0x17759eb50>: [<PermuteBackward0 object at 0x17759eeb0>], <ExpandBackward0 object at 0x17759eb80>: [<PermuteBackward0 object at 0x17759eee0>], <ViewBackward0 object at 0x17759ebb0>: [<ViewBackward0 object at 0x17759ef10>], <DivBackward0 object at 0x17759ebe0>: [<UnsafeViewBackward0 object at 0x17759ef40>, None], <SliceBackward0 object at 0x17759ec10>: [<SelectBackward0 object at 0x17759ef70>], <ViewBackward0 object at 0x17759ec40>: [<ExpandBackward0 object at 0x17759efa0>], <ReshapeAliasBackward0 object at 0x17759ec70>: [<ExpandBackward0 object at 0x17759efd0>], <TBackward0 object at 0x17759eca0>: [<AccumulateGrad object at 0x1775a3040>], <ReshapeAliasBackward0 object at 0x17759ecd0>: [<PermuteBackward0 object at 0x1775a3070>], <AccumulateGrad object at 0x17759ed00>: [], <MulBackward0 object at 0x17759ed30>: [<GeluBackward0 object at 0x1775a30a0>, <SliceBackward0 object at 0x1775a30d0>], <TBackward0 object at 0x17759ed60>: [<AccumulateGrad object at 0x1775a3100>], <AddBackward0 object at 0x17759ed90>: [<AddmmBackward0 object at 0x1775a3130>, <NativeLayerNormBackward0 object at 0x1775a3160>], <AccumulateGrad object at 0x17759edc0>: [], <AccumulateGrad object at 0x17759edf0>: [], <SliceBackward0 object at 0x17759ee20>: [<SliceBackward0 object at 0x1775a3190>], <SliceBackward0 object at 0x17759ee50>: [<SliceBackward0 object at 0x1775a31c0>], <AccumulateGrad object at 0x17759ee80>: [], <PermuteBackward0 object at 0x17759eeb0>: [<SliceBackward0 object at 0x1775a31f0>], <PermuteBackward0 object at 0x17759eee0>: [<SliceBackward0 object at 0x1775a3220>], <ViewBackward0 object at 0x17759ef10>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b740>], <UnsafeViewBackward0 object at 0x17759ef40>: [<BmmBackward0 object at 0x1775a3250>], <SelectBackward0 object at 0x17759ef70>: [<SliceBackward0 object at 0x1775a3280>], <ExpandBackward0 object at 0x17759efa0>: [<SoftmaxBackward0 object at 0x1775a32b0>], <ExpandBackward0 object at 0x17759efd0>: [<PermuteBackward0 object at 0x1775a32e0>], <AccumulateGrad object at 0x1775a3040>: [], <PermuteBackward0 object at 0x1775a3070>: [<UnsafeViewBackward0 object at 0x1775a3310>], <GeluBackward0 object at 0x1775a30a0>: [<SliceBackward0 object at 0x1775a3340>], <SliceBackward0 object at 0x1775a30d0>: [<SliceBackward0 object at 0x1775a3370>], <AccumulateGrad object at 0x1775a3100>: [], <AddmmBackward0 object at 0x1775a3130>: [<AccumulateGrad object at 0x1775a33a0>, <ViewBackward0 object at 0x1775a33d0>, <TBackward0 object at 0x1775a3400>], <NativeLayerNormBackward0 object at 0x1775a3160>: [<AddBackward0 object at 0x1775a3430>, <AccumulateGrad object at 0x1775a3460>, <AccumulateGrad object at 0x1775a3490>], <SliceBackward0 object at 0x1775a3190>: [<ViewBackward0 object at 0x17740ddc0>], <SliceBackward0 object at 0x1775a31c0>: [<ViewBackward0 object at 0x17740ddc0>], <SliceBackward0 object at 0x1775a31f0>: [<SliceBackward0 object at 0x1775a34c0>], <SliceBackward0 object at 0x1775a3220>: [<SliceBackward0 object at 0x1775a34f0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b740>: [<AddmmBackward0 object at 0x1775a3520>, None], <BmmBackward0 object at 0x1775a3250>: [<ReshapeAliasBackward0 object at 0x1775a3550>, <ReshapeAliasBackward0 object at 0x1775a3580>], <SliceBackward0 object at 0x1775a3280>: [<SliceBackward0 object at 0x1775a35b0>], <SoftmaxBackward0 object at 0x1775a32b0>: [<AddBackward0 object at 0x1775a35e0>], <PermuteBackward0 object at 0x1775a32e0>: [<SliceBackward0 object at 0x1775a3610>], <UnsafeViewBackward0 object at 0x1775a3310>: [<BmmBackward0 object at 0x1775a3640>], <SliceBackward0 object at 0x1775a3340>: [<SliceBackward0 object at 0x1775a3670>], <SliceBackward0 object at 0x1775a3370>: [<MmBackward0 object at 0x1775a36a0>], <AccumulateGrad object at 0x1775a33a0>: [], <ViewBackward0 object at 0x1775a33d0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x17758b040>], <TBackward0 object at 0x1775a3400>: [<AccumulateGrad object at 0x1775a36d0>], <AddBackward0 object at 0x1775a3430>: [<AddmmBackward0 object at 0x1775a3700>, <NativeLayerNormBackward0 object at 0x1775a3730>], <AccumulateGrad object at 0x1775a3460>: [], <AccumulateGrad object at 0x1775a3490>: [], <SliceBackward0 object at 0x1775a34c0>: [<SelectBackward0 object at 0x1775a3760>], <SliceBackward0 object at 0x1775a34f0>: [<SelectBackward0 object at 0x1775a3790>], <AddmmBackward0 object at 0x1775a3520>: [<AccumulateGrad object at 0x1775a37c0>, <NativeLayerNormBackward0 object at 0x177449790>, <TBackward0 object at 0x1775a37f0>], <ReshapeAliasBackward0 object at 0x1775a3550>: [<ExpandBackward0 object at 0x1775a3820>], <ReshapeAliasBackward0 object at 0x1775a3580>: [<ExpandBackward0 object at 0x1775a3850>], <SliceBackward0 object at 0x1775a35b0>: [<ViewBackward0 object at 0x1775a3880>], <AddBackward0 object at 0x1775a35e0>: [<DivBackward0 object at 0x1775a38b0>, None], <SliceBackward0 object at 0x1775a3610>: [<SliceBackward0 object at 0x1775a38e0>], <BmmBackward0 object at 0x1775a3640>: [<ViewBackward0 object at 0x1775a3910>, <ReshapeAliasBackward0 object at 0x1775a3940>], <SliceBackward0 object at 0x1775a3670>: [<MmBackward0 object at 0x1775a36a0>], <MmBackward0 object at 0x1775a36a0>: [<NativeLayerNormBackward0 object at 0x17759ea60>, <TBackward0 object at 0x1775a3970>], <torch.autograd.function.IndexFirstAxisBackward object at 0x17758b040>: [<ReshapeAliasBackward0 object at 0x1775a39a0>, None], <AccumulateGrad object at 0x1775a36d0>: [], <AddmmBackward0 object at 0x1775a3700>: [<AccumulateGrad object at 0x1775a39d0>, <MulBackward0 object at 0x1775a3a00>, <TBackward0 object at 0x1775a3a30>], <NativeLayerNormBackward0 object at 0x1775a3730>: [<AddBackward0 object at 0x1775a3a60>, <AccumulateGrad object at 0x1775a3a90>, <AccumulateGrad object at 0x1775a3ac0>], <SelectBackward0 object at 0x1775a3760>: [<SliceBackward0 object at 0x1775a3af0>], <SelectBackward0 object at 0x1775a3790>: [<SliceBackward0 object at 0x1775a3b20>], <AccumulateGrad object at 0x1775a37c0>: [], <TBackward0 object at 0x1775a37f0>: [<AccumulateGrad object at 0x1775a3b50>], <ExpandBackward0 object at 0x1775a3820>: [<PermuteBackward0 object at 0x1775a3b80>], <ExpandBackward0 object at 0x1775a3850>: [<PermuteBackward0 object at 0x1775a3bb0>], <ViewBackward0 object at 0x1775a3880>: [<ViewBackward0 object at 0x1775a3be0>], <DivBackward0 object at 0x1775a38b0>: [<UnsafeViewBackward0 object at 0x1775a3c10>, None], <SliceBackward0 object at 0x1775a38e0>: [<SelectBackward0 object at 0x1775a3c40>], <ViewBackward0 object at 0x1775a3910>: [<ExpandBackward0 object at 0x1775a3c70>], <ReshapeAliasBackward0 object at 0x1775a3940>: [<ExpandBackward0 object at 0x1775a3ca0>], <TBackward0 object at 0x1775a3970>: [<AccumulateGrad object at 0x1775a3cd0>], <ReshapeAliasBackward0 object at 0x1775a39a0>: [<PermuteBackward0 object at 0x1775a3d00>], <AccumulateGrad object at 0x1775a39d0>: [], <MulBackward0 object at 0x1775a3a00>: [<GeluBackward0 object at 0x1775a3d30>, <SliceBackward0 object at 0x1775a3d60>], <TBackward0 object at 0x1775a3a30>: [<AccumulateGrad object at 0x1775a3d90>], <AddBackward0 object at 0x1775a3a60>: [<AddmmBackward0 object at 0x1775a3dc0>, <NativeLayerNormBackward0 object at 0x1775a3df0>], <AccumulateGrad object at 0x1775a3a90>: [], <AccumulateGrad object at 0x1775a3ac0>: [], <SliceBackward0 object at 0x1775a3af0>: [<SliceBackward0 object at 0x1775a3e20>], <SliceBackward0 object at 0x1775a3b20>: [<SliceBackward0 object at 0x1775a3e50>], <AccumulateGrad object at 0x1775a3b50>: [], <PermuteBackward0 object at 0x1775a3b80>: [<SliceBackward0 object at 0x1775a3e80>], <PermuteBackward0 object at 0x1775a3bb0>: [<SliceBackward0 object at 0x1775a3eb0>], <ViewBackward0 object at 0x1775a3be0>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b540>], <UnsafeViewBackward0 object at 0x1775a3c10>: [<BmmBackward0 object at 0x1775a3ee0>], <SelectBackward0 object at 0x1775a3c40>: [<SliceBackward0 object at 0x1775a3f10>], <ExpandBackward0 object at 0x1775a3c70>: [<SoftmaxBackward0 object at 0x1775a3f40>], <ExpandBackward0 object at 0x1775a3ca0>: [<PermuteBackward0 object at 0x1775a3f70>], <AccumulateGrad object at 0x1775a3cd0>: [], <PermuteBackward0 object at 0x1775a3d00>: [<UnsafeViewBackward0 object at 0x1775a3fa0>], <GeluBackward0 object at 0x1775a3d30>: [<SliceBackward0 object at 0x1775a3fd0>], <SliceBackward0 object at 0x1775a3d60>: [<SliceBackward0 object at 0x177599040>], <AccumulateGrad object at 0x1775a3d90>: [], <AddmmBackward0 object at 0x1775a3dc0>: [<AccumulateGrad object at 0x177599070>, <ViewBackward0 object at 0x1775990a0>, <TBackward0 object at 0x1775990d0>], <NativeLayerNormBackward0 object at 0x1775a3df0>: [<AddBackward0 object at 0x177599100>, <AccumulateGrad object at 0x177599130>, <AccumulateGrad object at 0x177599160>], <SliceBackward0 object at 0x1775a3e20>: [<ViewBackward0 object at 0x17759ebb0>], <SliceBackward0 object at 0x1775a3e50>: [<ViewBackward0 object at 0x17759ebb0>], <SliceBackward0 object at 0x1775a3e80>: [<SliceBackward0 object at 0x177599190>], <SliceBackward0 object at 0x1775a3eb0>: [<SliceBackward0 object at 0x1775991c0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b540>: [<AddmmBackward0 object at 0x1775991f0>, None], <BmmBackward0 object at 0x1775a3ee0>: [<ReshapeAliasBackward0 object at 0x177599220>, <ReshapeAliasBackward0 object at 0x177599250>], <SliceBackward0 object at 0x1775a3f10>: [<SliceBackward0 object at 0x177599280>], <SoftmaxBackward0 object at 0x1775a3f40>: [<AddBackward0 object at 0x1775992b0>], <PermuteBackward0 object at 0x1775a3f70>: [<SliceBackward0 object at 0x1775992e0>], <UnsafeViewBackward0 object at 0x1775a3fa0>: [<BmmBackward0 object at 0x177599310>], <SliceBackward0 object at 0x1775a3fd0>: [<SliceBackward0 object at 0x177599340>], <SliceBackward0 object at 0x177599040>: [<MmBackward0 object at 0x177599370>], <AccumulateGrad object at 0x177599070>: [], <ViewBackward0 object at 0x1775990a0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x177430d40>], <TBackward0 object at 0x1775990d0>: [<AccumulateGrad object at 0x1775993a0>], <AddBackward0 object at 0x177599100>: [<AddmmBackward0 object at 0x1775993d0>, <NativeLayerNormBackward0 object at 0x177599400>], <AccumulateGrad object at 0x177599130>: [], <AccumulateGrad object at 0x177599160>: [], <SliceBackward0 object at 0x177599190>: [<SelectBackward0 object at 0x177599430>], <SliceBackward0 object at 0x1775991c0>: [<SelectBackward0 object at 0x177599460>], <AddmmBackward0 object at 0x1775991f0>: [<AccumulateGrad object at 0x177599490>, <NativeLayerNormBackward0 object at 0x177433c70>, <TBackward0 object at 0x1775994c0>], <ReshapeAliasBackward0 object at 0x177599220>: [<ExpandBackward0 object at 0x1775994f0>], <ReshapeAliasBackward0 object at 0x177599250>: [<ExpandBackward0 object at 0x177599520>], <SliceBackward0 object at 0x177599280>: [<ViewBackward0 object at 0x177599550>], <AddBackward0 object at 0x1775992b0>: [<DivBackward0 object at 0x177599580>, None], <SliceBackward0 object at 0x1775992e0>: [<SliceBackward0 object at 0x1775995b0>], <BmmBackward0 object at 0x177599310>: [<ViewBackward0 object at 0x1775995e0>, <ReshapeAliasBackward0 object at 0x177599610>], <SliceBackward0 object at 0x177599340>: [<MmBackward0 object at 0x177599370>], <MmBackward0 object at 0x177599370>: [<NativeLayerNormBackward0 object at 0x1775a3730>, <TBackward0 object at 0x177599640>], <torch.autograd.function.IndexFirstAxisBackward object at 0x177430d40>: [<ReshapeAliasBackward0 object at 0x177599670>, None], <AccumulateGrad object at 0x1775993a0>: [], <AddmmBackward0 object at 0x1775993d0>: [<AccumulateGrad object at 0x1775996a0>, <MulBackward0 object at 0x1775996d0>, <TBackward0 object at 0x177599700>], <NativeLayerNormBackward0 object at 0x177599400>: [<AddBackward0 object at 0x177599730>, <AccumulateGrad object at 0x177599760>, <AccumulateGrad object at 0x177599790>], <SelectBackward0 object at 0x177599430>: [<SliceBackward0 object at 0x1775997c0>], <SelectBackward0 object at 0x177599460>: [<SliceBackward0 object at 0x1775997f0>], <AccumulateGrad object at 0x177599490>: [], <TBackward0 object at 0x1775994c0>: [<AccumulateGrad object at 0x177599820>], <ExpandBackward0 object at 0x1775994f0>: [<PermuteBackward0 object at 0x177599850>], <ExpandBackward0 object at 0x177599520>: [<PermuteBackward0 object at 0x177599880>], <ViewBackward0 object at 0x177599550>: [<ViewBackward0 object at 0x1775998b0>], <DivBackward0 object at 0x177599580>: [<UnsafeViewBackward0 object at 0x1775998e0>, None], <SliceBackward0 object at 0x1775995b0>: [<SelectBackward0 object at 0x177599910>], <ViewBackward0 object at 0x1775995e0>: [<ExpandBackward0 object at 0x177599940>], <ReshapeAliasBackward0 object at 0x177599610>: [<ExpandBackward0 object at 0x177599970>], <TBackward0 object at 0x177599640>: [<AccumulateGrad object at 0x1775999a0>], <ReshapeAliasBackward0 object at 0x177599670>: [<PermuteBackward0 object at 0x1775999d0>], <AccumulateGrad object at 0x1775996a0>: [], <MulBackward0 object at 0x1775996d0>: [<GeluBackward0 object at 0x177599a00>, <SliceBackward0 object at 0x177599a30>], <TBackward0 object at 0x177599700>: [<AccumulateGrad object at 0x177599a60>], <AddBackward0 object at 0x177599730>: [<AddmmBackward0 object at 0x177599a90>, <NativeLayerNormBackward0 object at 0x177599ac0>], <AccumulateGrad object at 0x177599760>: [], <AccumulateGrad object at 0x177599790>: [], <SliceBackward0 object at 0x1775997c0>: [<SliceBackward0 object at 0x177599af0>], <SliceBackward0 object at 0x1775997f0>: [<SliceBackward0 object at 0x177599b20>], <AccumulateGrad object at 0x177599820>: [], <PermuteBackward0 object at 0x177599850>: [<SliceBackward0 object at 0x177599b50>], <PermuteBackward0 object at 0x177599880>: [<SliceBackward0 object at 0x177599b80>], <ViewBackward0 object at 0x1775998b0>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b340>], <UnsafeViewBackward0 object at 0x1775998e0>: [<BmmBackward0 object at 0x177599bb0>], <SelectBackward0 object at 0x177599910>: [<SliceBackward0 object at 0x177599be0>], <ExpandBackward0 object at 0x177599940>: [<SoftmaxBackward0 object at 0x177599c10>], <ExpandBackward0 object at 0x177599970>: [<PermuteBackward0 object at 0x177599c40>], <AccumulateGrad object at 0x1775999a0>: [], <PermuteBackward0 object at 0x1775999d0>: [<UnsafeViewBackward0 object at 0x177599c70>], <GeluBackward0 object at 0x177599a00>: [<SliceBackward0 object at 0x177599ca0>], <SliceBackward0 object at 0x177599a30>: [<SliceBackward0 object at 0x177599cd0>], <AccumulateGrad object at 0x177599a60>: [], <AddmmBackward0 object at 0x177599a90>: [<AccumulateGrad object at 0x177599d00>, <ViewBackward0 object at 0x177599d30>, <TBackward0 object at 0x177599d60>], <NativeLayerNormBackward0 object at 0x177599ac0>: [<AddBackward0 object at 0x177599d90>, <AccumulateGrad object at 0x177599dc0>, <AccumulateGrad object at 0x177599df0>], <SliceBackward0 object at 0x177599af0>: [<ViewBackward0 object at 0x1775a3880>], <SliceBackward0 object at 0x177599b20>: [<ViewBackward0 object at 0x1775a3880>], <SliceBackward0 object at 0x177599b50>: [<SliceBackward0 object at 0x177599e20>], <SliceBackward0 object at 0x177599b80>: [<SliceBackward0 object at 0x177599e50>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b340>: [<AddmmBackward0 object at 0x177599e80>, None], <BmmBackward0 object at 0x177599bb0>: [<ReshapeAliasBackward0 object at 0x177599eb0>, <ReshapeAliasBackward0 object at 0x177599ee0>], <SliceBackward0 object at 0x177599be0>: [<SliceBackward0 object at 0x177599f10>], <SoftmaxBackward0 object at 0x177599c10>: [<AddBackward0 object at 0x177599f40>], <PermuteBackward0 object at 0x177599c40>: [<SliceBackward0 object at 0x177599f70>], <UnsafeViewBackward0 object at 0x177599c70>: [<BmmBackward0 object at 0x177599fa0>], <SliceBackward0 object at 0x177599ca0>: [<SliceBackward0 object at 0x177599fd0>], <SliceBackward0 object at 0x177599cd0>: [<MmBackward0 object at 0x1775a2040>], <AccumulateGrad object at 0x177599d00>: [], <ViewBackward0 object at 0x177599d30>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x177430a40>], <TBackward0 object at 0x177599d60>: [<AccumulateGrad object at 0x1775a2070>], <AddBackward0 object at 0x177599d90>: [<AddmmBackward0 object at 0x1775a20a0>, <NativeLayerNormBackward0 object at 0x1775a20d0>], <AccumulateGrad object at 0x177599dc0>: [], <AccumulateGrad object at 0x177599df0>: [], <SliceBackward0 object at 0x177599e20>: [<SelectBackward0 object at 0x1775a2100>], <SliceBackward0 object at 0x177599e50>: [<SelectBackward0 object at 0x1775a2130>], <AddmmBackward0 object at 0x177599e80>: [<AccumulateGrad object at 0x1775a2160>, <NativeLayerNormBackward0 object at 0x17740d5e0>, <TBackward0 object at 0x1775a2190>], <ReshapeAliasBackward0 object at 0x177599eb0>: [<ExpandBackward0 object at 0x1775a21c0>], <ReshapeAliasBackward0 object at 0x177599ee0>: [<ExpandBackward0 object at 0x1775a21f0>], <SliceBackward0 object at 0x177599f10>: [<ViewBackward0 object at 0x1775a2220>], <AddBackward0 object at 0x177599f40>: [<DivBackward0 object at 0x1775a2250>, None], <SliceBackward0 object at 0x177599f70>: [<SliceBackward0 object at 0x1775a2280>], <BmmBackward0 object at 0x177599fa0>: [<ViewBackward0 object at 0x1775a22b0>, <ReshapeAliasBackward0 object at 0x1775a22e0>], <SliceBackward0 object at 0x177599fd0>: [<MmBackward0 object at 0x1775a2040>], <MmBackward0 object at 0x1775a2040>: [<NativeLayerNormBackward0 object at 0x177599400>, <TBackward0 object at 0x1775a2310>], <torch.autograd.function.IndexFirstAxisBackward object at 0x177430a40>: [<ReshapeAliasBackward0 object at 0x1775a2340>, None], <AccumulateGrad object at 0x1775a2070>: [], <AddmmBackward0 object at 0x1775a20a0>: [<AccumulateGrad object at 0x1775a2370>, <MulBackward0 object at 0x1775a23a0>, <TBackward0 object at 0x1775a23d0>], <NativeLayerNormBackward0 object at 0x1775a20d0>: [<AddBackward0 object at 0x1775a2400>, <AccumulateGrad object at 0x1775a2430>, <AccumulateGrad object at 0x1775a2460>], <SelectBackward0 object at 0x1775a2100>: [<SliceBackward0 object at 0x1775a2490>], <SelectBackward0 object at 0x1775a2130>: [<SliceBackward0 object at 0x1775a24c0>], <AccumulateGrad object at 0x1775a2160>: [], <TBackward0 object at 0x1775a2190>: [<AccumulateGrad object at 0x1775a24f0>], <ExpandBackward0 object at 0x1775a21c0>: [<PermuteBackward0 object at 0x1775a2520>], <ExpandBackward0 object at 0x1775a21f0>: [<PermuteBackward0 object at 0x1775a2550>], <ViewBackward0 object at 0x1775a2220>: [<ViewBackward0 object at 0x1775a2580>], <DivBackward0 object at 0x1775a2250>: [<UnsafeViewBackward0 object at 0x1775a25b0>, None], <SliceBackward0 object at 0x1775a2280>: [<SelectBackward0 object at 0x1775a25e0>], <ViewBackward0 object at 0x1775a22b0>: [<ExpandBackward0 object at 0x1775a2610>], <ReshapeAliasBackward0 object at 0x1775a22e0>: [<ExpandBackward0 object at 0x1775a2640>], <TBackward0 object at 0x1775a2310>: [<AccumulateGrad object at 0x1775a2670>], <ReshapeAliasBackward0 object at 0x1775a2340>: [<PermuteBackward0 object at 0x1775a26a0>], <AccumulateGrad object at 0x1775a2370>: [], <MulBackward0 object at 0x1775a23a0>: [<GeluBackward0 object at 0x1775a26d0>, <SliceBackward0 object at 0x1775a2700>], <TBackward0 object at 0x1775a23d0>: [<AccumulateGrad object at 0x1775a2730>], <AddBackward0 object at 0x1775a2400>: [<AddmmBackward0 object at 0x1775a2760>, <NativeLayerNormBackward0 object at 0x1775a2790>], <AccumulateGrad object at 0x1775a2430>: [], <AccumulateGrad object at 0x1775a2460>: [], <SliceBackward0 object at 0x1775a2490>: [<SliceBackward0 object at 0x1775a27c0>], <SliceBackward0 object at 0x1775a24c0>: [<SliceBackward0 object at 0x1775a27f0>], <AccumulateGrad object at 0x1775a24f0>: [], <PermuteBackward0 object at 0x1775a2520>: [<SliceBackward0 object at 0x1775a2820>], <PermuteBackward0 object at 0x1775a2550>: [<SliceBackward0 object at 0x1775a2850>], <ViewBackward0 object at 0x1775a2580>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b140>], <UnsafeViewBackward0 object at 0x1775a25b0>: [<BmmBackward0 object at 0x1775a2880>], <SelectBackward0 object at 0x1775a25e0>: [<SliceBackward0 object at 0x1775a28b0>], <ExpandBackward0 object at 0x1775a2610>: [<SoftmaxBackward0 object at 0x1775a28e0>], <ExpandBackward0 object at 0x1775a2640>: [<PermuteBackward0 object at 0x1775a2910>], <AccumulateGrad object at 0x1775a2670>: [], <PermuteBackward0 object at 0x1775a26a0>: [<UnsafeViewBackward0 object at 0x1775a2940>], <GeluBackward0 object at 0x1775a26d0>: [<SliceBackward0 object at 0x1775a2970>], <SliceBackward0 object at 0x1775a2700>: [<SliceBackward0 object at 0x1775a29a0>], <AccumulateGrad object at 0x1775a2730>: [], <AddmmBackward0 object at 0x1775a2760>: [<AccumulateGrad object at 0x1775a29d0>, <ViewBackward0 object at 0x1775a2a00>, <TBackward0 object at 0x1775a2a30>], <NativeLayerNormBackward0 object at 0x1775a2790>: [<AddBackward0 object at 0x1775a2a60>, <AccumulateGrad object at 0x1775a2a90>, <AccumulateGrad object at 0x1775a2ac0>], <SliceBackward0 object at 0x1775a27c0>: [<ViewBackward0 object at 0x177599550>], <SliceBackward0 object at 0x1775a27f0>: [<ViewBackward0 object at 0x177599550>], <SliceBackward0 object at 0x1775a2820>: [<SliceBackward0 object at 0x1775a2af0>], <SliceBackward0 object at 0x1775a2850>: [<SliceBackward0 object at 0x1775a2b20>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x17758b140>: [<AddmmBackward0 object at 0x1775a2b50>, None], <BmmBackward0 object at 0x1775a2880>: [<ReshapeAliasBackward0 object at 0x1775a2b80>, <ReshapeAliasBackward0 object at 0x1775a2bb0>], <SliceBackward0 object at 0x1775a28b0>: [<SliceBackward0 object at 0x1775a2be0>], <SoftmaxBackward0 object at 0x1775a28e0>: [<AddBackward0 object at 0x1775a2c10>], <PermuteBackward0 object at 0x1775a2910>: [<SliceBackward0 object at 0x1775a2c40>], <UnsafeViewBackward0 object at 0x1775a2940>: [<BmmBackward0 object at 0x1775a2c70>], <SliceBackward0 object at 0x1775a2970>: [<SliceBackward0 object at 0x1775a2ca0>], <SliceBackward0 object at 0x1775a29a0>: [<MmBackward0 object at 0x1775a2cd0>], <AccumulateGrad object at 0x1775a29d0>: [], <ViewBackward0 object at 0x1775a2a00>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x177430840>], <TBackward0 object at 0x1775a2a30>: [<AccumulateGrad object at 0x1775a2d00>], <AddBackward0 object at 0x1775a2a60>: [<AddmmBackward0 object at 0x1775a2d30>, <NativeLayerNormBackward0 object at 0x1775a2d60>], <AccumulateGrad object at 0x1775a2a90>: [], <AccumulateGrad object at 0x1775a2ac0>: [], <SliceBackward0 object at 0x1775a2af0>: [<SelectBackward0 object at 0x1775a2d90>], <SliceBackward0 object at 0x1775a2b20>: [<SelectBackward0 object at 0x1775a2dc0>], <AddmmBackward0 object at 0x1775a2b50>: [<AccumulateGrad object at 0x1775a2df0>, <NativeLayerNormBackward0 object at 0x17759e490>, <TBackward0 object at 0x1775a2e20>], <ReshapeAliasBackward0 object at 0x1775a2b80>: [<ExpandBackward0 object at 0x1775a2e50>], <ReshapeAliasBackward0 object at 0x1775a2bb0>: [<ExpandBackward0 object at 0x1775a2e80>], <SliceBackward0 object at 0x1775a2be0>: [<ViewBackward0 object at 0x1775a2eb0>], <AddBackward0 object at 0x1775a2c10>: [<DivBackward0 object at 0x1775a2ee0>, None], <SliceBackward0 object at 0x1775a2c40>: [<SliceBackward0 object at 0x1775a2f10>], <BmmBackward0 object at 0x1775a2c70>: [<ViewBackward0 object at 0x1775a2f40>, <ReshapeAliasBackward0 object at 0x1775a2f70>], <SliceBackward0 object at 0x1775a2ca0>: [<MmBackward0 object at 0x1775a2cd0>], <MmBackward0 object at 0x1775a2cd0>: [<NativeLayerNormBackward0 object at 0x1775a20d0>, <TBackward0 object at 0x1775a2fa0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x177430840>: [<ReshapeAliasBackward0 object at 0x1775a2fd0>, None], <AccumulateGrad object at 0x1775a2d00>: [], <AddmmBackward0 object at 0x1775a2d30>: [<AccumulateGrad object at 0x177dc4040>, <MulBackward0 object at 0x177dc4070>, <TBackward0 object at 0x177dc40a0>], <NativeLayerNormBackward0 object at 0x1775a2d60>: [<AddBackward0 object at 0x177dc40d0>, <AccumulateGrad object at 0x177dc4100>, <AccumulateGrad object at 0x177dc4130>], <SelectBackward0 object at 0x1775a2d90>: [<SliceBackward0 object at 0x177dc4160>], <SelectBackward0 object at 0x1775a2dc0>: [<SliceBackward0 object at 0x177dc4190>], <AccumulateGrad object at 0x1775a2df0>: [], <TBackward0 object at 0x1775a2e20>: [<AccumulateGrad object at 0x177dc41c0>], <ExpandBackward0 object at 0x1775a2e50>: [<PermuteBackward0 object at 0x177dc41f0>], <ExpandBackward0 object at 0x1775a2e80>: [<PermuteBackward0 object at 0x177dc4220>], <ViewBackward0 object at 0x1775a2eb0>: [<ViewBackward0 object at 0x177dc4250>], <DivBackward0 object at 0x1775a2ee0>: [<UnsafeViewBackward0 object at 0x177dc4280>, None], <SliceBackward0 object at 0x1775a2f10>: [<SelectBackward0 object at 0x177dc42b0>], <ViewBackward0 object at 0x1775a2f40>: [<ExpandBackward0 object at 0x177dc42e0>], <ReshapeAliasBackward0 object at 0x1775a2f70>: [<ExpandBackward0 object at 0x177dc4310>], <TBackward0 object at 0x1775a2fa0>: [<AccumulateGrad object at 0x177dc4340>], <ReshapeAliasBackward0 object at 0x1775a2fd0>: [<PermuteBackward0 object at 0x177dc4370>], <AccumulateGrad object at 0x177dc4040>: [], <MulBackward0 object at 0x177dc4070>: [<GeluBackward0 object at 0x177dc43a0>, <SliceBackward0 object at 0x177dc43d0>], <TBackward0 object at 0x177dc40a0>: [<AccumulateGrad object at 0x177dc4400>], <AddBackward0 object at 0x177dc40d0>: [<AddmmBackward0 object at 0x177dc4430>, <torch.autograd.function.IndexFirstAxisBackward object at 0x1773b8e40>], <AccumulateGrad object at 0x177dc4100>: [], <AccumulateGrad object at 0x177dc4130>: [], <SliceBackward0 object at 0x177dc4160>: [<SliceBackward0 object at 0x177dc4460>], <SliceBackward0 object at 0x177dc4190>: [<SliceBackward0 object at 0x177dc4490>], <AccumulateGrad object at 0x177dc41c0>: [], <PermuteBackward0 object at 0x177dc41f0>: [<SliceBackward0 object at 0x177dc44c0>], <PermuteBackward0 object at 0x177dc4220>: [<SliceBackward0 object at 0x177dc44f0>], <ViewBackward0 object at 0x177dc4250>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430e40>], <UnsafeViewBackward0 object at 0x177dc4280>: [<BmmBackward0 object at 0x177dc4520>], <SelectBackward0 object at 0x177dc42b0>: [<SliceBackward0 object at 0x177dc4550>], <ExpandBackward0 object at 0x177dc42e0>: [<SoftmaxBackward0 object at 0x177dc4580>], <ExpandBackward0 object at 0x177dc4310>: [<PermuteBackward0 object at 0x177dc45b0>], <AccumulateGrad object at 0x177dc4340>: [], <PermuteBackward0 object at 0x177dc4370>: [<UnsafeViewBackward0 object at 0x177dc45e0>], <GeluBackward0 object at 0x177dc43a0>: [<SliceBackward0 object at 0x177dc4610>], <SliceBackward0 object at 0x177dc43d0>: [<SliceBackward0 object at 0x177dc4640>], <AccumulateGrad object at 0x177dc4400>: [], <AddmmBackward0 object at 0x177dc4430>: [<AccumulateGrad object at 0x177dc4670>, <ViewBackward0 object at 0x177dc46a0>, <TBackward0 object at 0x177dc46d0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x1773b8e40>: [<ViewBackward0 object at 0x177dc4700>, None], <SliceBackward0 object at 0x177dc4460>: [<ViewBackward0 object at 0x1775a2220>], <SliceBackward0 object at 0x177dc4490>: [<ViewBackward0 object at 0x1775a2220>], <SliceBackward0 object at 0x177dc44c0>: [<SliceBackward0 object at 0x177dc4730>], <SliceBackward0 object at 0x177dc44f0>: [<SliceBackward0 object at 0x177dc4760>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430e40>: [<AddmmBackward0 object at 0x177dc4790>, None], <BmmBackward0 object at 0x177dc4520>: [<ReshapeAliasBackward0 object at 0x177dc47c0>, <ReshapeAliasBackward0 object at 0x177dc47f0>], <SliceBackward0 object at 0x177dc4550>: [<SliceBackward0 object at 0x177dc4820>], <SoftmaxBackward0 object at 0x177dc4580>: [<AddBackward0 object at 0x177dc4850>], <PermuteBackward0 object at 0x177dc45b0>: [<SliceBackward0 object at 0x177dc4880>], <UnsafeViewBackward0 object at 0x177dc45e0>: [<BmmBackward0 object at 0x177dc48b0>], <SliceBackward0 object at 0x177dc4610>: [<SliceBackward0 object at 0x177dc48e0>], <SliceBackward0 object at 0x177dc4640>: [<MmBackward0 object at 0x177dc4910>], <AccumulateGrad object at 0x177dc4670>: [], <ViewBackward0 object at 0x177dc46a0>: [<torch.autograd.function.IndexFirstAxisBackward object at 0x177430040>], <TBackward0 object at 0x177dc46d0>: [<AccumulateGrad object at 0x177dc4940>], <ViewBackward0 object at 0x177dc4700>: [<NativeLayerNormBackward0 object at 0x177dc4970>], <SliceBackward0 object at 0x177dc4730>: [<SelectBackward0 object at 0x177dc49a0>], <SliceBackward0 object at 0x177dc4760>: [<SelectBackward0 object at 0x177dc49d0>], <AddmmBackward0 object at 0x177dc4790>: [<AccumulateGrad object at 0x177dc4a00>, <NativeLayerNormBackward0 object at 0x1775a3160>, <TBackward0 object at 0x177dc4a30>], <ReshapeAliasBackward0 object at 0x177dc47c0>: [<ExpandBackward0 object at 0x177dc4a60>], <ReshapeAliasBackward0 object at 0x177dc47f0>: [<ExpandBackward0 object at 0x177dc4a90>], <SliceBackward0 object at 0x177dc4820>: [<ViewBackward0 object at 0x177dc4ac0>], <AddBackward0 object at 0x177dc4850>: [<DivBackward0 object at 0x177dc4af0>, None], <SliceBackward0 object at 0x177dc4880>: [<SliceBackward0 object at 0x177dc4b20>], <BmmBackward0 object at 0x177dc48b0>: [<ViewBackward0 object at 0x177dc4b50>, <ReshapeAliasBackward0 object at 0x177dc4b80>], <SliceBackward0 object at 0x177dc48e0>: [<MmBackward0 object at 0x177dc4910>], <MmBackward0 object at 0x177dc4910>: [<NativeLayerNormBackward0 object at 0x1775a2d60>, <TBackward0 object at 0x177dc4bb0>], <torch.autograd.function.IndexFirstAxisBackward object at 0x177430040>: [<ReshapeAliasBackward0 object at 0x177dc4be0>, None], <AccumulateGrad object at 0x177dc4940>: [], <NativeLayerNormBackward0 object at 0x177dc4970>: [<AddBackward0 object at 0x177dc4c10>, <AccumulateGrad object at 0x177dc4c40>, <AccumulateGrad object at 0x177dc4c70>], <SelectBackward0 object at 0x177dc49a0>: [<SliceBackward0 object at 0x177dc4ca0>], <SelectBackward0 object at 0x177dc49d0>: [<SliceBackward0 object at 0x177dc4cd0>], <AccumulateGrad object at 0x177dc4a00>: [], <TBackward0 object at 0x177dc4a30>: [<AccumulateGrad object at 0x177dc4d00>], <ExpandBackward0 object at 0x177dc4a60>: [<PermuteBackward0 object at 0x177dc4d30>], <ExpandBackward0 object at 0x177dc4a90>: [<PermuteBackward0 object at 0x177dc4d60>], <ViewBackward0 object at 0x177dc4ac0>: [<ViewBackward0 object at 0x177dc4d90>], <DivBackward0 object at 0x177dc4af0>: [<UnsafeViewBackward0 object at 0x177dc4dc0>, None], <SliceBackward0 object at 0x177dc4b20>: [<SelectBackward0 object at 0x177dc4df0>], <ViewBackward0 object at 0x177dc4b50>: [<ExpandBackward0 object at 0x177dc4e20>], <ReshapeAliasBackward0 object at 0x177dc4b80>: [<ExpandBackward0 object at 0x177dc4e50>], <TBackward0 object at 0x177dc4bb0>: [<AccumulateGrad object at 0x177dc4e80>], <ReshapeAliasBackward0 object at 0x177dc4be0>: [<PermuteBackward0 object at 0x177dc4eb0>], <AddBackward0 object at 0x177dc4c10>: [<EmbeddingBackward0 object at 0x177dc4ee0>, <EmbeddingBackward0 object at 0x177dc4f10>], <AccumulateGrad object at 0x177dc4c40>: [], <AccumulateGrad object at 0x177dc4c70>: [], <SliceBackward0 object at 0x177dc4ca0>: [<SliceBackward0 object at 0x177dc4f40>], <SliceBackward0 object at 0x177dc4cd0>: [<SliceBackward0 object at 0x177dc4f70>], <AccumulateGrad object at 0x177dc4d00>: [], <PermuteBackward0 object at 0x177dc4d30>: [<SliceBackward0 object at 0x177dc4fa0>], <PermuteBackward0 object at 0x177dc4d60>: [<SliceBackward0 object at 0x177dc4fd0>], <ViewBackward0 object at 0x177dc4d90>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430c40>], <UnsafeViewBackward0 object at 0x177dc4dc0>: [<BmmBackward0 object at 0x177dc9040>], <SelectBackward0 object at 0x177dc4df0>: [<SliceBackward0 object at 0x177dc9070>], <ExpandBackward0 object at 0x177dc4e20>: [<SoftmaxBackward0 object at 0x177dc90a0>], <ExpandBackward0 object at 0x177dc4e50>: [<PermuteBackward0 object at 0x177dc90d0>], <AccumulateGrad object at 0x177dc4e80>: [], <PermuteBackward0 object at 0x177dc4eb0>: [<UnsafeViewBackward0 object at 0x177dc9100>], <EmbeddingBackward0 object at 0x177dc4ee0>: [<AccumulateGrad object at 0x177dc9130>], <EmbeddingBackward0 object at 0x177dc4f10>: [<AccumulateGrad object at 0x177dc9160>], <SliceBackward0 object at 0x177dc4f40>: [<ViewBackward0 object at 0x1775a2eb0>], <SliceBackward0 object at 0x177dc4f70>: [<ViewBackward0 object at 0x1775a2eb0>], <SliceBackward0 object at 0x177dc4fa0>: [<SliceBackward0 object at 0x177dc9190>], <SliceBackward0 object at 0x177dc4fd0>: [<SliceBackward0 object at 0x177dc91c0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430c40>: [<AddmmBackward0 object at 0x177dc91f0>, None], <BmmBackward0 object at 0x177dc9040>: [<ReshapeAliasBackward0 object at 0x177dc9220>, <ReshapeAliasBackward0 object at 0x177dc9250>], <SliceBackward0 object at 0x177dc9070>: [<SliceBackward0 object at 0x177dc9280>], <SoftmaxBackward0 object at 0x177dc90a0>: [<AddBackward0 object at 0x177dc92b0>], <PermuteBackward0 object at 0x177dc90d0>: [<SliceBackward0 object at 0x177dc92e0>], <UnsafeViewBackward0 object at 0x177dc9100>: [<BmmBackward0 object at 0x177dc9310>], <AccumulateGrad object at 0x177dc9130>: [], <AccumulateGrad object at 0x177dc9160>: [], <SliceBackward0 object at 0x177dc9190>: [<SelectBackward0 object at 0x177dc9340>], <SliceBackward0 object at 0x177dc91c0>: [<SelectBackward0 object at 0x177dc9370>], <AddmmBackward0 object at 0x177dc91f0>: [<AccumulateGrad object at 0x177dc93a0>, <NativeLayerNormBackward0 object at 0x1775a3df0>, <TBackward0 object at 0x177dc93d0>], <ReshapeAliasBackward0 object at 0x177dc9220>: [<ExpandBackward0 object at 0x177dc9400>], <ReshapeAliasBackward0 object at 0x177dc9250>: [<ExpandBackward0 object at 0x177dc9430>], <SliceBackward0 object at 0x177dc9280>: [<ViewBackward0 object at 0x177dc9460>], <AddBackward0 object at 0x177dc92b0>: [<DivBackward0 object at 0x177dc9490>, None], <SliceBackward0 object at 0x177dc92e0>: [<SliceBackward0 object at 0x177dc94c0>], <BmmBackward0 object at 0x177dc9310>: [<ViewBackward0 object at 0x177dc94f0>, <ReshapeAliasBackward0 object at 0x177dc9520>], <SelectBackward0 object at 0x177dc9340>: [<SliceBackward0 object at 0x177dc9550>], <SelectBackward0 object at 0x177dc9370>: [<SliceBackward0 object at 0x177dc9580>], <AccumulateGrad object at 0x177dc93a0>: [], <TBackward0 object at 0x177dc93d0>: [<AccumulateGrad object at 0x177dc95b0>], <ExpandBackward0 object at 0x177dc9400>: [<PermuteBackward0 object at 0x177dc95e0>], <ExpandBackward0 object at 0x177dc9430>: [<PermuteBackward0 object at 0x177dc9610>], <ViewBackward0 object at 0x177dc9460>: [<ViewBackward0 object at 0x177dc9640>], <DivBackward0 object at 0x177dc9490>: [<UnsafeViewBackward0 object at 0x177dc9670>, None], <SliceBackward0 object at 0x177dc94c0>: [<SelectBackward0 object at 0x177dc96a0>], <ViewBackward0 object at 0x177dc94f0>: [<ExpandBackward0 object at 0x177dc96d0>], <ReshapeAliasBackward0 object at 0x177dc9520>: [<ExpandBackward0 object at 0x177dc9700>], <SliceBackward0 object at 0x177dc9550>: [<SliceBackward0 object at 0x177dc9730>], <SliceBackward0 object at 0x177dc9580>: [<SliceBackward0 object at 0x177dc9760>], <AccumulateGrad object at 0x177dc95b0>: [], <PermuteBackward0 object at 0x177dc95e0>: [<SliceBackward0 object at 0x177dc9790>], <PermuteBackward0 object at 0x177dc9610>: [<SliceBackward0 object at 0x177dc97c0>], <ViewBackward0 object at 0x177dc9640>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430940>], <UnsafeViewBackward0 object at 0x177dc9670>: [<BmmBackward0 object at 0x177dc97f0>], <SelectBackward0 object at 0x177dc96a0>: [<SliceBackward0 object at 0x177dc9820>], <ExpandBackward0 object at 0x177dc96d0>: [<SoftmaxBackward0 object at 0x177dc9850>], <ExpandBackward0 object at 0x177dc9700>: [<PermuteBackward0 object at 0x177dc9880>], <SliceBackward0 object at 0x177dc9730>: [<ViewBackward0 object at 0x177dc4ac0>], <SliceBackward0 object at 0x177dc9760>: [<ViewBackward0 object at 0x177dc4ac0>], <SliceBackward0 object at 0x177dc9790>: [<SliceBackward0 object at 0x177dc98b0>], <SliceBackward0 object at 0x177dc97c0>: [<SliceBackward0 object at 0x177dc98e0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430940>: [<AddmmBackward0 object at 0x177dc9910>, None], <BmmBackward0 object at 0x177dc97f0>: [<ReshapeAliasBackward0 object at 0x177dc9940>, <ReshapeAliasBackward0 object at 0x177dc9970>], <SliceBackward0 object at 0x177dc9820>: [<SliceBackward0 object at 0x177dc99a0>], <SoftmaxBackward0 object at 0x177dc9850>: [<AddBackward0 object at 0x177dc99d0>], <PermuteBackward0 object at 0x177dc9880>: [<SliceBackward0 object at 0x177dc9a00>], <SliceBackward0 object at 0x177dc98b0>: [<SelectBackward0 object at 0x177dc9a30>], <SliceBackward0 object at 0x177dc98e0>: [<SelectBackward0 object at 0x177dc9a60>], <AddmmBackward0 object at 0x177dc9910>: [<AccumulateGrad object at 0x177dc9a90>, <NativeLayerNormBackward0 object at 0x177599ac0>, <TBackward0 object at 0x177dc9ac0>], <ReshapeAliasBackward0 object at 0x177dc9940>: [<ExpandBackward0 object at 0x177dc9af0>], <ReshapeAliasBackward0 object at 0x177dc9970>: [<ExpandBackward0 object at 0x177dc9b20>], <SliceBackward0 object at 0x177dc99a0>: [<ViewBackward0 object at 0x177dc9b50>], <AddBackward0 object at 0x177dc99d0>: [<DivBackward0 object at 0x177dc9b80>, None], <SliceBackward0 object at 0x177dc9a00>: [<SliceBackward0 object at 0x177dc9bb0>], <SelectBackward0 object at 0x177dc9a30>: [<SliceBackward0 object at 0x177dc9be0>], <SelectBackward0 object at 0x177dc9a60>: [<SliceBackward0 object at 0x177dc9c10>], <AccumulateGrad object at 0x177dc9a90>: [], <TBackward0 object at 0x177dc9ac0>: [<AccumulateGrad object at 0x177dc9c40>], <ExpandBackward0 object at 0x177dc9af0>: [<PermuteBackward0 object at 0x177dc9c70>], <ExpandBackward0 object at 0x177dc9b20>: [<PermuteBackward0 object at 0x177dc9ca0>], <ViewBackward0 object at 0x177dc9b50>: [<ViewBackward0 object at 0x177dc9cd0>], <DivBackward0 object at 0x177dc9b80>: [<UnsafeViewBackward0 object at 0x177dc9d00>, None], <SliceBackward0 object at 0x177dc9bb0>: [<SelectBackward0 object at 0x177dc9d30>], <SliceBackward0 object at 0x177dc9be0>: [<SliceBackward0 object at 0x177dc9d60>], <SliceBackward0 object at 0x177dc9c10>: [<SliceBackward0 object at 0x177dc9d90>], <AccumulateGrad object at 0x177dc9c40>: [], <PermuteBackward0 object at 0x177dc9c70>: [<SliceBackward0 object at 0x177dc9dc0>], <PermuteBackward0 object at 0x177dc9ca0>: [<SliceBackward0 object at 0x177dc9df0>], <ViewBackward0 object at 0x177dc9cd0>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430740>], <UnsafeViewBackward0 object at 0x177dc9d00>: [<BmmBackward0 object at 0x177dc9e20>], <SelectBackward0 object at 0x177dc9d30>: [<SliceBackward0 object at 0x177dc9e50>], <SliceBackward0 object at 0x177dc9d60>: [<ViewBackward0 object at 0x177dc9460>], <SliceBackward0 object at 0x177dc9d90>: [<ViewBackward0 object at 0x177dc9460>], <SliceBackward0 object at 0x177dc9dc0>: [<SliceBackward0 object at 0x177dc9e80>], <SliceBackward0 object at 0x177dc9df0>: [<SliceBackward0 object at 0x177dc9eb0>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430740>: [<AddmmBackward0 object at 0x177dc9ee0>, None], <BmmBackward0 object at 0x177dc9e20>: [<ReshapeAliasBackward0 object at 0x177dc9f10>, <ReshapeAliasBackward0 object at 0x177dc9f40>], <SliceBackward0 object at 0x177dc9e50>: [<SliceBackward0 object at 0x177dc9f70>], <SliceBackward0 object at 0x177dc9e80>: [<SelectBackward0 object at 0x177dc9fa0>], <SliceBackward0 object at 0x177dc9eb0>: [<SelectBackward0 object at 0x177dc9fd0>], <AddmmBackward0 object at 0x177dc9ee0>: [<AccumulateGrad object at 0x177dc0040>, <NativeLayerNormBackward0 object at 0x1775a2790>, <TBackward0 object at 0x177dc0070>], <ReshapeAliasBackward0 object at 0x177dc9f10>: [<ExpandBackward0 object at 0x177dc00a0>], <ReshapeAliasBackward0 object at 0x177dc9f40>: [<ExpandBackward0 object at 0x177dc00d0>], <SliceBackward0 object at 0x177dc9f70>: [<ViewBackward0 object at 0x177dc0100>], <SelectBackward0 object at 0x177dc9fa0>: [<SliceBackward0 object at 0x177dc0130>], <SelectBackward0 object at 0x177dc9fd0>: [<SliceBackward0 object at 0x177dc0160>], <AccumulateGrad object at 0x177dc0040>: [], <TBackward0 object at 0x177dc0070>: [<AccumulateGrad object at 0x177dc0190>], <ExpandBackward0 object at 0x177dc00a0>: [<PermuteBackward0 object at 0x177dc01c0>], <ExpandBackward0 object at 0x177dc00d0>: [<PermuteBackward0 object at 0x177dc01f0>], <ViewBackward0 object at 0x177dc0100>: [<ViewBackward0 object at 0x177dc0220>], <SliceBackward0 object at 0x177dc0130>: [<SliceBackward0 object at 0x177dc0250>], <SliceBackward0 object at 0x177dc0160>: [<SliceBackward0 object at 0x177dc0280>], <AccumulateGrad object at 0x177dc0190>: [], <PermuteBackward0 object at 0x177dc01c0>: [<SliceBackward0 object at 0x177dc02b0>], <PermuteBackward0 object at 0x177dc01f0>: [<SliceBackward0 object at 0x177dc02e0>], <ViewBackward0 object at 0x177dc0220>: [<torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430b40>], <SliceBackward0 object at 0x177dc0250>: [<ViewBackward0 object at 0x177dc9b50>], <SliceBackward0 object at 0x177dc0280>: [<ViewBackward0 object at 0x177dc9b50>], <SliceBackward0 object at 0x177dc02b0>: [<SliceBackward0 object at 0x177dc0310>], <SliceBackward0 object at 0x177dc02e0>: [<SliceBackward0 object at 0x177dc0340>], <torch.autograd.function.IndexPutFirstAxisBackward object at 0x177430b40>: [<AddmmBackward0 object at 0x177dc0370>, None], <SliceBackward0 object at 0x177dc0310>: [<SelectBackward0 object at 0x177dc03a0>], <SliceBackward0 object at 0x177dc0340>: [<SelectBackward0 object at 0x177dc03d0>], <AddmmBackward0 object at 0x177dc0370>: [<AccumulateGrad object at 0x177dc0400>, <torch.autograd.function.IndexFirstAxisBackward object at 0x1773b8e40>, <TBackward0 object at 0x177dc0430>], <SelectBackward0 object at 0x177dc03a0>: [<SliceBackward0 object at 0x177dc0460>], <SelectBackward0 object at 0x177dc03d0>: [<SliceBackward0 object at 0x177dc0490>], <AccumulateGrad object at 0x177dc0400>: [], <TBackward0 object at 0x177dc0430>: [<AccumulateGrad object at 0x177dc04c0>], <SliceBackward0 object at 0x177dc0460>: [<SliceBackward0 object at 0x177dc04f0>], <SliceBackward0 object at 0x177dc0490>: [<SliceBackward0 object at 0x177dc0520>], <AccumulateGrad object at 0x177dc04c0>: [], <SliceBackward0 object at 0x177dc04f0>: [<ViewBackward0 object at 0x177dc0100>], <SliceBackward0 object at 0x177dc0520>: [<ViewBackward0 object at 0x177dc0100>]}\n"
     ]
    }
   ],
   "source": [
    "for k, v in list(in_adj.items()):\n",
    "    if k == \"AddMmBackward0\" or \"AddMmBackward0\" in v:\n",
    "        print(k, v)\n",
    "print(out_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22ad4bb0-b096-4fa0-ab69-6fc7d0f5c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 768)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited[-137]._saved_self_sym_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b9840b0-c76e-406b-aae4-ac09696f1ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([768, 768]),\n",
       " torch.Size([2304, 768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([2304]),\n",
       " torch.Size([2304, 768]),\n",
       " torch.Size([2304]),\n",
       " torch.Size([2304, 768]),\n",
       " torch.Size([2304]),\n",
       " torch.Size([2304, 768])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ acc.variable.shape for acc in visited[-10:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8529ba4e-295a-42b7-b94f-839e0af7436d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_input_metadata',\n",
       " '_raw_saved_mat1',\n",
       " '_raw_saved_mat2',\n",
       " '_register_hook_dict',\n",
       " '_saved_alpha',\n",
       " '_saved_beta',\n",
       " '_saved_mat1',\n",
       " '_saved_mat1_sym_sizes',\n",
       " '_saved_mat1_sym_strides',\n",
       " '_saved_mat2',\n",
       " '_saved_mat2_sym_sizes',\n",
       " '_saved_mat2_sym_strides',\n",
       " '_sequence_nr',\n",
       " '_set_sequence_nr',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'next_functions',\n",
       " 'register_hook',\n",
       " 'register_prehook',\n",
       " 'requires_grad']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visited[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a8c0415-fe5d-4a32-a933-82cc69fed2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18446744073709551615"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8565c-7fca-43dc-b6be-015cf0bf1259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f620ab94-4522-4f70-802f-234f15583ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 3072 9223372036854775807\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "1 0 3072\n",
      "1 3072 9223372036854775807\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "for fcn in visited:\n",
    "    if fcn.name() == \"SliceBackward0\" and not (fcn._saved_start == 0 and fcn._saved_end == 9223372036854775807):\n",
    "        print(fcn._saved_dim, fcn._saved_start, fcn._saved_end)\n",
    "print(len([ fcn for fcn in visited if fcn.name() == \"SliceBackward0\" ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "59e14e31-cfe9-40b5-a9ad-ac8380c606bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_input_metadata',\n",
       " '_register_hook_dict',\n",
       " '_saved_dim',\n",
       " '_saved_end',\n",
       " '_saved_self_sym_sizes',\n",
       " '_saved_start',\n",
       " '_saved_step',\n",
       " '_sequence_nr',\n",
       " '_set_sequence_nr',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'next_functions',\n",
       " 'register_hook',\n",
       " 'register_prehook',\n",
       " 'requires_grad']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visited[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4e7f0bb6-6b3b-492b-ba9b-0e9f94b00ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited[3]._saved_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b4122ca7-6985-429f-ab55-5ca4f2a31833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1706, 0.8294])\n",
      "((<AccumulateGrad object at 0x17a75efa0>, 0), (<AddBackward0 object at 0x130051940>, 0))\n",
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_input_metadata', '_register_hook_dict', '_saved_alpha', '_sequence_nr', '_set_sequence_nr', 'metadata', 'name', 'next_functions', 'register_hook', 'register_prehook', 'requires_grad']\n",
      "<AddBackward0 object at 0x13005a940>\n",
      "((<AddBackward0 object at 0x1300111f0>, 0), (None, 0))\n",
      "True\n",
      "((<AccumulateGrad object at 0x1300111f0>, 0), (<MulBackward0 object at 0x13005a940>, 0))\n",
      "None\n",
      "((<AccumulateGrad object at 0x1300111f0>, 0), (None, 0))\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, requires_grad=True)\n",
    "b = a*(a + a * 2 + 2)\n",
    "multa = b.grad_fn._saved_self\n",
    "multb = b.grad_fn._saved_other\n",
    "with torch.no_grad():\n",
    "    print(torch.concat((multa, multb)) / (multa + multb))\n",
    "print (b.grad_fn.next_functions)\n",
    "print(dir(b.grad_fn.next_functions[1][0]))\n",
    "print(b.grad_fn.next_functions[1][0])\n",
    "print (b.grad_fn.next_functions[1][0].next_functions)\n",
    "print (b.grad_fn.next_functions[0][0].variable is a)\n",
    "print(b.grad_fn.next_functions[1][0].next_functions[0][0].next_functions)\n",
    "print(b.grad_fn.next_functions[1][0].next_functions[0][0].next_functions[1][0]._saved_self)\n",
    "print(b.grad_fn.next_functions[1][0].next_functions[0][0].next_functions[1][0].next_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0d56d-0b51-4304-8145-5833989505d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
