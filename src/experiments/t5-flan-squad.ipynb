{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effc13ad-3923-43c2-a281-99fe874d6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ea4b81-207f-498e-bf39-3e0b642fac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f898b49-8c2e-43d7-b00d-3cbc1e45e9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb114dd6-78de-4545-9a6b-ac7ffec350b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646ac862-b49d-4e15-893a-98935ee11716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f131d971-27c2-4025-8bed-6d5fc7dd5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f737a19a-6c58-4d0a-ae89-776997d7db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flan_encode_decode(input_ids):\n",
    "    encoder_outputs = model.encoder(input_ids)\n",
    "    decoder_input_ids = torch.tensor([[tokenizer.pad_token_id]]).to(device)\n",
    "    return model.decoder(\n",
    "        input_ids=decoder_input_ids,\n",
    "        encoder_hidden_states=encoder_outputs.last_hidden_state,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4cdb3e8-9ec9-491a-8e89-dc18d03438d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrp_engine import LRPEngine, checkpoint_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d37b2c66-dbc5-4267-9353-a09d5fa025be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp = LRPEngine(use_gamma=True, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a992a89-ce8e-4164-88a4-89ace02b1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"'Welcome to the final examination for this term's offering of CS100. Please remove all headphones and earbuds, as well as hats and hoods. Place your bag under your desk so that it does not block the aisle. You are permitted writing instruments, a clear water bottle, and any aids listed on the front of your booklet. The exam will be 150 minutes in duration. You may now begin.' How long is the exam?\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd323abd-c65a-464e-af55-edae833948e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = run_flan_encode_decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd502368-92eb-41eb-9fc0-00ca29072bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "_, param_vals = lrp.run(decoder_outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "525a8bc2-3bcd-426e-b21c-d957b0a1a2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "_, param_vals1 = lrp.run(decoder_outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a48096-8478-4d73-9942-968b40c8032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.3235e-23, device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(2.5394e-20, device='cuda:0'),\n",
       " tensor(3.4245e-20, device='cuda:0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results diff between 1st pass and 2nd pass on same input (should be ~0)\n",
    "[\n",
    "    ((p1 - p0)**2).sum() for p1, p0 in zip(param_vals1, param_vals)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ad7c4fd-2caa-4306-8c5c-a2fc0fe4ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1]),\n",
       " torch.Size([1, 1]),\n",
       " torch.Size([1, 103]),\n",
       " torch.Size([103, 103])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ t.shape for t in param_vals ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5911e1da-825e-46cd-801e-8e491e5a8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 exam minutes duration long\n",
      "torch.return_types.topk(\n",
      "values=tensor([[3.4523e-04, 1.2875e-04, 1.2493e-04, 7.6294e-05, 7.2002e-05]],\n",
      "       device='cuda:0'),\n",
      "indices=tensor([[85, 82, 86, 88, 97]], device='cuda:0'))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(param_vals1[2].float().cpu(), cmap=\"jet\")\n",
    "\n",
    "print(tokenizer.decode(input_ids[0][param_vals1[2].float().topk(5).indices][0]))\n",
    "print(param_vals1[2].float().topk(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0458446d-3d32-4713-9812-334084cc21bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37ef199e-7324-4af3-b832-c40720ee0ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for example in dataset[\"validation\"].select(range(100)):\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = example[\"answers\"][\"text\"]\n",
    "\n",
    "    input_ids = tokenizer(context + \" \" + question, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    if input_ids.shape[-1] > max_length:\n",
    "        max_length = input_ids.shape[-1]\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b0f736f-5a72-4800-9b4e-457d0a08c6eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                            | 217/11873 [01:07<48:39,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                          | 239/11873 [01:15<1:01:26,  3.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     19\u001b[39m output = run_flan_encode_decode(input_ids)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m _, param_vals = \u001b[43mlrp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m lrp_max = param_vals[\u001b[32m2\u001b[39m].flatten().argmax()\n\u001b[32m     24\u001b[39m lrp_top_token = tokenizer.convert_ids_to_tokens([input_ids[\u001b[32m0\u001b[39m][lrp_max]])[\u001b[32m0\u001b[39m].strip().replace(\u001b[38;5;28mchr\u001b[39m(\u001b[32m9601\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Programming\\research\\lrp\\src\\experiments\\..\\lrp_engine\\lrp.py:208\u001b[39m, in \u001b[36mLRPEngine.run\u001b[39m\u001b[34m(self, output_tuple_or_tensor)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28mself\u001b[39m.promise_bucket.clear_all()\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_lrp_subsequent_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_tuple_or_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPropagation took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Programming\\research\\lrp\\src\\experiments\\..\\lrp_engine\\lrp.py:708\u001b[39m, in \u001b[36mLRPEngine._run_lrp_subsequent_pass\u001b[39m\u001b[34m(self, root_nodes, starting_relevances)\u001b[39m\n\u001b[32m    705\u001b[39m     input_frontier[root.metadata[\u001b[33m\"\u001b[39m\u001b[33mtopo_ind\u001b[39m\u001b[33m\"\u001b[39m]] = {\u001b[32m0\u001b[39m: sr}\n\u001b[32m    707\u001b[39m \u001b[38;5;66;03m# First pre-process all Promises by updating the starting fwd_shapes and setting every leaf Promise arg\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m \u001b[43mpromise_bucket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_all_starting_fwd_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecompile\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mno_recompile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m leaf_promise: Promise\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m leaf_promise \u001b[38;5;129;01min\u001b[39;00m promise_bucket.leaf_promises:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Programming\\research\\lrp\\src\\experiments\\..\\lrp_engine\\promises\\promise.py:94\u001b[39m, in \u001b[36mPromiseBucket.update_all_starting_fwd_shapes\u001b[39m\u001b[34m(self, recompile)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     92\u001b[39m     curr_promise.fwd_shape = node._input_metadata[\u001b[32m0\u001b[39m].shape\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m curr_promise.set_rout(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_input_metadata\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurr_promise\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurr_promise\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPromiseBucket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_grad\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(curr_promise, \u001b[33m\"\u001b[39m\u001b[33mrefresh_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     97\u001b[39m     curr_promise.refresh_metadata(node)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "top1_hits = 0\n",
    "total_examples = 0\n",
    "\n",
    "for example in tqdm(dataset[\"validation\"]):\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = example[\"answers\"][\"text\"]\n",
    "\n",
    "    if not answers:\n",
    "        continue\n",
    "\n",
    "    input_ids = tokenizer(context + \" \" + question, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    if input_ids.shape[-1] > 512:\n",
    "        continue\n",
    "    \n",
    "    output = run_flan_encode_decode(input_ids)\n",
    "\n",
    "    _, param_vals = lrp.run(output.last_hidden_state)\n",
    "\n",
    "    lrp_max = param_vals[2].flatten().argmax()\n",
    "    lrp_top_token = tokenizer.convert_ids_to_tokens([input_ids[0][lrp_max]])[0].strip().replace(chr(9601), \"\")\n",
    "\n",
    "    if any(lrp_top_token in ans for ans in answers):\n",
    "        top1_hits += 1\n",
    "    total_examples += 1\n",
    "    if not (total_examples % 100):\n",
    "        print(top1_hits, total_examples)\n",
    "    # lrp_top5 = param_vals[2].flatten().topk(k=5)\n",
    "    # lrp_top5_tokens = tokenizer.decode(input_ids[0][lrp_top5.indices.cpu()])\n",
    "    # results.append({\n",
    "    #     \"example\": example,\n",
    "    #     \"lrp_top5_tokens\": lrp_top5_tokens,\n",
    "    #     \"lrp_top5_relevances\": lrp_top5.values.cpu(),\n",
    "    #     \"is_impossible\": len(answers) == 0\n",
    "    # })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10f58544-b02b-477d-97ba-9710a1849d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  In what country is Normandy located?\n",
      "A (labels):  ['France', 'France', 'France', 'France']\n",
      "LRP top5:  France, region Norman country\n",
      "LRP top5 attributions:  tensor([1.1452e-04, 4.3845e-05, 2.9287e-05, 1.8449e-05, 1.2439e-05]) \n",
      "\n",
      "Q:  When were the Normans in Normandy?\n",
      "A (labels):  ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries', '10th and 11th centuries']\n",
      "LRP top5:  10 first 10 people 11\n",
      "LRP top5 attributions:  tensor([3.3029e-05, 2.2602e-05, 1.4791e-05, 1.1537e-05, 8.8099e-06]) \n",
      "\n",
      "Q:  From which countries did the Norse originate?\n",
      "A (labels):  ['Denmark, Iceland and Norway', 'Denmark, Iceland and Norway', 'Denmark, Iceland and Norway', 'Denmark, Iceland and Norway']\n",
      "LRP top5:  ers from raid,.\n",
      "LRP top5 attributions:  tensor([5.3515e-05, 3.5023e-05, 8.7190e-06, 7.8946e-06, 6.2662e-06]) \n",
      "\n",
      "Q:  Who was the Norse leader?\n",
      "A (labels):  ['Rollo', 'Rollo', 'Rollo', 'Rollo']\n",
      "LRP top5:  Roll Iceland pirate leader,\n",
      "LRP top5 attributions:  tensor([1.1889e-04, 6.5455e-05, 1.8594e-05, 1.1123e-05, 5.1003e-06]) \n",
      "\n",
      "Q:  What century did the Normans first gain their separate identity?\n",
      "A (labels):  ['10th century', 'the first half of the 10th century', '10th', '10th']\n",
      "LRP top5:  Norman century 10 Norman century\n",
      "LRP top5 attributions:  tensor([3.9687e-04, 6.7869e-05, 6.1402e-05, 3.3645e-05, 2.9693e-05]) \n",
      "\n",
      "Q:  Who gave their name to Normandy in the 1000's and 1100's\n",
      "A (labels):  []\n",
      "LRP top5:  peoples Norman raid 1000\n",
      "LRP top5 attributions:  tensor([1.7367e-05, 1.3892e-05, 9.1053e-06, 8.2326e-06, 6.2282e-06]) \n",
      "\n",
      "Q:  What is France a region of?\n",
      "A (labels):  []\n",
      "LRP top5:  France in West of Iceland\n",
      "LRP top5 attributions:  tensor([4.9447e-05, 2.6198e-05, 1.3629e-05, 1.0544e-05, 9.2953e-06]) \n",
      "\n",
      "Q:  Who did King Charles III swear fealty to?\n",
      "A (labels):  []\n",
      "LRP top5:  Roll raid Norman Charles pirate\n",
      "LRP top5 attributions:  tensor([2.9787e-05, 1.1713e-05, 8.0779e-06, 7.5693e-06, 7.1644e-06]) \n",
      "\n",
      "Q:  When did the Frankish identity emerge?\n",
      "A (labels):  []\n",
      "LRP top5:  ish first Romanish the\n",
      "LRP top5 attributions:  tensor([2.2297e-03, 2.2051e-05, 1.6764e-05, 1.5788e-05, 1.5363e-05]) \n",
      "\n",
      "Q:  Who was the duke in the battle of Hastings?\n",
      "A (labels):  ['William the Conqueror', 'William the Conqueror', 'William the Conqueror']\n",
      "LRP top5:  William their Norman Normanke\n",
      "LRP top5 attributions:  tensor([1.1542e-04, 9.7030e-06, 7.0516e-06, 6.8250e-06, 6.2263e-06]) \n",
      "\n",
      "Q:  Who ruled the duchy of Normandy\n",
      "A (labels):  ['Richard I', 'Richard I', 'Richard I']\n",
      "LRP top5:  Norman The sdyna\n",
      "LRP top5 attributions:  tensor([nan, nan, nan, nan, nan]) \n",
      "\n",
      "Q:  What religion were the Normans\n",
      "A (labels):  ['Catholic', 'Catholic orthodoxy', 'Catholic']\n",
      "LRP top5:  Norman Norman Christian Norman Catholic\n",
      "LRP top5 attributions:  tensor([1.1468e-04, 9.8812e-05, 6.4570e-05, 1.3990e-05, 1.0023e-05]) \n",
      "\n",
      "Q:  What type of major impact did the Norman dynasty have on modern Europe?\n",
      "A (labels):  []\n",
      "LRP top5:  political majory founded modern\n",
      "LRP top5 attributions:  tensor([3.4577e-05, 1.9907e-05, 1.3250e-05, 1.1122e-05, 8.5969e-06]) \n",
      "\n",
      "Q:  Who was famed for their Christian spirit?\n",
      "A (labels):  []\n",
      "LRP top5:  Christians. Norman were\n",
      "LRP top5 attributions:  tensor([4.0367e-05, 1.0474e-05, 8.2806e-06, 6.1933e-06, 5.2981e-06]) \n",
      "\n",
      "Q:  Who assimilted the Roman language?\n",
      "A (labels):  []\n",
      "LRP top5:  . The principal Norman Catholic\n",
      "LRP top5 attributions:  tensor([1.6054e-04, 2.8529e-05, 1.9687e-05, 1.7634e-05, 9.9805e-06]) \n",
      "\n",
      "Q:  Who ruled the country of Normandy?\n",
      "A (labels):  []\n",
      "LRP top5:  Richard country French Norman Norman\n",
      "LRP top5 attributions:  tensor([8.0214e-05, 2.5171e-05, 1.5523e-05, 1.5394e-05, 1.5062e-05]) \n",
      "\n",
      "Q:  What principality did William the conquerer found?\n",
      "A (labels):  []\n",
      "LRP top5:  Kingdom Principal found Bo Anti\n",
      "LRP top5 attributions:  tensor([2.7727e-05, 2.3762e-05, 1.7932e-05, 1.3748e-05, 1.1302e-05]) \n",
      "\n",
      "Q:  What is the original meaning of the word Norman?\n",
      "A (labels):  ['Viking', 'Norseman, Viking', 'Norseman, Viking']\n",
      "LRP top5:  meaning plural \" NormanNorth\n",
      "LRP top5 attributions:  tensor([3.3955e-05, 2.2024e-05, 2.1805e-05, 1.5221e-05, 1.3931e-05]) \n",
      "\n",
      "Q:  When was the Latin version of the word Norman first recorded?\n",
      "A (labels):  ['9th century', '9th century', '9th century']\n",
      "LRP top5:  9 century, in Medi\n",
      "LRP top5 attributions:  tensor([9.9535e-05, 2.4819e-05, 2.3688e-05, 1.9748e-05, 1.9604e-05]) \n",
      "\n",
      "Q:  What name comes from the English words Normans/Normanz?\n",
      "A (labels):  []\n",
      "LRP top5:  ans normNorm comes Nord\n",
      "LRP top5 attributions:  tensor([1.7903e-05, 1.5811e-05, 1.4444e-05, 1.2369e-05, 9.9533e-06]) \n",
      "\n",
      "Q:  When was the French version of the word Norman first recorded?\n",
      "A (labels):  []\n",
      "LRP top5:  9) Latin Norman Latin\n",
      "LRP top5 attributions:  tensor([7.9399e-05, 1.4488e-05, 1.4468e-05, 1.3139e-05, 1.0536e-05]) \n",
      "\n",
      "Q:  When was the Duchy of Normandy founded?\n",
      "A (labels):  ['911', '911', '911']\n",
      "LRP top5:  911.). between Du\n",
      "LRP top5 attributions:  tensor([2.8649e-05, 1.4057e-05, 5.4778e-06, 5.4130e-06, 5.0573e-06]) \n",
      "\n",
      "Q:  Who did Rollo sign the treaty of Saint-Clair-sur-Epte with?\n",
      "A (labels):  ['King Charles III', 'King Charles III', 'King Charles III']\n",
      "LRP top5:  King established Charles). treat\n",
      "LRP top5 attributions:  tensor([7.4612e-05, 2.2457e-05, 1.7515e-05, 1.2986e-05, 1.2966e-05]) \n",
      "\n",
      "Q:  What river originally bounded the Duchy\n",
      "A (labels):  ['Seine', 'Epte', 'Seine']\n",
      "LRP top5:  present river river river Atlantic\n",
      "LRP top5 attributions:  tensor([3.1022e-05, 1.8724e-05, 1.3985e-05, 9.9750e-06, 9.8838e-06]) \n",
      "\n",
      "Q:  when did Nors encampments ivolve into destructive incursions?\n",
      "A (labels):  []\n",
      "LRP top5:  s course incur In 10\n",
      "LRP top5 attributions:  tensor([1.0475e-04, 3.2440e-05, 2.2683e-05, 1.9162e-05, 1.7656e-05]) \n",
      "\n",
      "Q:  What treaty was established in the 9th century?\n",
      "A (labels):  []\n",
      "LRP top5:  y treat What Saint Nor\n",
      "LRP top5 attributions:  tensor([2.8659e-05, 2.7266e-05, 2.4282e-05, 2.1029e-05, 1.9651e-05]) \n",
      "\n",
      "Q:  Who established a treaty with King Charles the third of France?\n",
      "A (labels):  []\n",
      "LRP top5:  Roll). Roll and King\n",
      "LRP top5 attributions:  tensor([2.5785e-05, 1.8483e-05, 1.1929e-05, 8.3157e-06, 5.7757e-06]) \n",
      "\n",
      "Q:  What did the French promises to protect Rollo and his men from?\n",
      "A (labels):  []\n",
      "LRP top5:  Upper Viking against offered French\n",
      "LRP top5 attributions:  tensor([6.2741e-05, 5.7747e-05, 3.8088e-05, 1.0902e-05, 7.6969e-06]) \n",
      "\n",
      "Q:  Who upon arriving gave the original viking settlers a common identity?\n",
      "A (labels):  ['Rollo', 'Rollo', 'Rollo']\n",
      "LRP top5:  Rollpag Roll Dan An\n",
      "LRP top5 attributions:  tensor([6.0344e-05, 4.2495e-05, 4.0828e-05, 2.0155e-05, 9.4156e-06]) \n",
      "\n",
      "Q:  When did Rollo begin to arrive in Normandy?\n",
      "A (labels):  []\n",
      "LRP top5:  880ss.\n",
      "LRP top5 attributions:  tensor([5.9744e-05, 3.5962e-05, 2.7566e-05, 1.4551e-05, 1.3213e-05]) \n",
      "\n",
      "Q:  What Viking groups were conquered by Rollo?\n",
      "A (labels):  []\n",
      "LRP top5:  ultimately Norman Or Dan Viking\n",
      "LRP top5 attributions:  tensor([2.1433e-05, 2.0597e-05, 1.8371e-05, 1.7435e-05, 1.4577e-05]) \n",
      "\n",
      "Q:  What was the Norman religion?\n",
      "A (labels):  ['Catholicism', 'Catholicism', 'Catholicism']\n",
      "LRP top5:  FranceChristian Catholic Norman of\n",
      "LRP top5 attributions:  tensor([1.0584e-04, 3.9060e-05, 2.3877e-05, 1.0784e-05, 1.0212e-05]) \n",
      "\n",
      "Q:  What part of France were the Normans located?\n",
      "A (labels):  ['north', 'the north', 'north']\n",
      "LRP top5:  north Norman ins France\n",
      "LRP top5 attributions:  tensor([1.6410e-04, 8.1701e-06, 7.4245e-06, 6.6969e-06, 5.5966e-06]) \n",
      "\n",
      "Q:  What was replace with the Norse religion?\n",
      "A (labels):  []\n",
      "LRP top5:  .Christian synth Catholic Old\n",
      "LRP top5 attributions:  tensor([2.8570e-05, 2.3177e-05, 2.0968e-05, 1.5615e-05, 1.0194e-05]) \n",
      "\n",
      "Q:  What did maternal Old Norse traditions merge with?\n",
      "A (labels):  []\n",
      "LRP top5:  descendantsblending Frank their heritage\n",
      "LRP top5 attributions:  tensor([8.6957e-05, 2.3987e-05, 1.9893e-05, 1.8136e-05, 8.3222e-06]) \n",
      "\n",
      "Q:  What language replaced the Gallo-Romance language?\n",
      "A (labels):  []\n",
      "LRP top5:  Nor language NorsChristian\n",
      "LRP top5 attributions:  tensor([2.9570e-05, 2.2323e-05, 1.7997e-05, 1.7452e-05, 1.2807e-05]) \n",
      "\n",
      "Q:  What was one of the Norman's major exports?\n",
      "A (labels):  ['fighting horsemen', 'fighting horsemen', 'fighting horsemen']\n",
      "LRP top5:  fighting export knight horse Norman\n",
      "LRP top5 attributions:  tensor([1.4631e-04, 1.0160e-04, 6.3787e-05, 5.3656e-05, 9.3054e-06]) \n",
      "\n",
      "Q:  Who adopted the fuedel doctrines of the Normans?\n",
      "A (labels):  []\n",
      "LRP top5:  rest Norman France Norman Who\n",
      "LRP top5 attributions:  tensor([5.0617e-05, 4.8225e-05, 2.8988e-05, 1.2231e-05, 7.2736e-06]) \n",
      "\n",
      "Q:  What was one of the Norman's major imports?\n",
      "A (labels):  []\n",
      "LRP top5:  Norman Thes adopted thereafter\n",
      "LRP top5 attributions:  tensor([nan, nan, nan, nan, nan]) \n",
      "\n",
      "Q:  Who's arristocracy eventually served as avid Crusaders?\n",
      "A (labels):  []\n",
      "LRP top5:  It old French Bo Carol\n",
      "LRP top5 attributions:  tensor([2.3045e-05, 2.0434e-05, 1.8295e-05, 1.4382e-05, 9.7261e-06]) \n",
      "\n",
      "Q:  Who was the Normans' main enemy in Italy, the Byzantine Empire and Armenia?\n",
      "A (labels):  ['Seljuk Turks', 'the Pechenegs, the Bulgars, and especially the Seljuk Turks', 'the Seljuk Turks']\n",
      "LRP top5:  Armenia Turk enemystine\n",
      "LRP top5 attributions:  tensor([4.4790e-05, 2.1889e-05, 2.1829e-05, 1.8397e-05, 1.1850e-05]) \n",
      "\n",
      "Q:  Who entered Italy soon after the Byzantine Empire?\n",
      "A (labels):  []\n",
      "LRP top5:  Empires Armenia Norman Norman\n",
      "LRP top5 attributions:  tensor([1.0000e-04, 1.3818e-05, 1.1115e-05, 8.8331e-06, 8.2964e-06]) \n",
      "\n",
      "Q:  Who did the Normans fight in Italy?\n",
      "A (labels):  []\n",
      "LRP top5:  sard against Pe Italy\n",
      "LRP top5 attributions:  tensor([8.4747e-05, 3.2144e-05, 1.6238e-05, 1.4462e-05, 8.8861e-06]) \n",
      "\n",
      "Q:  Who did the Normans encourage to come to the south?\n",
      "A (labels):  []\n",
      "LRP top5:  mer Lard by Sel\n",
      "LRP top5 attributions:  tensor([3.3048e-05, 2.8541e-05, 2.4252e-05, 1.6052e-05, 1.3140e-05]) \n",
      "\n",
      "Q:  During what campaign did the Vargian and Lombard fight?\n",
      "A (labels):  []\n",
      "LRP top5:  Sicil campaigni George fight\n",
      "LRP top5 attributions:  tensor([7.2058e-05, 1.6335e-05, 1.2278e-05, 1.1302e-05, 8.6887e-06]) \n",
      "\n",
      "Q:  When did Herve serve as a Byzantine general?\n",
      "A (labels):  ['1050s', 'in the 1050s', 'in the 1050s']\n",
      "LRP top5:  1050 10</s>Norman\n",
      "LRP top5 attributions:  tensor([3.9758e-05, 3.2823e-05, 1.7233e-05, 6.2331e-06, 4.6484e-06]) \n",
      "\n",
      "Q:  When did Robert Crispin go up against the Turks?\n",
      "A (labels):  ['1060s', 'In the 1060s', 'In the 1060s']\n",
      "LRP top5:  1060 Turk In 10\n",
      "LRP top5 attributions:  tensor([3.2331e-05, 2.6478e-05, 2.5857e-05, 1.6858e-05, 1.5591e-05]) \n",
      "\n",
      "Q:  Who ruined Roussel de Bailleul's plans for an independent state?\n",
      "A (labels):  ['Alexius Komnenos', 'Alexius Komnenos', 'Alexius Komnenos']\n",
      "LRP top5:  Alex general for Who By\n",
      "LRP top5 attributions:  tensor([1.1567e-04, 9.4693e-05, 3.7544e-05, 2.9327e-05, 2.5771e-05]) \n",
      "\n",
      "Q:  Who was the first Byzantine mercenary to serve with the Normans?\n",
      "A (labels):  []\n",
      "LRP top5:  Hercke general Rou\n",
      "LRP top5 attributions:  tensor([6.0974e-05, 4.9014e-05, 2.6948e-05, 2.4235e-05, 2.1819e-05]) \n",
      "\n",
      "Q:  When did Herve serve as a Norman general?\n",
      "A (labels):  []\n",
      "LRP top5:  50 10 Norman 10 Norman\n",
      "LRP top5 attributions:  tensor([2.4743e-05, 2.2460e-05, 8.4170e-06, 7.6512e-06, 5.1107e-06]) \n",
      "\n",
      "Q:  Who ruined Alexius Komnenos plans for an independent state?\n",
      "A (labels):  []\n",
      "LRP top5:  Rou theretine Who Norman\n",
      "LRP top5 attributions:  tensor([9.5659e-05, 1.9814e-05, 1.6052e-05, 1.4101e-05, 1.0324e-05]) \n",
      "\n",
      "Q:  When did Herve go up against the Turks?\n",
      "A (labels):  []\n",
      "LRP top5:  50 1060, In\n",
      "LRP top5 attributions:  tensor([1.4708e-05, 9.9911e-06, 9.7856e-06, 5.6735e-06, 5.6048e-06]) \n",
      "\n",
      "Q:  What was the name of the Norman castle?\n",
      "A (labels):  ['Afranji', 'Afranji', 'Afranji']\n",
      "LRP top5:  Afran Norman Normand\n",
      "LRP top5 attributions:  tensor([8.5377e-05, 1.2387e-05, 1.0959e-05, 1.0221e-05, 8.4037e-06]) \n",
      "\n",
      "Q:  Who was the leader when the Franks entered the Euphrates valley?\n",
      "A (labels):  ['Oursel', 'Oursel', 'Oursel']\n",
      "LRP top5:  A Our Norman Our Frank\n",
      "LRP top5 attributions:  tensor([3.4495e-05, 1.4372e-05, 1.4017e-05, 1.0635e-05, 9.0749e-06]) \n",
      "\n",
      "Q:  Who did the Normans team up with in Anatolia?\n",
      "A (labels):  ['Turkish forces', 'Turkish forces', 'Turkish forces']\n",
      "LRP top5:  Norman Somes Turkish joined\n",
      "LRP top5 attributions:  tensor([nan, nan, nan, nan, nan]) \n",
      "\n",
      "Q:  Who joined Norman forces in the destruction of the Armenians?\n",
      "A (labels):  []\n",
      "LRP top5:  Turkish forcess joined Norman\n",
      "LRP top5 attributions:  tensor([9.8545e-05, 9.3485e-06, 8.7114e-06, 7.5712e-06, 7.1735e-06]) \n",
      "\n",
      "Q:  Who did the Turks take up service with?\n",
      "A (labels):  []\n",
      "LRP top5:  of Armenia Turkn Armenia\n",
      "LRP top5 attributions:  tensor([4.5222e-05, 4.1187e-05, 2.1017e-05, 1.4752e-05, 1.3300e-05]) \n",
      "\n",
      "Q:  What Frank led Norman forces?\n",
      "A (labels):  []\n",
      "LRP top5:  Our A Norman Ourrank\n",
      "LRP top5 attributions:  tensor([3.7785e-05, 2.2068e-05, 1.3062e-05, 8.4237e-06, 6.7595e-06]) \n",
      "\n",
      "Q:  Where did Oursel lead the Franks?\n",
      "A (labels):  []\n",
      "LRP top5:  upper Norman into Eu Ana\n",
      "LRP top5 attributions:  tensor([1.1636e-04, 3.6603e-05, 3.4489e-05, 2.9854e-05, 2.2482e-05]) \n",
      "\n",
      "Q:  What were the origins of the Raouliii family?\n",
      "A (labels):  ['Norman mercenary', 'an Italo-Norman named Raoul', 'descended from an Italo-Norman named Raoul']\n",
      "LRP top5:  Norman It Normanoul.\n",
      "LRP top5 attributions:  tensor([4.0366e-05, 3.1016e-05, 2.7427e-05, 2.4209e-05, 2.3920e-05]) \n",
      "\n",
      "Q:  Where were several Norman mercenary familes originate from?\n",
      "A (labels):  []\n",
      "LRP top5:  Byzan Norman western Greece\n",
      "LRP top5 attributions:  tensor([9.7636e-05, 6.4136e-05, 2.8203e-05, 2.2794e-05, 2.1195e-05]) \n",
      "\n",
      "Q:  Who did the Normans serve under in the 10th century?\n",
      "A (labels):  []\n",
      "LRP top5:  George when Who Norman Sicil\n",
      "LRP top5 attributions:  tensor([3.0888e-05, 2.3299e-05, 1.5005e-05, 9.6462e-06, 8.0977e-06]) \n",
      "\n",
      "Q:  What expedition did George Maniaces lead in the 10th century?\n",
      "A (labels):  []\n",
      "LRP top5:  Several  families By of\n",
      "LRP top5 attributions:  tensor([nan, nan, nan, nan, nan]) \n",
      "\n",
      "Q:  What was the name of the count of Apulia \n",
      "A (labels):  ['Robert Guiscard', 'Robert Guiscard', 'Robert Guiscard']\n",
      "LRP top5:  Robert Robert Gregory name Norman\n",
      "LRP top5 attributions:  tensor([5.4786e-05, 2.1330e-05, 1.8692e-05, 1.6649e-05, 1.5797e-05]) \n",
      "\n",
      "Q:  When did Dyrrachium  fall to the Normans?\n",
      "A (labels):  ['1082', 'February 1082', 'February 1082']\n",
      "LRP top5:  in February82 Dy 10\n",
      "LRP top5 attributions:  tensor([6.3129e-05, 4.9523e-05, 2.1371e-05, 1.2512e-05, 1.0104e-05]) \n",
      "\n",
      "Q:  How many men were in Robert's army?\n",
      "A (labels):  ['30,000', '30,000', '30,000']\n",
      "LRP top5:  Gui Roberts,card\n",
      "LRP top5 attributions:  tensor([nan, nan, nan, nan, nan]) \n",
      "\n",
      "Q:  Who ultimatly drove the Byzantines out of Europe?\n",
      "A (labels):  []\n",
      "LRP top5:  Robert Robert southern ultimately Catholic\n",
      "LRP top5 attributions:  tensor([3.4651e-05, 2.4113e-05, 2.2873e-05, 1.9162e-05, 1.4831e-05]) \n",
      "\n",
      "Q:  What pope opposed Roberts campaign?\n",
      "A (labels):  []\n",
      "LRP top5:  Alex. Alex Norman local\n",
      "LRP top5 attributions:  tensor([2.5859e-05, 7.8853e-06, 7.0064e-06, 5.7196e-06, 4.6057e-06]) \n",
      "\n",
      "Q:  What fell to the Normans in the 10th century?\n",
      "A (labels):  []\n",
      "LRP top5:  dignityr Dy Dy Bal\n",
      "LRP top5 attributions:  tensor([3.4254e-04, 9.7741e-05, 1.4611e-05, 1.1613e-05, 6.1586e-06]) \n",
      "\n",
      "Q:  How many men did Roberts army face?\n",
      "A (labels):  []\n",
      "LRP top5:  Dy30,000? battle many\n",
      "LRP top5 attributions:  tensor([1.7102e-05, 1.0832e-05, 6.4065e-06, 5.8806e-06, 4.5221e-06]) \n",
      "\n",
      "Q:  Where did the Normans and Byzantines sign the peace treaty?\n",
      "A (labels):  ['Deabolis', 'Deabolis', 'Deabolis']\n",
      "LRP top5:  city De in De of\n",
      "LRP top5 attributions:  tensor([1.1002e-04, 6.9590e-05, 1.8366e-05, 1.1924e-05, 7.0985e-06]) \n",
      "\n",
      "Q:  Who was Robert's son?\n",
      "A (labels):  ['Bohemond', 'Bohemond', 'Bohemond']\n",
      "LRP top5:  Bo By, Bo Norman\n",
      "LRP top5 attributions:  tensor([1.2499e-04, 6.0780e-05, 3.9101e-05, 2.9266e-05, 1.0951e-05]) \n",
      "\n",
      "Q:  What river was Petrela located by?\n",
      "A (labels):  ['Deabolis', 'the river Deabolis', 'Deabolis']\n",
      "LRP top5:  Kan river river De at\n",
      "LRP top5 attributions:  tensor([4.2056e-04, 8.0514e-05, 5.7069e-05, 5.4952e-05, 2.8769e-05]) \n",
      "\n",
      "Q:  Who did the Normans besiege in the 11th century?\n",
      "A (labels):  []\n",
      "LRP top5:  rach Norman Dyged,\n",
      "LRP top5 attributions:  tensor([1.0468e-04, 1.8649e-05, 1.8594e-05, 1.6963e-05, 1.3292e-05]) \n",
      "\n",
      "Q:  Who did Robert lead agains Dyrrachium in 1107?\n",
      "A (labels):  []\n",
      "LRP top5:  Bo Norman.ium lead\n",
      "LRP top5 attributions:  tensor([2.0773e-05, 1.9686e-05, 1.2302e-05, 6.7620e-06, 6.2277e-06]) \n",
      "\n",
      "Q:  Who was Bohemond's son?\n",
      "A (labels):  []\n",
      "LRP top5:  Robert Norman</s>' Norman\n",
      "LRP top5 attributions:  tensor([9.9193e-05, 1.5951e-05, 1.0210e-05, 6.4978e-06, 5.9980e-06]) \n",
      "\n",
      "Q:  When did the Normans attack Dyrrachium?\n",
      "A (labels):  ['1185', 'in 1185', '1185']\n",
      "LRP top5:  85 11 in Norman Norman\n",
      "LRP top5 attributions:  tensor([5.8760e-05, 3.0598e-05, 2.2972e-05, 1.9851e-05, 1.6814e-05]) \n",
      "\n",
      "Q:  What was the naval base called?\n",
      "A (labels):  ['Dyrrachium', 'Dyrrachium', 'Dyrrachium']\n",
      "LRP top5:  Dy Dyzan important By\n",
      "LRP top5 attributions:  tensor([6.9338e-05, 4.1320e-05, 2.3751e-05, 1.5848e-05, 1.2028e-05]) \n",
      "\n",
      "Q:  Where was Dyrrachium located?\n",
      "A (labels):  ['the Adriatic', 'the Adriatic', 'Adriatic']\n",
      "LRP top5:  Adrioneatic naval of\n",
      "LRP top5 attributions:  tensor([2.0766e-04, 4.2400e-05, 3.4806e-05, 1.6885e-05, 1.3392e-05]) \n",
      "\n",
      "Q:  Who attacked Dyrrachium in the 11th century?\n",
      "A (labels):  []\n",
      "LRP top5:  highiumtine Byzan\n",
      "LRP top5 attributions:  tensor([3.3560e-05, 2.5490e-05, 2.1368e-05, 1.5840e-05, 1.4299e-05]) \n",
      "\n",
      "Q:  Who betrayed the Normans?\n",
      "A (labels):  []\n",
      "LRP top5:  high By be Byray\n",
      "LRP top5 attributions:  tensor([1.3114e-04, 1.7849e-05, 1.6033e-05, 6.6896e-06, 5.1818e-06]) \n",
      "\n",
      "Q:  What naval base fell to the Normans?\n",
      "A (labels):  []\n",
      "LRP top5:  Dy Norman 11l Adri\n",
      "LRP top5 attributions:  tensor([2.8740e-05, 2.5215e-05, 2.4808e-05, 2.2636e-05, 1.7075e-05]) \n",
      "\n",
      "Q:  Who did Emma Marry?\n",
      "A (labels):  ['King Ethelred II', 'Ethelred II', 'King Ethelred II']\n",
      "LRP top5:  Norman Thes in were\n",
      "LRP top5 attributions:  tensor([nan, nan, nan, nan, nan]) \n",
      "\n",
      "Q:  Who was Emma's brother?\n",
      "A (labels):  ['Duke Richard II', 'Duke Richard II', 'Duke Richard II']\n",
      "LRP top5:  Richard Duke? brother Norman\n",
      "LRP top5 attributions:  tensor([5.2776e-05, 2.6595e-05, 1.7175e-05, 1.6415e-05, 9.5203e-06]) \n",
      "\n",
      "Q:  To where did Ethelred flee?\n",
      "A (labels):  ['Normandy', 'Normandy', 'Normandy']\n",
      "LRP top5:  to Norman Norman kingdom Norman\n",
      "LRP top5 attributions:  tensor([4.2153e-05, 3.1874e-05, 2.1200e-05, 1.8526e-05, 1.6192e-05]) \n",
      "\n",
      "Q:  Who kicked Ethelred out?\n",
      "A (labels):  ['Sweyn Forkbeard', 'Sweyn Forkbeard', 'Sweyn Forkbeard']\n",
      "LRP top5:  Sw by kingdom forced.\n",
      "LRP top5 attributions:  tensor([1.0200e-04, 1.5141e-05, 9.5604e-06, 4.4269e-06, 3.2448e-06]) \n",
      "\n",
      "Q:  Who married Cnut the Great?\n",
      "A (labels):  []\n",
      "LRP top5:  Emma E</s>ofle\n",
      "LRP top5 attributions:  tensor([2.6500e-05, 1.5869e-05, 9.3747e-06, 7.5729e-06, 7.4100e-06]) \n",
      "\n",
      "Q:  When did Richard II flee to Normandy?\n",
      "A (labels):  []\n",
      "LRP top5:  6) Richard sister? Emma\n",
      "LRP top5 attributions:  tensor([1.8059e-05, 1.2974e-05, 9.5478e-06, 8.0118e-06, 7.8376e-06]) \n",
      "\n",
      "Q:  Who's major ports were controlled by the English?\n",
      "A (labels):  []\n",
      "LRP top5:  Channel opposite Norman Englishred\n",
      "LRP top5 attributions:  tensor([2.5413e-05, 2.5261e-05, 2.0982e-05, 1.8250e-05, 1.2724e-05]) \n",
      "\n",
      "Q:  Who was Edward the Confessor's half-brother?\n",
      "A (labels):  ['Harthacnut', 'Harthacnut', 'Harthacnut']\n",
      "LRP top5:  Hart,' was half\n",
      "LRP top5 attributions:  tensor([9.9114e-05, 1.2303e-05, 1.1458e-05, 1.1120e-05, 9.0302e-06]) \n",
      "\n",
      "Q:  When did Edward return?\n",
      "A (labels):  ['1041', 'in 1041', '1041']\n",
      "LRP top5:  1041essor 10 finally\n",
      "LRP top5 attributions:  tensor([2.9813e-05, 2.3710e-05, 2.3254e-05, 1.8395e-05, 1.8262e-05]) \n",
      "\n",
      "Q:  Who did Edward make archbishop of Canterbury?\n",
      "A (labels):  ['Robert of Jumièges', 'Robert of Jumièges', 'Robert of Jumièges']\n",
      "LRP top5:  Robert Edwardm Edward of\n",
      "LRP top5 attributions:  tensor([1.3494e-04, 1.3409e-04, 1.1081e-05, 1.0127e-05, 9.4252e-06]) \n",
      "\n",
      "Q:  When did Edward the Confessor's son return from his fathers refuge?\n",
      "A (labels):  []\n",
      "LRP top5:  his 10 10 finally.\n",
      "LRP top5 attributions:  tensor([4.2294e-05, 4.1392e-05, 1.5105e-05, 1.2437e-05, 7.6883e-06]) \n",
      "\n",
      "Q:  What kind of force did Harthacnut establish?\n",
      "A (labels):  []\n",
      "LRP top5:  finally When Edward Conf the\n",
      "LRP top5 attributions:  tensor([nan, nan, nan, nan, nan]) \n",
      "\n",
      "Q:  Who made Robert of Jumieges earl of Hereford?\n",
      "A (labels):  []\n",
      "LRP top5:  Edward Edward Norman finallyhop\n",
      "LRP top5 attributions:  tensor([2.6580e-05, 1.7789e-05, 7.0224e-06, 6.0123e-06, 5.8480e-06]) \n",
      "\n",
      "Q:  Where did Harold II die?\n",
      "A (labels):  ['Battle of Hastings', 'the Battle of Hastings', 'at the Battle of Hastings']\n",
      "LRP top5:  Battle at die Has of\n",
      "LRP top5 attributions:  tensor([1.5507e-04, 2.3164e-05, 1.3318e-05, 1.2976e-05, 8.6146e-06]) \n",
      "\n",
      "Q:  Who killed Harold II? \n",
      "A (labels):  ['William II', 'Duke William II', 'Duke William II']\n",
      "LRP top5:  Duke William Dukee Norman\n",
      "LRP top5 attributions:  tensor([5.4744e-05, 2.2121e-05, 1.1128e-05, 9.5650e-06, 8.1094e-06]) \n",
      "\n",
      "Q:  When was the Battle of Hastings?\n",
      "A (labels):  ['1066', 'In 1066', '1066']\n",
      "LRP top5:  1066 Norman II In\n",
      "LRP top5 attributions:  tensor([3.5091e-05, 2.6621e-05, 1.4490e-05, 1.1714e-05, 1.1521e-05]) \n",
      "\n",
      "Q:  Who was the ruling class ahead of the Normans?\n",
      "A (labels):  ['Anglo-Saxons', 'the Anglo-Saxons', 'Anglo-Saxons']\n",
      "LRP top5:  gloSaxon Ans).\n",
      "LRP top5 attributions:  tensor([5.4870e-05, 4.9903e-05, 4.1117e-05, 2.2957e-05, 1.1055e-05]) \n",
      "\n",
      "Q:  When did King Harold II conquer England?\n",
      "A (labels):  []\n",
      "LRP top5:  ). King Battle King In\n",
      "LRP top5 attributions:  tensor([2.9808e-05, 1.9376e-05, 1.8612e-05, 1.5246e-05, 1.4448e-05]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print(\"Q: \", res[\"example\"][\"question\"])\n",
    "    print(\"A (labels): \", res[\"example\"][\"answers\"][\"text\"])\n",
    "    print(\"LRP top5: \", res[\"lrp_top5_tokens\"])\n",
    "    print(\"LRP top5 attributions: \", res[\"lrp_top5_relevances\"], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09e79e-3b18-41f2-87b6-36eef763995e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
