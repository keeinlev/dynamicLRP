{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571fed9a-d779-4e89-9893-09d691ce842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b275d1f1-b23e-431d-997e-071d5e8695b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06efdccb-3e55-4fd2-9db2-058409464dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3449334d-38ff-4c6d-b8c7-fdccf6714511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrp_engine import LRPEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28542d9-8dd8-4932-b62e-742f52162bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForQuestionAnswering were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc00008-f107-4592-8888-8caffd0c2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06727846-dd6d-4acd-b3f4-31452ea54613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2Model(\n",
       "  (embeddings): DebertaV2Embeddings(\n",
       "    (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): DebertaV2Encoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rel_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0c074d-2243-4680-a598-0a6a57929503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9898d951-99ce-4d2b-969d-07f709cd95e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [ example for example in dataset[\"validation\"] if example[\"answers\"][\"text\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dee6bdef-d2ca-4565-8f55-ddcfc8333d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ds[3]\n",
    "question = example[\"question\"]\n",
    "context = example[\"context\"]\n",
    "prompt = context + \" \" + question\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).input_ids.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "517f7f59-11d1-4e0f-aa94-e740bdb53dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd8bd294-bd78-4b4f-bc03-279f60a6c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = output.last_hidden_state.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d441a048-72fc-45fb-a58e-c3b0299037a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp = LRPEngine(use_attn_lrp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba17cd23-9921-4a32-809f-7532941c31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_rels, param_rels = lrp.run(output.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2b11c47-97a8-45f7-97de-dacdfd6cfbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 167])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_rels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99e79b3f-6d32-4905-8cf8-e643ec1f013f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries. Who was the Norse leader?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "474f4a48-7ae6-45c8-8f4c-d2d5ed65a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was their? and with Norway Denmark and their and in the people region with\n",
      "torch.return_types.topk(\n",
      "values=tensor([[0.4898, 0.4660, 0.4443, 0.4362, 0.4353]], device='cuda:0'),\n",
      "indices=tensor([[161,  76, 165,  71,  99]], device='cuda:0'))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(param_rels[0].cpu(), cmap=\"jet\")\n",
    "\n",
    "print(tokenizer.decode(input_ids[0][param_rels[0].topk(5).indices][0]))\n",
    "print(param_rels[0].topk(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "951c3566-c0bf-4095-8dc2-5e1914a521a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                            | 217/11873 [00:19<14:25, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                            | 239/11873 [00:21<17:49, 10.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     19\u001b[39m output = model(input_ids)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m _, param_vals = \u001b[43mlrp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m lrp_max = param_vals[\u001b[32m0\u001b[39m].flatten().argmax()\n\u001b[32m     24\u001b[39m lrp_top_token = tokenizer.convert_ids_to_tokens([input_ids[\u001b[32m0\u001b[39m][lrp_max]])[\u001b[32m0\u001b[39m].strip().replace(\u001b[38;5;28mchr\u001b[39m(\u001b[32m9601\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Programming\\research\\lrp\\src\\experiments\\..\\lrp_engine\\lrp.py:209\u001b[39m, in \u001b[36mLRPEngine.run\u001b[39m\u001b[34m(self, output_tuple_or_tensor)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28mself\u001b[39m.promise_bucket.clear_all()\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_lrp_subsequent_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_tuple_or_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPropagation took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Programming\\research\\lrp\\src\\experiments\\..\\lrp_engine\\lrp.py:794\u001b[39m, in \u001b[36mLRPEngine._run_lrp_subsequent_pass\u001b[39m\u001b[34m(self, root_nodes, starting_relevances)\u001b[39m\n\u001b[32m    792\u001b[39m     rel = rel[\u001b[32m0\u001b[39m]\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m     res = \u001b[43mfcn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    796\u001b[39m     \u001b[38;5;28mprint\u001b[39m(node_ind, [ idx \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m topo_exec_order \u001b[38;5;28;01mif\u001b[39;00m node_ind \u001b[38;5;129;01min\u001b[39;00m out_adj_list[idx] ], input_frontier[node_ind])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Programming\\research\\lrp\\src\\experiments\\..\\lrp_engine\\lrp_prop_fcns.py:50\u001b[39m, in \u001b[36moutput_relevances.<locals>.default_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(res):\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, torch.Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     51\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[-\u001b[32m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[-\u001b[32m2\u001b[39m].metadata[\u001b[33m'\u001b[39m\u001b[33mtopo_ind\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m produced nan! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m LRPPropFunctions.dtype != torch.float32 \u001b[38;5;129;01mand\u001b[39;00m r.dtype != LRPPropFunctions.dtype:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "top1_hits = 0\n",
    "total_examples = 0\n",
    "\n",
    "for example in tqdm(dataset[\"validation\"]):\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = example[\"answers\"][\"text\"]\n",
    "\n",
    "    if not answers:\n",
    "        continue\n",
    "\n",
    "    input_ids = tokenizer(context + \" \" + question, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    if input_ids.shape[-1] > 512:\n",
    "        continue\n",
    "    \n",
    "    output = model(input_ids)\n",
    "\n",
    "    _, param_vals = lrp.run(output.last_hidden_state)\n",
    "\n",
    "    lrp_max = param_vals[0].flatten().argmax()\n",
    "    lrp_top_token = tokenizer.convert_ids_to_tokens([input_ids[0][lrp_max]])[0].strip().replace(chr(9601), \"\")\n",
    "\n",
    "    if any(lrp_top_token in ans for ans in answers):\n",
    "        top1_hits += 1\n",
    "    total_examples += 1\n",
    "    if not (total_examples % 100):\n",
    "        print(top1_hits, total_examples)\n",
    "    # lrp_top5 = param_vals[2].flatten().topk(k=5)\n",
    "    # lrp_top5_tokens = tokenizer.decode(input_ids[0][lrp_top5.indices.cpu()])\n",
    "    # results.append({\n",
    "    #     \"example\": example,\n",
    "    #     \"lrp_top5_tokens\": lrp_top5_tokens,\n",
    "    #     \"lrp_top5_relevances\": lrp_top5.values.cpu(),\n",
    "    #     \"is_impossible\": len(answers) == 0\n",
    "    # })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd75ba9-9336-4033-9ce1-ecbce61151bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
