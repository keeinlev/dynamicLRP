{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2e5bca-5fb2-4c76-afcc-a2ab615c94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4e588c-f701-480e-b4cb-5b43676a2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrp_graph import make_graph\n",
    "from lrp_prop_fcns import LRPPropFunctions\n",
    "from add_backward_promise import AddBackwardPromise, compound_promises\n",
    "from util import create_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccda83d0-3c4e-4368-b618-b3876af3999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_hook(module, input, output):\n",
    "    return create_checkpoint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1150a4-4d26-4bf6-b62d-559b4ac789ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinlee-talka/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-2-117M/7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"zhihan1996/DNABERT-2-117M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc3588f-ea72-4720-b5b4-5a086131d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_module in model.encoder.layer:\n",
    "    layer_module.attention.self.register_forward_hook(checkpoint_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a526fc8e-4de8-426b-9ada-1b2ded2ce8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = \"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\"\n",
    "inputs = tokenizer(dna, return_tensors = 'pt')[\"input_ids\"]\n",
    "hidden_states : torch.Tensor = model(inputs, requires_grad=True)[0] # [1, sequence_length, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d07fbec0-958c-4016-a9f0-8cffbfb46ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.graph import Node\n",
    "\n",
    "in_adj_list, out_adj_list, names = make_graph(hidden_states)\n",
    "input_tracker : dict[Node, list] = { k : [] for k in list(in_adj_list.keys()) }\n",
    "checkpoints = list(filter(lambda k: type(k).__name__ == \"LRPCheckpointBackward\", list(in_adj_list.keys())))\n",
    "num_checkpoints_reached = 0\n",
    "\n",
    "fcn_map = LRPPropFunctions.generate_prop_fcn_map(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "166ea202-d92b-4e56-9a1e-d647283ab33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 2.8995461463928223\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# visited1 = set()\n",
    "with torch.no_grad():\n",
    "    # Create the first relevance layer via max logit.\n",
    "    m = hidden_states.max(-1)\n",
    "    relevance = torch.zeros_like(hidden_states)\n",
    "    b, s, d = hidden_states.shape\n",
    "    for i, inds in enumerate(m.indices):\n",
    "        relevance[i,list(range(s)),inds] = torch.ones_like(m.values[0])\n",
    "\n",
    "    # Setup the first iteration\n",
    "    input_tracker[hidden_states.grad_fn] = [ relevance ]\n",
    "    stack = [hidden_states.grad_fn]\n",
    "    in_adj_list[hidden_states.grad_fn] = []\n",
    "    nodes_pending = { k : len(v) for k, v in list(in_adj_list.items()) }\n",
    "\n",
    "    promise_queue : list[Node] = []\n",
    "\n",
    "    promise_traversal_stack = []\n",
    "    promise_traversal_mode = False\n",
    "\n",
    "    promise_fulfillment_mode = False\n",
    "\n",
    "    while (stack or promise_traversal_stack or promise_queue) and num_checkpoints_reached < len(checkpoints):\n",
    "        \n",
    "        curnode = None\n",
    "        \n",
    "        # Decide where we should take curnode from\n",
    "        if promise_queue and any(fcn.metadata[\"promise\"][\"complete\"] for fcn in promise_queue):\n",
    "            # Search for the first complete promise in the queue.\n",
    "            curnode = next(( fcn for fcn in promise_queue if fcn.metadata[\"promise\"][\"complete\"] ))\n",
    "            idx = promise_queue.index(curnode)\n",
    "            promise_queue = promise_queue[:idx] + promise_queue[idx + 1:]\n",
    "            promise_traversal_mode = False\n",
    "            promise_fulfillment_mode = True\n",
    "\n",
    "        elif promise_queue and any(nodes_pending[fcn] == 0 and \"pre_promise\" in fcn.metadata and\n",
    "                                   all(parent.complete for parent in fcn.metadata[\"pre_promise\"].parents)\n",
    "                                   for fcn in promise_queue):\n",
    "            # Promises that come from the pre_promise flow, they should be ready but they were created\n",
    "            # in promise traversal mode, so their in-relevances are not yet calculated.\n",
    "            curnode = next(( fcn for fcn in promise_queue if nodes_pending[fcn] == 0 and \n",
    "                            all(parent.complete for parent in fcn.metadata[\"pre_promise\"].parents) ))\n",
    "            idx = promise_queue.index(curnode)\n",
    "            promise_queue = promise_queue[:idx] + promise_queue[idx + 1:]\n",
    "\n",
    "            # We can process these like normal actually\n",
    "            promise_traversal_mode = False\n",
    "            promise_fulfillment_mode = False\n",
    "\n",
    "        elif promise_traversal_stack:\n",
    "            # Second priority is promise traversal, which overrides the requirement for all inputs to land\n",
    "            # before traversing a node. However, the promise will not have its rins computed until \n",
    "            curnode = promise_traversal_stack[0]\n",
    "            promise_traversal_stack = promise_traversal_stack[1:]\n",
    "            promise_traversal_mode = True\n",
    "            promise_fulfillment_mode = False\n",
    "\n",
    "        elif stack:\n",
    "            # Fallback to main stack\n",
    "            curnode = stack[0]\n",
    "            stack = stack[1:]\n",
    "            promise_traversal_mode = False\n",
    "            promise_fulfillment_mode = False\n",
    "\n",
    "        curnode_inputs = input_tracker[curnode]\n",
    "\n",
    "        # visited1.add(curnode) # For debugging\n",
    "\n",
    "        # According to next_functions\n",
    "        children = out_adj_list[curnode]\n",
    "\n",
    "        if not promise_fulfillment_mode:\n",
    "\n",
    "            # Categorize all inputs into either pending promises, complete promises, or tensors\n",
    "            pending_promise_inputs = []\n",
    "            complete_promise_inputs = []\n",
    "            tensor_inputs = []\n",
    "            for input_ in curnode_inputs:\n",
    "                if isinstance(input_, torch.Tensor):\n",
    "                    tensor_inputs.append(input_)\n",
    "                elif isinstance(input_, AddBackwardPromise) and input_.complete:\n",
    "                    complete_promise_inputs.append(input_)\n",
    "                elif isinstance(input_, AddBackwardPromise):\n",
    "                    pending_promise_inputs.append(input_)\n",
    "                elif input_ == 0.0:\n",
    "                    continue\n",
    "                else:\n",
    "                    print(input_)\n",
    "                    raise ValueError(f\"Expected relevance input to Node {curnode} to be type AddBackwardPromise or Tensor, but got {type(input_)} instead.\")\n",
    "    \n",
    "            if not complete_promise_inputs and not pending_promise_inputs and not tensor_inputs:\n",
    "                continue\n",
    "    \n",
    "            # Aggregate all inputs into one Tensor or AddBackwardPromise\n",
    "            curnode_in_rel = sum(tensor_inputs) + sum([ p.rin for p in complete_promise_inputs ])\n",
    "            if pending_promise_inputs:\n",
    "                # In promise traversal mode this will be True\n",
    "                agg_promises = compound_promises(pending_promise_inputs, promise_traversal_mode, promise_traversal_mode)\n",
    "                if curnode_in_rel != 0:\n",
    "                    curnode_in_rel = agg_promises + curnode_in_rel\n",
    "                else:\n",
    "                    curnode_in_rel = agg_promises\n",
    "        else:\n",
    "            curnode_in_rel = curnode.metadata[\"promise\"][\"rins\"][curnode.metadata[\"promise_idx\"]]\n",
    "\n",
    "\n",
    "        if not promise_traversal_mode and \"pre_promise\" in curnode.metadata:\n",
    "            # We have already traversed a promise tree, but have not calculated its bwd,\n",
    "            # since it was done in promise traversal mode.\n",
    "            pre_promise : AddBackwardPromise = curnode.metadata[\"pre_promise\"]\n",
    "\n",
    "            assert pre_promise.ready, f\"Pre-promise at {curnode} was assumed to be ready but was not.\"\n",
    "\n",
    "            if not pre_promise.complete:\n",
    "                if isinstance(curnode_in_rel, AddBackwardPromise):\n",
    "                    # If there is still pending promises at this node, try to complete them via the aggregate promise.\n",
    "                    # In the case this completes and propagates relevance down, we will have to pick up from the tail nodes\n",
    "                    # of the aggregate promise.\n",
    "                    curnode_in_rel.children.append(pre_promise)\n",
    "                    curnode_in_rel.setarg(pre_promise.arg1 + pre_promise.arg2)\n",
    "                else:\n",
    "                    pre_promise.accumulate_rout(curnode_in_rel)\n",
    "                    pre_promise.trigger_promise_completion()\n",
    "\n",
    "            tail_nodes = pre_promise.promise[\"tail_nodes\"]\n",
    "            if curnode in tail_nodes:\n",
    "                tail_nodes.remove(curnode)\n",
    "            if tail_nodes:\n",
    "                # Don't know if the promise is complete yet, so put on the promise queue.\n",
    "                # If any are done, they will be traversed with priority.\n",
    "                promise_queue += tail_nodes\n",
    "                continue\n",
    "            else:\n",
    "                # If the pre-promise is a singleton, i.e. the node is the tail of its own pre-promise,\n",
    "                # just collect the computed rin and re-traverse this node with a tensor rin input like normal.\n",
    "                curnode_in_rel = pre_promise.rin\n",
    "\n",
    "        if promise_traversal_mode:\n",
    "            # We want to save this so later we'll know we've already traversed this node.\n",
    "            curnode.metadata[\"pre_promise\"] = curnode_in_rel\n",
    "\n",
    "        # Call the propagation function for the node\n",
    "        curnode_outputs = fcn_map[type(curnode).__name__](curnode, curnode_in_rel)\n",
    "\n",
    "        if isinstance(curnode_outputs, AddBackwardPromise) and curnode_outputs.arg is not None and not curnode_outputs.complete:\n",
    "            # Node is waiting on Promise to be completed, add to promise queue and come back later.\n",
    "            curnode.metadata[\"promise\"] = curnode_outputs.promise\n",
    "            curnode.metadata[\"promise_idx\"] = curnode_outputs.idx\n",
    "            promise_queue.append(curnode)\n",
    "            continue\n",
    "\n",
    "        # Children may contain None, like grad_fn.next_functions, to keep integrity of input tracking\n",
    "        if len(children) == 0 or all(child is None for child in children):\n",
    "            continue\n",
    "        elif len(children) == 1:\n",
    "            # if isinstance(curnode_outputs, tuple):\n",
    "            #     curnode_outputs = [ curnode_outputs[0] ]\n",
    "            # else:\n",
    "            curnode_outputs = [ curnode_outputs ]\n",
    "            \n",
    "        elif len(children) != len(curnode_outputs):\n",
    "            raise ValueError(f\"Mismatch: {len(children)} children but {len(curnode_outputs)} outputs from {curnode}.\")\n",
    "\n",
    "\n",
    "        # Update child inputs\n",
    "        for i, child in enumerate(children):\n",
    "            if child is None:\n",
    "                # Discard the input (it shouldn't have value anyway), if it's a promise make it a zero-promise\n",
    "                if isinstance(curnode_outputs[i], AddBackwardPromise):\n",
    "                    # Manually set the arg to not trigger any additional side effects\n",
    "                    curnode_outputs[i].promise[\"args\"][curnode_outputs[i].idx] = 0.0\n",
    "                continue\n",
    "            input_tracker[child].append(curnode_outputs[i])\n",
    "            nodes_pending[child] -= 1\n",
    "            assert nodes_pending[child] >= 0, f\"Negative pending count for node {child}\"\n",
    "            assert len(input_tracker[child]) <= len(in_adj_list[child]), \\\n",
    "                f\"Too many inputs landed for {child}\"\n",
    "\n",
    "        # Collect children who now have all their inputs or that have promise(s) depending on them.\n",
    "        ready_children = []\n",
    "        promise_depends_on = []\n",
    "        for i, child in enumerate(children):\n",
    "            if child is None:\n",
    "                continue\n",
    "            if nodes_pending[child] == 0 and child not in promise_queue:\n",
    "                ready_children.append(child)\n",
    "            elif isinstance(curnode_outputs[i], AddBackwardPromise) and not curnode_outputs[i].complete and \"pre_promise\" not in child.metadata:\n",
    "                promise_depends_on.append(child)\n",
    "\n",
    "        promise_traversal_stack = promise_depends_on + promise_traversal_stack\n",
    "        stack = ready_children + stack\n",
    "        num_checkpoints_reached = sum([ \"checkpoint_relevance\" in checkpoint.metadata for checkpoint in checkpoints])\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"took {end_time - start_time} seconds\")\n",
    "checkpoint_vals = [ checkpoint.metadata[\"checkpoint_relevance\" ] for checkpoint in checkpoints ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a1ead4c-bf63-42c6-8dc8-554562b4788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.0137, -0.0005,  0.0155,  ...,  0.0047, -0.0184,  0.0038],\n",
      "        [ 0.0031,  0.0116,  0.0016,  ...,  0.0057, -0.0081,  0.0016],\n",
      "        [ 0.0002, -0.0040, -0.0008,  ..., -0.0001,  0.0002, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0039, -0.0003,  0.0006,  ...,  0.0036,  0.0011,  0.0021],\n",
      "        [-0.0303, -0.0040,  0.0022,  ..., -0.0005,  0.0004,  0.0065],\n",
      "        [ 0.0218,  0.1068,  0.1161,  ...,  0.0004,  0.0014,  0.0162]]), tensor([[-8.2475e-03, -8.0910e-03, -2.2354e-02,  ...,  2.2166e-04,\n",
      "         -1.1696e-03, -5.5983e-03],\n",
      "        [ 7.0878e-03,  4.9376e-02,  8.3516e-02,  ..., -3.8763e-02,\n",
      "         -2.6544e-02,  1.1215e-02],\n",
      "        [ 1.6580e+00,  4.4644e+00,  4.4368e-01,  ..., -2.7372e+00,\n",
      "          3.6432e-01, -2.3699e-02],\n",
      "        ...,\n",
      "        [ 2.3372e-03, -6.5937e-03,  1.7435e-03,  ...,  8.9610e-05,\n",
      "         -8.3524e-04,  4.7659e-06],\n",
      "        [-2.4250e-03, -4.1749e-03,  3.1729e-03,  ...,  3.8755e-04,\n",
      "         -6.1688e-05,  2.7256e-04],\n",
      "        [ 4.6258e-03,  1.5875e-03, -1.8096e-02,  ...,  6.3966e-04,\n",
      "         -6.1099e-04, -1.6058e-03]]), tensor([[-2.6239e-02,  1.7989e-01, -1.4599e+00,  ...,  6.5065e-03,\n",
      "          4.0949e-02, -8.2418e-02],\n",
      "        [ 8.0462e-01, -6.1229e-03,  1.3286e-01,  ...,  5.1774e-02,\n",
      "         -5.2023e-01, -5.3776e-01],\n",
      "        [-2.0381e+01, -3.7852e+00, -1.4659e+00,  ...,  3.2611e-01,\n",
      "          4.0325e+00,  1.3120e+00],\n",
      "        ...,\n",
      "        [-2.6461e-01, -7.5928e-02, -1.1166e-01,  ..., -6.9359e-02,\n",
      "         -7.8009e-02, -1.4005e-01],\n",
      "        [-2.5058e-01,  1.9061e-04, -7.5930e-02,  ...,  4.3438e-03,\n",
      "          2.2072e-01,  6.8343e-02],\n",
      "        [ 4.1732e-01,  5.5236e-02,  3.8777e-03,  ...,  3.1451e-02,\n",
      "          6.1643e-02,  3.3132e-02]]), tensor([[ 2.7844e-01, -1.7757e+00, -2.2657e+00,  ..., -1.2074e-01,\n",
      "          3.1108e-02, -9.0596e-02],\n",
      "        [ 2.8860e-01,  3.9943e-01,  3.6702e+00,  ...,  1.1092e-01,\n",
      "          9.1614e-02,  1.6047e-01],\n",
      "        [-1.7497e+00,  1.1269e+01, -5.0180e+00,  ..., -2.1459e+00,\n",
      "         -2.2871e+00, -3.3179e-01],\n",
      "        ...,\n",
      "        [ 1.1652e+00,  4.2933e-01,  1.4334e+00,  ...,  2.5020e-01,\n",
      "          3.0014e-02,  6.3757e-03],\n",
      "        [ 3.3902e-01, -1.1398e-02,  1.1250e+00,  ...,  3.7926e-01,\n",
      "          3.5136e-02,  2.5348e-02],\n",
      "        [-6.3631e-02,  5.8095e-01,  1.2373e-01,  ..., -1.9568e-03,\n",
      "         -2.6212e-02, -5.4832e-02]]), tensor([[ 1.3376e+01, -2.0333e+01, -1.5726e+01,  ..., -2.5795e-01,\n",
      "         -1.3792e+00, -2.1031e-01],\n",
      "        [ 1.7219e+01,  2.2932e+01, -1.3668e+02,  ...,  5.9077e-01,\n",
      "         -2.9161e+00, -8.8616e-01],\n",
      "        [-3.3719e+01,  1.7287e+02,  5.4982e+02,  ...,  6.0131e+00,\n",
      "          1.2974e-01,  1.1850e+01],\n",
      "        ...,\n",
      "        [-1.3412e+00,  4.8302e+00, -1.6769e+02,  ..., -2.2599e+00,\n",
      "         -2.0614e+00,  2.8714e-01],\n",
      "        [-4.5496e-01, -2.3890e+00, -1.3038e+02,  ..., -1.2725e+00,\n",
      "         -9.2561e-02, -4.5459e-01],\n",
      "        [ 2.3160e+00, -2.9339e+00, -2.7345e+00,  ...,  1.0628e-01,\n",
      "         -1.6341e-01, -5.3761e-01]]), tensor([[-6.5428e+01,  4.9644e+01,  2.1405e+01,  ...,  1.1887e+01,\n",
      "          1.5109e+00, -7.3839e+00],\n",
      "        [ 1.4028e+02, -1.8832e+02, -3.7859e+01,  ...,  1.6138e+02,\n",
      "          2.8107e+01,  1.2746e+02],\n",
      "        [ 5.5382e+01, -2.0179e+02, -4.7459e+01,  ..., -3.0095e+02,\n",
      "          4.8221e+01, -2.3070e+02],\n",
      "        ...,\n",
      "        [-1.5255e+02, -3.0359e+01, -6.9699e+01,  ...,  3.9697e+01,\n",
      "         -2.4628e+01,  5.0595e+01],\n",
      "        [-8.8904e+00, -8.5944e+00,  2.1391e+01,  ..., -4.6056e+01,\n",
      "         -3.4796e+00, -4.9835e+01],\n",
      "        [ 1.2242e+00,  4.4696e+00, -5.6941e+00,  ...,  3.1868e-01,\n",
      "          4.1677e-01,  2.3999e-01]]), tensor([[-4.7755e+03,  2.2374e+03,  2.5754e+03,  ...,  2.4338e+04,\n",
      "          2.8194e+02, -2.4746e+03],\n",
      "        [-2.6685e+01,  1.2018e+02,  2.2265e+02,  ...,  1.4905e+02,\n",
      "         -2.5381e+02, -8.8259e+00],\n",
      "        [-3.3172e+02, -9.0205e+01, -7.2857e+02,  ..., -1.8448e+03,\n",
      "          2.7245e+02,  2.5473e+02],\n",
      "        ...,\n",
      "        [-2.3804e+03, -2.6743e+02, -5.3570e+01,  ...,  9.6273e+02,\n",
      "         -1.3563e+02,  1.5028e+02],\n",
      "        [ 9.5217e+01, -8.1663e+00, -2.6013e+01,  ...,  9.0338e+01,\n",
      "         -3.2235e+01, -2.2465e+00],\n",
      "        [ 5.3395e+01,  2.1003e-01,  1.0452e+01,  ..., -2.5854e+02,\n",
      "         -6.2866e+01,  2.0597e+01]]), tensor([[-4.1393e+03,  2.0070e+02,  5.1091e+02,  ...,  6.7419e+03,\n",
      "          4.8005e+02,  4.5538e+03],\n",
      "        [-6.5079e+03, -4.3940e+03, -1.6738e+03,  ...,  3.4105e+03,\n",
      "          7.9964e+01, -1.6134e+03],\n",
      "        [-1.3401e+04,  2.7414e+03, -3.1734e+03,  ..., -1.0056e+03,\n",
      "          3.6210e+02, -2.7774e+03],\n",
      "        ...,\n",
      "        [ 1.2823e+04,  1.2077e+04,  3.6077e+03,  ..., -6.6591e+00,\n",
      "         -9.4910e+01, -5.2794e+03],\n",
      "        [-1.5581e+03, -2.4563e+03, -1.9321e+03,  ..., -1.6816e+01,\n",
      "         -2.4551e+02,  3.3671e+03],\n",
      "        [ 2.2844e+03, -6.5679e+02, -5.6022e+01,  ..., -2.8813e+02,\n",
      "         -2.0263e+03,  3.2181e+03]]), tensor([[ 5.1866e+01, -1.6039e+03, -3.8953e+03,  ...,  3.5021e+04,\n",
      "         -8.9949e+03,  3.6048e+02],\n",
      "        [-9.9963e+03, -2.5625e+04, -2.8412e+03,  ...,  4.8152e+04,\n",
      "          7.7536e+04, -3.1955e+04],\n",
      "        [-6.8827e+04,  1.5809e+04,  1.9708e+04,  ..., -4.3698e+04,\n",
      "         -6.3316e+03,  7.9913e+02],\n",
      "        ...,\n",
      "        [ 1.2356e+04,  3.8349e+03, -1.0360e+04,  ..., -2.0970e+04,\n",
      "          1.7433e+03, -1.5268e+03],\n",
      "        [-1.7640e+03, -1.7595e+04, -3.4663e+04,  ..., -8.4634e+03,\n",
      "          2.3665e+04, -2.1433e+03],\n",
      "        [-1.3464e+02, -6.6058e+00, -2.8477e+01,  ..., -5.5719e+02,\n",
      "         -3.0907e+02, -4.1455e+00]]), tensor([[ 4.3230e+03,  7.8702e+03, -1.0180e+05,  ...,  1.4225e+04,\n",
      "         -7.7529e+01, -6.6057e+03],\n",
      "        [ 2.9795e+04,  7.5245e+03,  8.7117e+04,  ...,  5.2130e+04,\n",
      "         -5.1267e+04, -1.3814e+05],\n",
      "        [ 1.5879e+04, -1.5573e+03, -5.5091e+04,  ...,  7.8562e+03,\n",
      "          4.1671e+03, -1.2421e+04],\n",
      "        ...,\n",
      "        [ 4.5788e+04,  3.7099e+05, -1.4447e+05,  ...,  1.0165e+04,\n",
      "          5.3525e+04, -4.9130e+03],\n",
      "        [ 1.9162e+05,  5.6699e+05, -1.0622e+05,  ...,  4.9062e+01,\n",
      "          7.1990e+05,  1.3176e+06],\n",
      "        [ 4.9141e+04,  9.3252e+03,  3.6634e+04,  ...,  4.1541e+03,\n",
      "         -6.3472e+04, -9.5998e+03]]), tensor([[ 2.6331e+05, -7.1850e+05, -4.7810e+05,  ..., -5.4805e+05,\n",
      "         -7.0551e+05,  1.7239e+05],\n",
      "        [-8.9416e+05,  9.2037e+05,  3.1954e+05,  ...,  4.0660e+05,\n",
      "         -1.8006e+05, -1.2213e+05],\n",
      "        [ 5.9195e+06, -1.1617e+07, -4.6310e+05,  ...,  2.3238e+05,\n",
      "          1.7268e+05, -1.0004e+05],\n",
      "        ...,\n",
      "        [ 1.9222e+05,  6.3724e+05, -1.9193e+05,  ...,  9.8231e+02,\n",
      "         -3.5433e+05,  2.2510e+04],\n",
      "        [ 6.9050e+05,  9.1187e+06, -5.2091e+05,  ..., -1.1239e+06,\n",
      "          2.1300e+06, -3.4173e+04],\n",
      "        [-6.7154e+05,  3.3631e+06, -4.6085e+04,  ..., -1.6020e+06,\n",
      "         -6.2251e+06, -4.8693e+04]]), tensor([[ 1.5357e+06,  7.1330e+04,  4.9856e+05,  ..., -3.3100e+05,\n",
      "         -2.5400e+04, -2.3838e+05],\n",
      "        [ 2.1869e+06,  2.5404e+05, -4.8849e+06,  ..., -3.1750e+05,\n",
      "          2.0719e+05, -4.2976e+05],\n",
      "        [-5.1810e+05,  5.1862e+05,  8.8096e+06,  ..., -1.6106e+07,\n",
      "          7.3109e+05, -8.5914e+05],\n",
      "        ...,\n",
      "        [ 1.4689e+05, -1.8576e+06,  6.6299e+06,  ...,  2.2583e+05,\n",
      "         -4.1793e+05, -3.8089e+05],\n",
      "        [-1.6619e+05, -4.4496e+06, -1.1192e+07,  ..., -3.9044e+06,\n",
      "         -5.4882e+05, -8.1323e+05],\n",
      "        [-1.5931e+05,  8.5519e+06, -2.6017e+07,  ...,  1.2516e+06,\n",
      "          1.8383e+05,  8.9248e+05]])]\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70616318-1493-4d4c-9f63-9771c7a18393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.8822e+09)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_vals[].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae5989-fc7d-4e85-8a6d-caf900197807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
